{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob\n",
    "import os.path\n",
    "from pandas.compat import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NREL Bird Model implementation: for obtaining clear sky GHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvlib\n",
    "from pvlib import clearsky, atmosphere\n",
    "from pvlib.location import Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CONFIGURE RUNS\n",
    "run_train = False # Disables training & processing of train set; Set it to True for the first time to create a model\n",
    "#test_location = \"Bondville\" #Folder name\n",
    "test_location = \"Boulder\" #Folder name\n",
    "#test_location = \"Desert_Rock\" #Folder name\n",
    "#test_location = \"Fort_Peck\" #Folder name\n",
    "#test_location = \"Goodwin_Creek\" #Folder name\n",
    "#test_location = \"Penn_State\" #Folder name\n",
    "#test_location = \"Sioux_Falls\" #Folder name\n",
    "\n",
    "# All_locations\n",
    "#bvl = Location(40.1134,-88.3695, 'US/Central', 217.932, 'Bondville')\n",
    "bvl = Location(40.0150,-105.2705, 'US/Mountain', 1655.064, 'Boulder')\n",
    "#bvl = Location(36.621,-116.043, 'US/Pacific', 1010.1072, 'Desert Rock')\n",
    "# bvl = Location(48,-106.449, 'US/Mountain', 630.0216, 'Fort Peck')\n",
    "# bvl = Location(34.2487,-89.8925, 'US/Central', 98, 'Goodwin Creek')\n",
    "# bvl = Location(40.798,-77.859, 'US/Eastern', 351.74, 'Penn State')\n",
    "# bvl = Location(43.544,-96.73, 'US/Central', 448.086, 'Sioux Falls')\n",
    "\n",
    "\n",
    "\n",
    "test_year = \"2015\"\n",
    "\n",
    "\n",
    "# TEST year 2009\n",
    "times = pd.DatetimeIndex(start='2009-01-01', end='2010-01-01', freq='1min',tz=bvl.tz)   # 12 months\n",
    "#  TEST year 2015\n",
    "#times = pd.DatetimeIndex(start='2015-01-01', end='2016-01-01', freq='1min',tz=bvl.tz)   # 12 months \n",
    "# TEST year 2016\n",
    "#times = pd.DatetimeIndex(start='2016-01-01', end='2017-01-01', freq='1min',tz=bvl.tz)   # 12 months \n",
    "# Test year 2017\n",
    "#times = pd.DatetimeIndex(start='2017-01-01', end='2018-01-01', freq='1min',tz=bvl.tz)   # 12 months \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1051200, 7)\n"
     ]
    }
   ],
   "source": [
    " if run_train:\n",
    "    # TRAIN set\n",
    "    times2010and2011 = pd.DatetimeIndex(start='2010-01-01', end='2012-01-01', freq='1min',\n",
    "                            tz=bvl.tz)   # 24 months of 2010 and 2011 - For training\n",
    "    cs_2010and2011 = bvl.get_clearsky(times2010and2011) # ineichen with climatology table by default\n",
    "    cs_2010and2011.drop(['dni','dhi'],axis=1, inplace=True) #updating the same dataframe by dropping two columns\n",
    "    cs_2010and2011.reset_index(inplace=True)\n",
    "\n",
    "    cs_2010and2011['index']=cs_2010and2011['index'].apply(lambda x:x.to_datetime())\n",
    "    cs_2010and2011['year'] = cs_2010and2011['index'].apply(lambda x:x.year)\n",
    "    cs_2010and2011['month'] = cs_2010and2011['index'].apply(lambda x:x.month)\n",
    "    cs_2010and2011['day'] = cs_2010and2011['index'].apply(lambda x:x.day)\n",
    "    cs_2010and2011['hour'] = cs_2010and2011['index'].apply(lambda x:x.hour)\n",
    "    cs_2010and2011['min'] = cs_2010and2011['index'].apply(lambda x:x.minute)\n",
    "\n",
    "\n",
    "    cs_2010and2011.drop(cs_2010and2011.index[-1], inplace=True)\n",
    "    print(cs_2010and2011.shape)\n",
    "    cs_2010and2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525600, 7)\n"
     ]
    }
   ],
   "source": [
    "# TEST set\n",
    "\n",
    "\n",
    "cs_test = bvl.get_clearsky(times)\n",
    "cs_test.drop(['dni','dhi'],axis=1, inplace=True) #updating the same dataframe by dropping two columns\n",
    "cs_test.reset_index(inplace=True)\n",
    "\n",
    "cs_test['index']=cs_test['index'].apply(lambda x:x.to_datetime())\n",
    "cs_test['year'] = cs_test['index'].apply(lambda x:x.year)\n",
    "cs_test['month'] = cs_test['index'].apply(lambda x:x.month)\n",
    "cs_test['day'] = cs_test['index'].apply(lambda x:x.day)\n",
    "cs_test['hour'] = cs_test['index'].apply(lambda x:x.hour)\n",
    "cs_test['min'] = cs_test['index'].apply(lambda x:x.minute)\n",
    "\n",
    "cs_test.drop(cs_test.index[-1], inplace=True)\n",
    "print(cs_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import files from each year in a separate dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "- year            integer\t year, i.e., 1995\n",
    "- jday            integer\t Julian day (1 through 365 [or 366])\n",
    "- month           integer\t number of the month (1-12)\n",
    "- day             integer\t day of the month(1-31)\n",
    "- hour            integer\t hour of the day (0-23)\n",
    "- min             integer\t minute of the hour (0-59)\n",
    "- dt              real\t decimal time (hour.decimalminutes, e.g., 23.5 = 2330)\n",
    "- zen             real\t solar zenith angle (degrees)\n",
    "- dw_solar        real\t downwelling global solar (Watts m^-2)\n",
    "- uw_solar        real\t upwelling global solar (Watts m^-2)\n",
    "- direct_n        real\t direct-normal solar (Watts m^-2)\n",
    "- diffuse         real\t downwelling diffuse solar (Watts m^-2)\n",
    "- dw_ir           real\t downwelling thermal infrared (Watts m^-2)\n",
    "- dw_casetemp     real\t downwelling IR case temp. (K)\n",
    "- dw_dometemp     real\t downwelling IR dome temp. (K)\n",
    "- uw_ir           real\t upwelling thermal infrared (Watts m^-2)\n",
    "- uw_casetemp     real\t upwelling IR case temp. (K)\n",
    "- uw_dometemp     real\t upwelling IR dome temp. (K)\n",
    "- uvb             real\t global UVB (milliWatts m^-2)\n",
    "- par             real\t photosynthetically active radiation (Watts m^-2)\n",
    "- netsolar        real\t net solar (dw_solar - uw_solar) (Watts m^-2)\n",
    "- netir           real\t net infrared (dw_ir - uw_ir) (Watts m^-2)\n",
    "- totalnet        real\t net radiation (netsolar+netir) (Watts m^-2)\n",
    "- temp            real\t 10-meter air temperature (?C)\n",
    "- rh              real\t relative humidity (%)\n",
    "- windspd         real\t wind speed (ms^-1)\n",
    "- winddir         real\t wind direction (degrees, clockwise from north)\n",
    "- pressure        real\t station pressure (mb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['year', 'jday', 'month', 'day','hour','min','dt','zen','dw_solar','dw_solar_QC','uw_solar',\n",
    "       'uw_solar_QC', 'direct_n','direct_n_QC','diffuse', 'diffuse_QC', 'dw_ir', 'dw_ir_QC', 'dw_casetemp',\n",
    "       'dw_casetemp_QC', 'dw_dometemp','dw_dometemp_QC','uw_ir', 'uw_ir_QC', 'uw_casetemp','uw_casetemp_QC',\n",
    "       'uw_dometemp','uw_dometemp_QC','uvb','uvb_QC','par','par_QC','netsolar','netsolar_QC','netir','netir_QC',\n",
    "       'totalnet','totalnet_QC','temp','temp_QC','rh','rh_QC','windspd','windspd_QC','winddir','winddir_QC',\n",
    "       'pressure','pressure_QC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: ./data/Boulder/Exp_1_train\n",
      "(1050018, 48)\n",
      "(1050018, 50)\n"
     ]
    }
   ],
   "source": [
    " if run_train:\n",
    "    # Train Set\n",
    "    path = r'./data/' + test_location + '/Exp_1_train'\n",
    "    print(\"train_path:\",path)\n",
    "    all_files = glob.glob(path + \"/*.dat\")\n",
    "    all_files.sort()\n",
    "\n",
    "    df_big_train = pd.concat([pd.read_csv(f, skipinitialspace = True, quotechar = '\"',skiprows=(2),delimiter=' ', \n",
    "                     index_col=False,header=None, names=cols) for f in all_files],ignore_index=True)\n",
    "    print(df_big_train.shape)\n",
    "    df_train = pd.merge(df_big_train, cs_2010and2011, on=['year','month','day','hour','min'])\n",
    "    print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Boulder/Exp_1_test/2009\n",
      "(3702, 48)\n",
      "(525132, 48)\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "path = r'./data/' + test_location + '/Exp_1_test/' + test_year\n",
    "print(path)\n",
    "all_files = glob.glob(path + \"/*.dat\")\n",
    "all_files.sort()\n",
    "\n",
    "df_big_test = pd.concat((pd.read_csv(f, skipinitialspace = True, quotechar = '\"',skiprows=(2),delimiter=' ', \n",
    "                 index_col=False,header=None, names=cols) for f in all_files),ignore_index=True)\n",
    "print(df_big_test[df_big_test['dw_solar']==-9999.9].shape)\n",
    "df_test = pd.merge(df_big_test, cs_test, on=['year','month','day','hour','min'])\n",
    "print(df_big_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Clear Sky GHI And the big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_train:\n",
    "    # TRAIN set\n",
    "    #updating the same dataframe by dropping the index columns from clear sky model\n",
    "    df_train.drop(['index'],axis=1, inplace=True)\n",
    "    # Resetting Index\n",
    "    df_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST set\n",
    "#updating the same dataframe by dropping the index columns from clear sky model\n",
    "df_test.drop(['index'],axis=1, inplace=True)\n",
    "# Resetting Index\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1034397, 49)\n"
     ]
    }
   ],
   "source": [
    "if run_train:\n",
    "    # TRAIN set\n",
    "    #Dropping rows with two or more -9999.9 values in columns\n",
    "    missing_data_indices = np.where((df_train <=-9999.9).apply(sum, axis=1)>=2)[0] #Get indices of all rows with 2 or more -9999.9\n",
    "    df_train.drop(missing_data_indices, axis=0, inplace=True) # Drop those inddices\n",
    "    print(df_train.shape)\n",
    "    df_train.reset_index(drop=True, inplace=True) # 2nd time - Resetting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505639, 49)\n"
     ]
    }
   ],
   "source": [
    "# TEST set\n",
    "missing_data_indices_test = np.where((df_test <= -9999.9).apply(sum, axis=1)>=2)[0]\n",
    "df_test.drop(missing_data_indices_test, axis=0, inplace=True)\n",
    "print(df_test.shape)\n",
    "df_test.reset_index(drop=True, inplace=True) # 2nd time - Reseting Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First resetting index after dropping rows in the previous part of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if run_train:\n",
    "    # TRAIN set\n",
    "    one_miss_train_idx = np.where((df_train <=-9999.9).apply(sum, axis=1)==1)[0]\n",
    "    print(len(one_miss_train_idx))\n",
    "    df_train.shape\n",
    "\n",
    "    col_names = df_train.columns\n",
    "    from collections import defaultdict\n",
    "    stats = defaultdict(int)\n",
    "    total_single_missing_values = 0\n",
    "    for name in col_names:\n",
    "        col_mean = df_train[~(df_train[name] == -9999.9)][name].mean()\n",
    "        missing_indices = np.where((df_train[name] == -9999.9))\n",
    "        stats[name] = len(missing_indices[0])\n",
    "        df_train[name].loc[missing_indices] = col_mean\n",
    "        total_single_missing_values += sum(df_train[name] == -9999.9)\n",
    "\n",
    "    train = np.where((df_train <=-9999.9).apply(sum, axis=1)==1)[0]\n",
    "    print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(505639, 49)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST set\n",
    "one_miss_test_idx = np.where((df_test <=-9999.9).apply(sum, axis=1)==1)[0]\n",
    "len(one_miss_test_idx)\n",
    "col_names_test = df_test.columns\n",
    "\n",
    "from collections import defaultdict\n",
    "stats_test = defaultdict(int)\n",
    "total_single_missing_values_test = 0\n",
    "for name in col_names_test:\n",
    "    col_mean = df_test[~(df_test[name] == -9999.9)][name].mean()\n",
    "    missing_indices = np.where((df_test[name] == -9999.9))\n",
    "    stats_test[name] = len(missing_indices[0])\n",
    "    df_test[name].loc[missing_indices] = col_mean\n",
    "    total_single_missing_values_test += sum(df_test[name] == -9999.9)\n",
    "    \n",
    "test = np.where((df_test <=-9999.9).apply(sum, axis=1)==1)[0]\n",
    "print(len(test))\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dw_solar_everyday = df_test.groupby(['jday'])['dw_solar'].mean()\n",
    "ghi_everyday = df_test.groupby(['jday'])['ghi'].mean()\n",
    "j_day = df_test['jday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEjCAYAAAD31uwUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxEz8uwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f079efa7ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "axes1 = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "axes1.scatter(j_day,dw_solar_everyday,label='Observed dw_solar',color='red')\n",
    "axes1.scatter(j_day, ghi_everyday, label='Clear Sky GHI',color='green')\n",
    "\n",
    "axes1.set_xlabel('Days')\n",
    "axes1.set_ylabel('Solar Irradiance (Watts /m^2)')\n",
    "axes1.set_title('Solar Irradiance - Test Year 2009')\n",
    "axes1.legend(loc='best')\n",
    "\n",
    "fig.savefig('RNN Paper Results/Exp2_1/' + test_location + '/'+  test_year + 'Figure 2.jpg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAGnCAYAAAAJ03gWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f078ca8e320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot(x=dw_solar_everyday,y=ghi_everyday,kind='reg')\n",
    "plt.xlabel('Observed global downwelling solar (Watts/m^2)')\n",
    "plt.ylabel('Clear Sky GHI (Watts/m^2)')\n",
    "plt.savefig('RNN Paper Results/Exp2_1/' + test_location + '/'+  test_year + 'Figure 3', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making the Kt (clear sky index at time t) column by first removing rows with ghi==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Kt max: 275783.511009\n",
      "train Kt min: -1561.16866474\n",
      "train Kt mean: 3.97720123135\n"
     ]
    }
   ],
   "source": [
    "if run_train:\n",
    "    # TRAIN dataset\n",
    "    df_train = df_train[df_train['ghi']!=0]\n",
    "    df_train['Kt'] = df_train['dw_solar']/df_train['ghi']\n",
    "    df_train.reset_index(inplace=True)\n",
    "\n",
    "    print(\"train Kt max: \"+str(df_train['Kt'].max()))\n",
    "    print(\"train Kt min: \"+str(df_train['Kt'].min()))\n",
    "    print(\"train Kt mean: \"+str(df_train['Kt'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Kt max: 18622.0035826\n",
      "test Kt min: -1997.84146167\n",
      "test Kt mean: 3.20825588533\n"
     ]
    }
   ],
   "source": [
    "# TEST dataset\n",
    "df_test = df_test[df_test['ghi']!=0]\n",
    "df_test['Kt'] = df_test['dw_solar']/df_test['ghi']\n",
    "df_test.reset_index(inplace=True)\n",
    "\n",
    "print(\"test Kt max: \"+str(df_test['Kt'].max()))\n",
    "print(\"test Kt min: \"+str(df_test['Kt'].min()))\n",
    "print(\"test Kt mean: \"+str(df_test['Kt'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_train:\n",
    "    # TRAIN dataset\n",
    "    df_train= df_train[df_train['Kt']< 5000]\n",
    "    df_train= df_train[df_train['Kt']> -1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "df_test= df_test[df_test['Kt']< 5000]\n",
    "df_test= df_test[df_test['Kt']> -1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making 4 Kt columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_train:\n",
    "    # Train dataset\n",
    "    df_train['Kt_2'] = df_train['Kt']\n",
    "    df_train['Kt_3'] = df_train['Kt']\n",
    "    df_train['Kt_4'] = df_train['Kt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "df_test['Kt_2'] = df_test['Kt']\n",
    "df_test['Kt_3'] = df_test['Kt']\n",
    "df_test['Kt_4'] = df_test['Kt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group the data (train dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zen = df_train.groupby(['year','month','day','hour'])['zen'].mean()\n",
    "dw_solar = df_train.groupby(['year','month','day','hour'])['dw_solar'].mean()\n",
    "uw_solar = df_train.groupby(['year','month','day','hour'])['uw_solar'].mean()\n",
    "direct_n = df_train.groupby(['year','month','day','hour'])['direct_n'].mean()\n",
    "diffuse = df_train.groupby(['year','month','day','hour'])['diffuse'].mean()\n",
    "dw_ir = df_train.groupby(['year','month','day','hour'])['dw_ir'].mean()\n",
    "dw_casetemp = df_train.groupby(['year','month','day','hour'])['dw_casetemp'].mean()\n",
    "dw_dometemp = df_train.groupby(['year','month','day','hour'])['dw_dometemp'].mean()\n",
    "uw_ir = df_train.groupby(['year','month','day','hour'])['uw_ir'].mean()\n",
    "uw_casetemp = df_train.groupby(['year','month','day','hour'])['uw_casetemp'].mean()\n",
    "uw_dometemp = df_train.groupby(['year','month','day','hour'])['uw_dometemp'].mean()\n",
    "uvb = df_train.groupby(['year','month','day','hour'])['uvb'].mean()\n",
    "par = df_train.groupby(['year','month','day','hour'])['par'].mean()\n",
    "netsolar = df_train.groupby(['year','month','day','hour'])['netsolar'].mean()\n",
    "netir = df_train.groupby(['year','month','day','hour'])['netir'].mean()\n",
    "totalnet = df_train.groupby(['year','month','day','hour'])['totalnet'].mean()\n",
    "temp = df_train.groupby(['year','month','day','hour'])['temp'].mean()\n",
    "rh = df_train.groupby(['year','month','day','hour'])['rh'].mean()\n",
    "windspd = df_train.groupby(['year','month','day','hour'])['windspd'].mean()\n",
    "winddir = df_train.groupby(['year','month','day','hour'])['winddir'].mean()\n",
    "pressure = df_train.groupby(['year','month','day','hour'])['pressure'].mean()\n",
    "ghi = df_train.groupby(['year','month','day','hour'])['ghi'].mean()\n",
    "Kt = df_train.groupby(['year','month','day','hour'])['Kt'].mean()\n",
    "Kt_2 = df_train.groupby(['year','month','day','hour'])['Kt_2'].mean()\n",
    "Kt_3 = df_train.groupby(['year','month','day','hour'])['Kt_3'].mean()\n",
    "Kt_4 = df_train.groupby(['year','month','day','hour'])['Kt_4'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_train = pd.concat([zen,dw_solar,uw_solar,direct_n,diffuse,dw_ir,dw_casetemp,dw_dometemp,uw_ir,uw_casetemp,uw_dometemp,\n",
    "                    uvb,par,netsolar,netir,totalnet,temp,rh,windspd,winddir,pressure,ghi,Kt,Kt_2,Kt_3,Kt_4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupdata - test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_zen = df_test.groupby(['month','day','hour'])['zen'].mean()\n",
    "test_dw_solar = df_test.groupby(['month','day','hour'])['dw_solar'].mean()\n",
    "test_uw_solar = df_test.groupby(['month','day','hour'])['uw_solar'].mean()\n",
    "test_direct_n = df_test.groupby(['month','day','hour'])['direct_n'].mean()\n",
    "test_diffuse = df_test.groupby(['month','day','hour'])['diffuse'].mean()\n",
    "test_dw_ir = df_test.groupby(['month','day','hour'])['dw_ir'].mean()\n",
    "test_dw_casetemp = df_test.groupby(['month','day','hour'])['dw_casetemp'].mean()\n",
    "test_dw_dometemp = df_test.groupby(['month','day','hour'])['dw_dometemp'].mean()\n",
    "test_uw_ir = df_test.groupby(['month','day','hour'])['uw_ir'].mean()\n",
    "test_uw_casetemp = df_test.groupby(['month','day','hour'])['uw_casetemp'].mean()\n",
    "test_uw_dometemp = df_test.groupby(['month','day','hour'])['uw_dometemp'].mean()\n",
    "test_uvb = df_test.groupby(['month','day','hour'])['uvb'].mean()\n",
    "test_par = df_test.groupby(['month','day','hour'])['par'].mean()\n",
    "test_netsolar = df_test.groupby(['month','day','hour'])['netsolar'].mean()\n",
    "test_netir = df_test.groupby(['month','day','hour'])['netir'].mean()\n",
    "test_totalnet = df_test.groupby(['month','day','hour'])['totalnet'].mean()\n",
    "test_temp = df_test.groupby(['month','day','hour'])['temp'].mean()\n",
    "test_rh = df_test.groupby(['month','day','hour'])['rh'].mean()\n",
    "test_windspd = df_test.groupby(['month','day','hour'])['windspd'].mean()\n",
    "test_winddir = df_test.groupby(['month','day','hour'])['winddir'].mean()\n",
    "test_pressure = df_test.groupby(['month','day','hour'])['pressure'].mean()\n",
    "test_ghi = df_test.groupby(['month','day','hour'])['ghi'].mean()\n",
    "test_Kt = df_test.groupby(['month','day','hour'])['Kt'].mean()\n",
    "test_Kt_2 = df_test.groupby(['month','day','hour'])['Kt_2'].mean()\n",
    "test_Kt_3 = df_test.groupby(['month','day','hour'])['Kt_3'].mean()\n",
    "test_Kt_4 = df_test.groupby(['month','day','hour'])['Kt_4'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new_test = pd.concat([test_zen,test_dw_solar,test_uw_solar,test_direct_n,test_diffuse,test_dw_ir,\n",
    "                         test_dw_casetemp,test_dw_dometemp,test_uw_ir,test_uw_casetemp,test_uw_dometemp,\n",
    "                    test_uvb,test_par,test_netsolar,test_netir,test_totalnet,test_temp,test_rh,\n",
    "                         test_windspd,test_winddir,test_pressure,test_ghi,test_Kt,test_Kt_2,test_Kt_3,test_Kt_4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new_test.loc[2].xs(17,level='day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting Kt values to make 1 hour ahead forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_train:\n",
    "    levels_index= []\n",
    "    for m in df_new_train.index.levels:\n",
    "        levels_index.append(m)\n",
    "    for i in levels_index[0]:\n",
    "        for j in levels_index[1]:\n",
    "            df_new_train.loc[i].loc[j]['Kt'] = df_new_train.loc[i].loc[j]['Kt'].shift(-1)\n",
    "            df_new_train.loc[i].loc[j]['Kt_2'] = df_new_train.loc[i].loc[j]['Kt_2'].shift(-2)\n",
    "            df_new_train.loc[i].loc[j]['Kt_3'] = df_new_train.loc[i].loc[j]['Kt_3'].shift(-3)\n",
    "            df_new_train.loc[i].loc[j]['Kt_4'] = df_new_train.loc[i].loc[j]['Kt_4'].shift(-4)\n",
    "    df_new_train = df_new_train[~(df_new_train['Kt_4'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels_index2= []\n",
    "for m in df_new_test.index.levels:\n",
    "    levels_index2.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in levels_index2[0]:\n",
    "    for j in levels_index2[1]:\n",
    "        df_new_test.loc[i].loc[j]['Kt'] = df_new_test.loc[i].loc[j]['Kt'].shift(-1)\n",
    "        df_new_test.loc[i].loc[j]['Kt_2'] = df_new_test.loc[i].loc[j]['Kt_2'].shift(-2)\n",
    "        df_new_test.loc[i].loc[j]['Kt_3'] = df_new_test.loc[i].loc[j]['Kt_3'].shift(-3)\n",
    "        df_new_test.loc[i].loc[j]['Kt_4'] = df_new_test.loc[i].loc[j]['Kt_4'].shift(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new_test = df_new_test[~(df_new_test['Kt_4'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize train and test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_train:\n",
    "    # TRAIN set\n",
    "    train_norm = (df_new_train - df_new_train.mean()) / (df_new_train.max() - df_new_train.min())\n",
    "    train_norm.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST set\n",
    "test_norm =  (df_new_test - df_new_test.mean()) / (df_new_test.max() - df_new_test.min())\n",
    "test_norm.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Making train and test sets with train_norm and test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### finding the gcf (greatest common factor) of train and test dataset's length and chop off the extra rows to make it divisible with the batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def roundup(x):\n",
    "    return int(math.ceil(x / 100.0)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_train shape is (9400, 22)\n",
      "y1_train shape is (9400, 4)\n"
     ]
    }
   ],
   "source": [
    "if run_train:\n",
    "    # TRAIN set\n",
    "    train_lim = roundup(train_norm.shape[0])\n",
    "    train_random = train_norm.sample(train_lim-train_norm.shape[0])\n",
    "    train_norm = train_norm.append(train_random)\n",
    "\n",
    "    X1 = train_norm.drop(['Kt','Kt_2','Kt_3','Kt_4'],axis=1)\n",
    "    y1 = train_norm[['Kt','Kt_2','Kt_3','Kt_4']]\n",
    "\n",
    "    print(\"X1_train shape is {}\".format(X1.shape))\n",
    "    print(\"y1_train shape is {}\".format(y1.shape))\n",
    "\n",
    "    X_train = np.array(X1)\n",
    "    y_train  = np.array(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2_test shape is (3200, 22)\n",
      "y2_test shape is (3200, 4)\n"
     ]
    }
   ],
   "source": [
    "# TEST set\n",
    "test_lim = roundup(test_norm.shape[0])\n",
    "test_random = test_norm.sample(test_lim-test_norm.shape[0])\n",
    "test_norm = test_norm.append(test_random)\n",
    "\n",
    "X2 = test_norm.drop(['Kt','Kt_2','Kt_3','Kt_4'],axis=1)\n",
    "y2 = test_norm[['Kt','Kt_2','Kt_3','Kt_4']]\n",
    "\n",
    "print(\"X2_test shape is {}\".format(X2.shape))\n",
    "print(\"y2_test shape is {}\".format(y2.shape))\n",
    "\n",
    "X_test = np.array(X2)\n",
    "y_test = np.array(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        #Hidden Dimension\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        #Building the RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initializing the hidden state with zeros\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        #One time step (the last one perhaps?)\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Indexing hidden state of the last time step\n",
    "        # out.size() --> ??\n",
    "        #out[:,-1,:] --> is it going to be 100,100\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        # out.size() --> 100,1\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_train:\n",
    "    # Instantiating Model Class\n",
    "    input_dim = 22\n",
    "    hidden_dim = 15\n",
    "    layer_dim = 1\n",
    "    output_dim = 4\n",
    "    batch_size = 100\n",
    "\n",
    "    model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "    # Instantiating Loss Class\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Instantiate Optimizer Class\n",
    "    learning_rate = 0.001\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # initializing lists to store losses over epochs:\n",
    "    train_loss = []\n",
    "    train_iter = []\n",
    "else:\n",
    "    model = torch.load('RNN Paper Results/Exp2_1/' + test_location + '/'+  test_year + 'torch_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEst set\n",
    "\n",
    "\n",
    "test_loss = []\n",
    "test_iter = []\n",
    "# converting numpy array to torch tensor\n",
    "\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "# Convert to Float tensor\n",
    "\n",
    "X_test = X_test.type(torch.FloatTensor)\n",
    "y_test = y_test.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 100. Train_MSE: 0.03832287713885307. Test_MSE: [[[ 0.12061296  0.03091992  0.00825078  0.04777953]]]\n",
      "Epoch: 2 Iteration: 200. Train_MSE: 0.03326038271188736. Test_MSE: [[[ 0.10679609  0.03094405  0.00756924  0.04006466]]]\n",
      "Epoch: 3 Iteration: 300. Train_MSE: 0.028695719316601753. Test_MSE: [[[ 0.09557553  0.03094332  0.00702937  0.03376288]]]\n",
      "Epoch: 4 Iteration: 400. Train_MSE: 0.02027653157711029. Test_MSE: [[[ 0.08644794  0.03094414  0.00658457  0.0286114 ]]]\n",
      "Epoch: 5 Iteration: 500. Train_MSE: 0.016247019171714783. Test_MSE: [[[ 0.07900257  0.03093149  0.00622283  0.02439137]]]\n",
      "Epoch: 6 Iteration: 600. Train_MSE: 0.017917541787028313. Test_MSE: [[[ 0.07290123  0.03089711  0.00593458  0.02090653]]]\n",
      "Epoch: 7 Iteration: 700. Train_MSE: 0.015244700014591217. Test_MSE: [[[ 0.06784897  0.03084437  0.00570457  0.01798662]]]\n",
      "Epoch: 8 Iteration: 800. Train_MSE: 0.011180789209902287. Test_MSE: [[[ 0.06374811  0.03078108  0.00552332  0.01559514]]]\n",
      "Epoch: 9 Iteration: 900. Train_MSE: 0.017052482813596725. Test_MSE: [[[ 0.06039879  0.03070905  0.0053782   0.01363007]]]\n",
      "Epoch: 10 Iteration: 1000. Train_MSE: 0.009396160021424294. Test_MSE: [[[ 0.05762663  0.03063303  0.00526112  0.01201377]]]\n",
      "Epoch: 11 Iteration: 1100. Train_MSE: 0.007917770184576511. Test_MSE: [[[ 0.05534184  0.03056885  0.00516074  0.01068815]]]\n",
      "Epoch: 12 Iteration: 1200. Train_MSE: 0.007108100224286318. Test_MSE: [[[ 0.05345024  0.03050339  0.00507925  0.00958829]]]\n",
      "Epoch: 13 Iteration: 1300. Train_MSE: 0.0073609668761491776. Test_MSE: [[[ 0.0518748   0.03043022  0.00501434  0.00865212]]]\n",
      "Epoch: 15 Iteration: 1400. Train_MSE: 0.00575594836845994. Test_MSE: [[[ 0.0505561   0.03035449  0.00496173  0.00786631]]]\n",
      "Epoch: 16 Iteration: 1500. Train_MSE: 0.005472333636134863. Test_MSE: [[[ 0.04948306  0.03027593  0.00492142  0.00722339]]]\n",
      "Epoch: 17 Iteration: 1600. Train_MSE: 0.005932149942964315. Test_MSE: [[[ 0.04859237  0.03019387  0.00489014  0.00669282]]]\n",
      "Epoch: 18 Iteration: 1700. Train_MSE: 0.005012026987969875. Test_MSE: [[[ 0.04784129  0.03012386  0.00486253  0.00625407]]]\n",
      "Epoch: 19 Iteration: 1800. Train_MSE: 0.005514926742762327. Test_MSE: [[[ 0.04720683  0.03006039  0.00483864  0.00588984]]]\n",
      "Epoch: 20 Iteration: 1900. Train_MSE: 0.004411553964018822. Test_MSE: [[[ 0.04667065  0.03000018  0.00481845  0.00557823]]]\n",
      "Epoch: 21 Iteration: 2000. Train_MSE: 0.003900592913851142. Test_MSE: [[[ 0.0462036   0.02993725  0.0048026   0.00529941]]]\n",
      "Epoch: 22 Iteration: 2100. Train_MSE: 0.0038534754421561956. Test_MSE: [[[ 0.04581331  0.02987176  0.00479073  0.00506529]]]\n",
      "Epoch: 23 Iteration: 2200. Train_MSE: 0.004704623483121395. Test_MSE: [[[ 0.04548445  0.02980573  0.00478283  0.00487256]]]\n",
      "Epoch: 24 Iteration: 2300. Train_MSE: 0.004746641032397747. Test_MSE: [[[ 0.04519672  0.02974102  0.00477614  0.00471212]]]\n",
      "Epoch: 25 Iteration: 2400. Train_MSE: 0.004309520591050386. Test_MSE: [[[ 0.04494235  0.02968989  0.0047694   0.00457692]]]\n",
      "Epoch: 26 Iteration: 2500. Train_MSE: 0.005965297110378742. Test_MSE: [[[ 0.04471593  0.02963676  0.00476367  0.0044614 ]]]\n",
      "Epoch: 27 Iteration: 2600. Train_MSE: 0.003149581840261817. Test_MSE: [[[ 0.04451418  0.02958916  0.00475895  0.00435388]]]\n",
      "Epoch: 29 Iteration: 2700. Train_MSE: 0.0026089369785040617. Test_MSE: [[[ 0.04433104  0.0295381   0.00475535  0.00425519]]]\n",
      "Epoch: 30 Iteration: 2800. Train_MSE: 0.0037896353751420975. Test_MSE: [[[ 0.04416877  0.0294851   0.00475379  0.00417285]]]\n",
      "Epoch: 31 Iteration: 2900. Train_MSE: 0.005740323569625616. Test_MSE: [[[ 0.04401943  0.02943016  0.00475388  0.0041022 ]]]\n",
      "Epoch: 32 Iteration: 3000. Train_MSE: 0.003627569880336523. Test_MSE: [[[ 0.04387838  0.02938499  0.00475324  0.00404158]]]\n",
      "Epoch: 33 Iteration: 3100. Train_MSE: 0.00477349990978837. Test_MSE: [[[ 0.04374591  0.02934067  0.00475266  0.00398876]]]\n",
      "Epoch: 34 Iteration: 3200. Train_MSE: 0.0028716258239001036. Test_MSE: [[[ 0.04361986  0.02930277  0.00475125  0.0039393 ]]]\n",
      "Epoch: 35 Iteration: 3300. Train_MSE: 0.0018153678392991424. Test_MSE: [[[ 0.0435029   0.02926181  0.00475101  0.00388992]]]\n",
      "Epoch: 36 Iteration: 3400. Train_MSE: 0.002428604755550623. Test_MSE: [[[ 0.04339289  0.02921925  0.00475118  0.00384351]]]\n",
      "Epoch: 37 Iteration: 3500. Train_MSE: 0.0035504354164004326. Test_MSE: [[[ 0.0432864   0.02917691  0.00475259  0.00380344]]]\n",
      "Epoch: 38 Iteration: 3600. Train_MSE: 0.004078075289726257. Test_MSE: [[[ 0.04318218  0.02912952  0.00475449  0.00376828]]]\n",
      "Epoch: 39 Iteration: 3700. Train_MSE: 0.003124921815469861. Test_MSE: [[[ 0.04307812  0.02909345  0.00475557  0.00373622]]]\n",
      "Epoch: 40 Iteration: 3800. Train_MSE: 0.0029759027529507875. Test_MSE: [[[ 0.04297638  0.02905776  0.00475604  0.00370708]]]\n",
      "Epoch: 41 Iteration: 3900. Train_MSE: 0.0032688146457076073. Test_MSE: [[[ 0.04287961  0.02902408  0.00475704  0.00367788]]]\n",
      "Epoch: 43 Iteration: 4000. Train_MSE: 0.0015921812737360597. Test_MSE: [[[ 0.04278799  0.02898704  0.00475796  0.00364717]]]\n",
      "Epoch: 44 Iteration: 4100. Train_MSE: 0.0031467173248529434. Test_MSE: [[[ 0.04269812  0.02894935  0.00475966  0.00361901]]]\n",
      "Epoch: 45 Iteration: 4200. Train_MSE: 0.004194313660264015. Test_MSE: [[[ 0.0426048   0.0289119   0.00476178  0.00359347]]]\n",
      "Epoch: 46 Iteration: 4300. Train_MSE: 0.003987344913184643. Test_MSE: [[[ 0.0425115   0.02887411  0.00476441  0.00357061]]]\n",
      "Epoch: 47 Iteration: 4400. Train_MSE: 0.0033538579009473324. Test_MSE: [[[ 0.04241993  0.02884179  0.004766    0.003549  ]]]\n",
      "Epoch: 48 Iteration: 4500. Train_MSE: 0.015066485852003098. Test_MSE: [[[ 0.04232763  0.02881121  0.00476673  0.00352785]]]\n",
      "Epoch: 49 Iteration: 4600. Train_MSE: 0.0020130795892328024. Test_MSE: [[[ 0.0422415   0.02878     0.00476823  0.00350591]]]\n",
      "Epoch: 50 Iteration: 4700. Train_MSE: 0.0021148694213479757. Test_MSE: [[[ 0.04215902  0.02874723  0.00476974  0.00348281]]]\n",
      "Epoch: 51 Iteration: 4800. Train_MSE: 0.0040925610810518265. Test_MSE: [[[ 0.04207496  0.02871341  0.00477193  0.00346179]]]\n",
      "Epoch: 52 Iteration: 4900. Train_MSE: 0.006051935721188784. Test_MSE: [[[ 0.04198865  0.02867701  0.00477423  0.00344245]]]\n",
      "Epoch: 53 Iteration: 5000. Train_MSE: 0.0033743148669600487. Test_MSE: [[[ 0.04190174  0.02864601  0.00477631  0.00342405]]]\n",
      "Epoch: 54 Iteration: 5100. Train_MSE: 0.013061076402664185. Test_MSE: [[[ 0.0418147   0.02861508  0.00477792  0.00340674]]]\n",
      "Epoch: 55 Iteration: 5200. Train_MSE: 0.002698556985706091. Test_MSE: [[[ 0.04173191  0.02858745  0.0047795   0.00338931]]]\n",
      "Epoch: 56 Iteration: 5300. Train_MSE: 0.0014187690103426576. Test_MSE: [[[ 0.04165317  0.02855689  0.00478106  0.00337051]]]\n",
      "Epoch: 58 Iteration: 5400. Train_MSE: 0.002589734736829996. Test_MSE: [[[ 0.04157638  0.02852561  0.00478286  0.00335196]]]\n",
      "Epoch: 59 Iteration: 5500. Train_MSE: 0.0031512356363236904. Test_MSE: [[[ 0.04149561  0.02849414  0.00478522  0.00333495]]]\n",
      "Epoch: 60 Iteration: 5600. Train_MSE: 0.0028585607651621103. Test_MSE: [[[ 0.04141203  0.02846166  0.00478775  0.00331888]]]\n",
      "Epoch: 61 Iteration: 5700. Train_MSE: 0.0029541209805756807. Test_MSE: [[[ 0.0413305   0.0284332   0.00478961  0.00330366]]]\n",
      "Epoch: 62 Iteration: 5800. Train_MSE: 0.003287498140707612. Test_MSE: [[[ 0.04124924  0.02840594  0.0047911   0.00328875]]]\n",
      "Epoch: 63 Iteration: 5900. Train_MSE: 0.00608425447717309. Test_MSE: [[[ 0.04117008  0.02837868  0.00479247  0.00327361]]]\n",
      "Epoch: 64 Iteration: 6000. Train_MSE: 0.0014688202645629644. Test_MSE: [[[ 0.04109753  0.02834967  0.00479413  0.00325664]]]\n",
      "Epoch: 65 Iteration: 6100. Train_MSE: 0.0030623911879956722. Test_MSE: [[[ 0.04102388  0.0283201   0.00479601  0.00324082]]]\n",
      "Epoch: 66 Iteration: 6200. Train_MSE: 0.0029386812821030617. Test_MSE: [[[ 0.04094582  0.02828999  0.00479848  0.00322598]]]\n",
      "Epoch: 67 Iteration: 6300. Train_MSE: 0.0030896016396582127. Test_MSE: [[[ 0.04086813  0.02825992  0.00480048  0.00321212]]]\n",
      "Epoch: 68 Iteration: 6400. Train_MSE: 0.0023946939036250114. Test_MSE: [[[ 0.04079108  0.02823423  0.00480213  0.00319864]]]\n",
      "Epoch: 69 Iteration: 6500. Train_MSE: 0.0027631192933768034. Test_MSE: [[[ 0.04071469  0.02820712  0.00480352  0.00318548]]]\n",
      "Epoch: 70 Iteration: 6600. Train_MSE: 0.0017805913230404258. Test_MSE: [[[ 0.04064303  0.02818131  0.00480495  0.00317113]]]\n",
      "Epoch: 72 Iteration: 6700. Train_MSE: 0.0018354329513385892. Test_MSE: [[[ 0.04057488  0.0281533   0.00480654  0.00315639]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 Iteration: 6800. Train_MSE: 0.0031603595707565546. Test_MSE: [[[ 0.04050383  0.02812497  0.00480854  0.00314282]]]\n",
      "Epoch: 74 Iteration: 6900. Train_MSE: 0.003992974292486906. Test_MSE: [[[ 0.04042875  0.02809488  0.00481104  0.00312998]]]\n",
      "Epoch: 75 Iteration: 7000. Train_MSE: 0.003116816282272339. Test_MSE: [[[ 0.04035565  0.02806892  0.00481306  0.00311779]]]\n",
      "Epoch: 76 Iteration: 7100. Train_MSE: 0.0026904239784926176. Test_MSE: [[[ 0.04028275  0.02804365  0.00481452  0.00310606]]]\n",
      "Epoch: 77 Iteration: 7200. Train_MSE: 0.002111581386998296. Test_MSE: [[[ 0.04021114  0.02801978  0.00481557  0.00309403]]]\n",
      "Epoch: 78 Iteration: 7300. Train_MSE: 0.0015868732007220387. Test_MSE: [[[ 0.04014512  0.02799392  0.00481703  0.00308073]]]\n",
      "Epoch: 79 Iteration: 7400. Train_MSE: 0.002181441755965352. Test_MSE: [[[ 0.04007982  0.02796695  0.00481863  0.00306753]]]\n",
      "Epoch: 80 Iteration: 7500. Train_MSE: 0.0026885769329965115. Test_MSE: [[[ 0.040011    0.02793998  0.00482081  0.00305536]]]\n",
      "Epoch: 81 Iteration: 7600. Train_MSE: 0.0026695220731198788. Test_MSE: [[[ 0.03994157  0.02791089  0.00482293  0.00304396]]]\n",
      "Epoch: 82 Iteration: 7700. Train_MSE: 0.0025653974153101444. Test_MSE: [[[ 0.03987151  0.0278876   0.00482448  0.00303297]]]\n",
      "Epoch: 83 Iteration: 7800. Train_MSE: 0.002425768645480275. Test_MSE: [[[ 0.03980268  0.02786301  0.00482559  0.00302231]]]\n",
      "Epoch: 84 Iteration: 7900. Train_MSE: 0.001832399400882423. Test_MSE: [[[ 0.03973759  0.02783942  0.00482705  0.0030111 ]]]\n",
      "Epoch: 86 Iteration: 8000. Train_MSE: 0.0015045111067593098. Test_MSE: [[[ 0.03967644  0.02781398  0.0048283   0.00299871]]]\n",
      "Epoch: 87 Iteration: 8100. Train_MSE: 0.004391434136778116. Test_MSE: [[[ 0.03961396  0.02778771  0.00483009  0.00298737]]]\n",
      "Epoch: 88 Iteration: 8200. Train_MSE: 0.00384667981415987. Test_MSE: [[[ 0.03954789  0.02776073  0.00483223  0.00297644]]]\n",
      "Epoch: 89 Iteration: 8300. Train_MSE: 0.002417906653136015. Test_MSE: [[[ 0.03948112  0.02773593  0.0048342   0.00296634]]]\n",
      "Epoch: 90 Iteration: 8400. Train_MSE: 0.011403050273656845. Test_MSE: [[[ 0.03941555  0.0277122   0.00483552  0.00295674]]]\n",
      "Epoch: 91 Iteration: 8500. Train_MSE: 0.0024540876038372517. Test_MSE: [[[ 0.03935061  0.02769027  0.00483628  0.00294689]]]\n",
      "Epoch: 92 Iteration: 8600. Train_MSE: 0.00156146171502769. Test_MSE: [[[ 0.03929042  0.02766676  0.00483771  0.00293622]]]\n",
      "Epoch: 93 Iteration: 8700. Train_MSE: 0.0019625844433903694. Test_MSE: [[[ 0.03923297  0.02764193  0.00483918  0.00292505]]]\n",
      "Epoch: 94 Iteration: 8800. Train_MSE: 0.002141122007742524. Test_MSE: [[[ 0.0391717   0.02761754  0.0048409   0.00291458]]]\n",
      "Epoch: 95 Iteration: 8900. Train_MSE: 0.002548086689785123. Test_MSE: [[[ 0.03910938  0.02759029  0.00484275  0.00290498]]]\n",
      "Epoch: 96 Iteration: 9000. Train_MSE: 0.0023803829681128263. Test_MSE: [[[ 0.03904648  0.02756818  0.00484429  0.00289572]]]\n",
      "Epoch: 97 Iteration: 9100. Train_MSE: 0.001949514145962894. Test_MSE: [[[ 0.03898402  0.02754494  0.00484531  0.00288694]]]\n",
      "Epoch: 98 Iteration: 9200. Train_MSE: 0.001679213484749198. Test_MSE: [[[ 0.03892512  0.02752419  0.00484653  0.00287787]]]\n",
      "Epoch: 99 Iteration: 9300. Train_MSE: 0.0013189720921218395. Test_MSE: [[[ 0.03886952  0.0275005   0.0048477   0.00286765]]]\n",
      "Epoch: 101 Iteration: 9400. Train_MSE: 0.0016755242832005024. Test_MSE: [[[ 0.0388149   0.02747666  0.0048492   0.00285763]]]\n",
      "Epoch: 102 Iteration: 9500. Train_MSE: 0.0024571577087044716. Test_MSE: [[[ 0.03875614  0.02745304  0.00485093  0.00284842]]]\n",
      "Epoch: 103 Iteration: 9600. Train_MSE: 0.0031084248330444098. Test_MSE: [[[ 0.0386956   0.02742766  0.00485294  0.00283993]]]\n",
      "Epoch: 104 Iteration: 9700. Train_MSE: 0.00252606812864542. Test_MSE: [[[ 0.03863655  0.02740743  0.00485404  0.00283178]]]\n",
      "Epoch: 105 Iteration: 9800. Train_MSE: 0.002670423360541463. Test_MSE: [[[ 0.03857784  0.02738697  0.00485483  0.0028237 ]]]\n",
      "Epoch: 106 Iteration: 9900. Train_MSE: 0.0019907548557966948. Test_MSE: [[[ 0.03852164  0.02736497  0.00485587  0.00281531]]]\n",
      "Epoch: 107 Iteration: 10000. Train_MSE: 0.002783992560580373. Test_MSE: [[[ 0.03846968  0.0273424   0.00485711  0.00280555]]]\n",
      "Epoch: 108 Iteration: 10100. Train_MSE: 0.002055758610367775. Test_MSE: [[[ 0.03841612  0.02731992  0.00485858  0.00279651]]]\n",
      "Epoch: 109 Iteration: 10200. Train_MSE: 0.008368786424398422. Test_MSE: [[[ 0.03835874  0.02729638  0.0048601   0.00278812]]]\n",
      "Epoch: 110 Iteration: 10300. Train_MSE: 0.0020998225081712008. Test_MSE: [[[ 0.03830259  0.02727353  0.0048617   0.00278044]]]\n",
      "Epoch: 111 Iteration: 10400. Train_MSE: 0.00285221915692091. Test_MSE: [[[ 0.03824653  0.02725309  0.00486261  0.00277304]]]\n",
      "Epoch: 112 Iteration: 10500. Train_MSE: 0.0017346175154671073. Test_MSE: [[[ 0.03819204  0.02723266  0.00486355  0.00276567]]]\n",
      "Epoch: 113 Iteration: 10600. Train_MSE: 0.001565223908983171. Test_MSE: [[[ 0.03814067  0.02721147  0.00486464  0.00275721]]]\n",
      "Epoch: 115 Iteration: 10700. Train_MSE: 0.0013144089607521892. Test_MSE: [[[ 0.03809139  0.02718991  0.0048658   0.00274838]]]\n",
      "Epoch: 116 Iteration: 10800. Train_MSE: 0.002051387680694461. Test_MSE: [[[ 0.03803878  0.02716828  0.00486722  0.00274048]]]\n",
      "Epoch: 117 Iteration: 10900. Train_MSE: 0.0025056172162294388. Test_MSE: [[[ 0.0379839   0.0271452   0.00486891  0.00273312]]]\n",
      "Epoch: 118 Iteration: 11000. Train_MSE: 0.002014054451137781. Test_MSE: [[[ 0.03793079  0.0271252   0.00487005  0.00272626]]]\n",
      "Epoch: 119 Iteration: 11100. Train_MSE: 0.0022209640592336655. Test_MSE: [[[ 0.03787791  0.02710567  0.00487089  0.00271965]]]\n",
      "Epoch: 120 Iteration: 11200. Train_MSE: 0.0016505424864590168. Test_MSE: [[[ 0.0378256   0.0270862   0.00487162  0.00271269]]]\n",
      "Epoch: 121 Iteration: 11300. Train_MSE: 0.0010517389746382833. Test_MSE: [[[ 0.03777803  0.02706563  0.00487265  0.00270443]]]\n",
      "Epoch: 122 Iteration: 11400. Train_MSE: 0.0014703640481457114. Test_MSE: [[[ 0.03773018  0.02704446  0.00487378  0.00269646]]]\n",
      "Epoch: 123 Iteration: 11500. Train_MSE: 0.00216944282874465. Test_MSE: [[[ 0.03767903  0.02702297  0.00487537  0.00268927]]]\n",
      "Epoch: 124 Iteration: 11600. Train_MSE: 0.002351259347051382. Test_MSE: [[[ 0.03762741  0.02700103  0.00487667  0.00268265]]]\n",
      "Epoch: 125 Iteration: 11700. Train_MSE: 0.0020535518415272236. Test_MSE: [[[ 0.03757621  0.02698333  0.00487747  0.00267633]]]\n",
      "Epoch: 126 Iteration: 11800. Train_MSE: 0.003954906947910786. Test_MSE: [[[ 0.03752542  0.0269625   0.00487821  0.00267025]]]\n",
      "Epoch: 127 Iteration: 11900. Train_MSE: 0.0013267702888697386. Test_MSE: [[[ 0.03747788  0.02694452  0.00487903  0.00266328]]]\n",
      "Epoch: 129 Iteration: 12000. Train_MSE: 0.0011084022698923945. Test_MSE: [[[ 0.03743315  0.02692442  0.00487991  0.00265558]]]\n",
      "Epoch: 130 Iteration: 12100. Train_MSE: 0.0019001537002623081. Test_MSE: [[[ 0.03738689  0.02690412  0.0048811   0.00264871]]]\n",
      "Epoch: 131 Iteration: 12200. Train_MSE: 0.003488015616312623. Test_MSE: [[[ 0.03733708  0.02688243  0.00488272  0.00264226]]]\n",
      "Epoch: 132 Iteration: 12300. Train_MSE: 0.0017888760194182396. Test_MSE: [[[ 0.03728753  0.02686444  0.0048837   0.0026363 ]]]\n",
      "Epoch: 133 Iteration: 12400. Train_MSE: 0.00293839443475008. Test_MSE: [[[ 0.03723889  0.0268453   0.0048845   0.00263078]]]\n",
      "Epoch: 134 Iteration: 12500. Train_MSE: 0.0014500223333016038. Test_MSE: [[[ 0.03719082  0.02682793  0.00488486  0.00262498]]]\n",
      "Epoch: 135 Iteration: 12600. Train_MSE: 0.000824113842099905. Test_MSE: [[[ 0.03714646  0.02680928  0.00488574  0.00261823]]]\n",
      "Epoch: 136 Iteration: 12700. Train_MSE: 0.0012459405697882175. Test_MSE: [[[ 0.03710343  0.02678971  0.00488667  0.00261117]]]\n",
      "Epoch: 137 Iteration: 12800. Train_MSE: 0.0018243577796965837. Test_MSE: [[[ 0.03705722  0.02677052  0.00488796  0.00260475]]]\n",
      "Epoch: 138 Iteration: 12900. Train_MSE: 0.002245046431198716. Test_MSE: [[[ 0.0370104   0.02674847  0.00488931  0.002599  ]]]\n",
      "Epoch: 139 Iteration: 13000. Train_MSE: 0.0015067531494423747. Test_MSE: [[[ 0.03696304  0.02673172  0.00489006  0.00259351]]]\n",
      "Epoch: 140 Iteration: 13100. Train_MSE: 0.0014582733856514096. Test_MSE: [[[ 0.03691629  0.02671326  0.00489045  0.00258839]]]\n",
      "Epoch: 141 Iteration: 13200. Train_MSE: 0.0019056875025853515. Test_MSE: [[[ 0.03687206  0.02669661  0.00489117  0.00258283]]]\n",
      "Epoch: 143 Iteration: 13300. Train_MSE: 0.0008467233274132013. Test_MSE: [[[ 0.03683095  0.02667771  0.00489192  0.00257617]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144 Iteration: 13400. Train_MSE: 0.0017545068403705955. Test_MSE: [[[ 0.03678977  0.02665886  0.00489299  0.0025699 ]]]\n",
      "Epoch: 145 Iteration: 13500. Train_MSE: 0.0024629838299006224. Test_MSE: [[[ 0.03674427  0.02664012  0.00489412  0.00256412]]]\n",
      "Epoch: 146 Iteration: 13600. Train_MSE: 0.0021445166785269976. Test_MSE: [[[ 0.03669892  0.0266211   0.0048954   0.00255907]]]\n",
      "Epoch: 147 Iteration: 13700. Train_MSE: 0.0019221031107008457. Test_MSE: [[[ 0.03665482  0.02660429  0.00489599  0.0025543 ]]]\n",
      "Epoch: 148 Iteration: 13800. Train_MSE: 0.013380492106080055. Test_MSE: [[[ 0.03660932  0.0265875   0.00489607  0.00254952]]]\n",
      "Epoch: 149 Iteration: 13900. Train_MSE: 0.001114505808800459. Test_MSE: [[[ 0.03656794  0.02657066  0.00489682  0.00254409]]]\n",
      "Epoch: 150 Iteration: 14000. Train_MSE: 0.0012132374104112387. Test_MSE: [[[ 0.03652863  0.02655286  0.00489762  0.00253776]]]\n",
      "Epoch: 151 Iteration: 14100. Train_MSE: 0.0024497646372765303. Test_MSE: [[[ 0.03648701  0.02653474  0.00489868  0.00253202]]]\n",
      "Epoch: 152 Iteration: 14200. Train_MSE: 0.004246676340699196. Test_MSE: [[[ 0.03644362  0.02651518  0.00489966  0.00252688]]]\n",
      "Epoch: 153 Iteration: 14300. Train_MSE: 0.0017458407673984766. Test_MSE: [[[ 0.03640045  0.02649893  0.00490042  0.00252209]]]\n",
      "Epoch: 154 Iteration: 14400. Train_MSE: 0.011440414935350418. Test_MSE: [[[ 0.03635704  0.0264811   0.00490089  0.00251772]]]\n",
      "Epoch: 155 Iteration: 14500. Train_MSE: 0.0015114762354642153. Test_MSE: [[[ 0.03631631  0.02646576  0.00490147  0.00251313]]]\n",
      "Epoch: 156 Iteration: 14600. Train_MSE: 0.0008183231693692505. Test_MSE: [[[ 0.03627783  0.0264486   0.00490215  0.00250755]]]\n",
      "Epoch: 158 Iteration: 14700. Train_MSE: 0.0015956428833305836. Test_MSE: [[[ 0.03624044  0.02643113  0.00490298  0.00250183]]]\n",
      "Epoch: 159 Iteration: 14800. Train_MSE: 0.0017191069200634956. Test_MSE: [[[ 0.03619996  0.02641389  0.00490405  0.00249681]]]\n",
      "Epoch: 160 Iteration: 14900. Train_MSE: 0.0015268523711711168. Test_MSE: [[[ 0.0361575   0.02639613  0.0049051   0.00249222]]]\n",
      "Epoch: 161 Iteration: 15000. Train_MSE: 0.0015758550725877285. Test_MSE: [[[ 0.03611679  0.02638067  0.00490565  0.00248806]]]\n",
      "Epoch: 162 Iteration: 15100. Train_MSE: 0.0019313188968226314. Test_MSE: [[[ 0.0360758   0.02636491  0.00490601  0.00248403]]]\n",
      "Epoch: 163 Iteration: 15200. Train_MSE: 0.005222839303314686. Test_MSE: [[[ 0.03603566  0.02634905  0.0049064   0.00247973]]]\n",
      "Epoch: 164 Iteration: 15300. Train_MSE: 0.0008855390478856862. Test_MSE: [[[ 0.0359998   0.02633241  0.00490716  0.00247408]]]\n",
      "Epoch: 165 Iteration: 15400. Train_MSE: 0.0020484384149312973. Test_MSE: [[[ 0.03596264  0.02631542  0.00490798  0.00246892]]]\n",
      "Epoch: 166 Iteration: 15500. Train_MSE: 0.0017185313627123833. Test_MSE: [[[ 0.03592228  0.02629855  0.00490907  0.00246421]]]\n",
      "Epoch: 167 Iteration: 15600. Train_MSE: 0.0017101782141253352. Test_MSE: [[[ 0.0358824   0.02628167  0.00490974  0.00246014]]]\n",
      "Epoch: 168 Iteration: 15700. Train_MSE: 0.0013258956605568528. Test_MSE: [[[ 0.03584328  0.02626691  0.0049102   0.00245628]]]\n",
      "Epoch: 169 Iteration: 15800. Train_MSE: 0.0015394140500575304. Test_MSE: [[[ 0.03580398  0.0262505   0.00491056  0.00245254]]]\n",
      "Epoch: 170 Iteration: 15900. Train_MSE: 0.0010628660675138235. Test_MSE: [[[ 0.03576757  0.02623559  0.0049111   0.00244785]]]\n",
      "Epoch: 172 Iteration: 16000. Train_MSE: 0.001087410026229918. Test_MSE: [[[ 0.03573332  0.02621922  0.00491178  0.0024427 ]]]\n",
      "Epoch: 173 Iteration: 16100. Train_MSE: 0.001976383849978447. Test_MSE: [[[ 0.03569678  0.02620301  0.00491262  0.00243817]]]\n",
      "Epoch: 174 Iteration: 16200. Train_MSE: 0.002455162350088358. Test_MSE: [[[ 0.03565757  0.02618598  0.00491371  0.00243405]]]\n",
      "Epoch: 175 Iteration: 16300. Train_MSE: 0.0018413361394777894. Test_MSE: [[[ 0.03562     0.02617162  0.00491442  0.00243037]]]\n",
      "Epoch: 176 Iteration: 16400. Train_MSE: 0.001515351701527834. Test_MSE: [[[ 0.0355822   0.02615656  0.00491476  0.002427  ]]]\n",
      "Epoch: 177 Iteration: 16500. Train_MSE: 0.0012439133133739233. Test_MSE: [[[ 0.0355448   0.02614245  0.00491494  0.00242334]]]\n",
      "Epoch: 178 Iteration: 16600. Train_MSE: 0.0009869015775620937. Test_MSE: [[[ 0.03551079  0.02612721  0.00491555  0.00241867]]]\n",
      "Epoch: 179 Iteration: 16700. Train_MSE: 0.0013434275751933455. Test_MSE: [[[ 0.03547693  0.02611131  0.00491623  0.00241387]]]\n",
      "Epoch: 180 Iteration: 16800. Train_MSE: 0.0016574918990954757. Test_MSE: [[[ 0.03544055  0.02609578  0.0049172   0.00240966]]]\n",
      "Epoch: 181 Iteration: 16900. Train_MSE: 0.001516045187599957. Test_MSE: [[[ 0.03540372  0.02607899  0.00491806  0.00240595]]]\n",
      "Epoch: 182 Iteration: 17000. Train_MSE: 0.0014715518336743116. Test_MSE: [[[ 0.03536684  0.0260658   0.00491843  0.00240254]]]\n",
      "Epoch: 183 Iteration: 17100. Train_MSE: 0.0013578127836808562. Test_MSE: [[[ 0.03533026  0.0260505   0.0049186   0.00239936]]]\n",
      "Epoch: 184 Iteration: 17200. Train_MSE: 0.0011815793113783002. Test_MSE: [[[ 0.03529592  0.02603681  0.0049191   0.00239563]]]\n",
      "Epoch: 186 Iteration: 17300. Train_MSE: 0.0009457152336835861. Test_MSE: [[[ 0.03526398  0.02602171  0.00491957  0.00239099]]]\n",
      "Epoch: 187 Iteration: 17400. Train_MSE: 0.0033054265659302473. Test_MSE: [[[ 0.03523092  0.02600637  0.00492031  0.00238691]]]\n",
      "Epoch: 188 Iteration: 17500. Train_MSE: 0.0026305820792913437. Test_MSE: [[[ 0.03519529  0.025991    0.00492126  0.00238305]]]\n",
      "Epoch: 189 Iteration: 17600. Train_MSE: 0.0013556074118241668. Test_MSE: [[[ 0.03515948  0.02597712  0.00492196  0.0023798 ]]]\n",
      "Epoch: 190 Iteration: 17700. Train_MSE: 0.010143941268324852. Test_MSE: [[[ 0.03512419  0.02596305  0.0049222   0.00237691]]]\n",
      "Epoch: 191 Iteration: 17800. Train_MSE: 0.0013904301449656487. Test_MSE: [[[ 0.03508892  0.02595001  0.00492216  0.00237383]]]\n",
      "Epoch: 192 Iteration: 17900. Train_MSE: 0.0010258876718580723. Test_MSE: [[[ 0.03505657  0.02593612  0.00492272  0.00237002]]]\n",
      "Epoch: 193 Iteration: 18000. Train_MSE: 0.0013340559089556336. Test_MSE: [[[ 0.03502586  0.02592135  0.00492333  0.00236572]]]\n",
      "Epoch: 194 Iteration: 18100. Train_MSE: 0.0013353248359635472. Test_MSE: [[[ 0.03499221  0.02590704  0.00492406  0.00236181]]]\n",
      "Epoch: 195 Iteration: 18200. Train_MSE: 0.0016215838259086013. Test_MSE: [[[ 0.03495776  0.02589112  0.00492477  0.00235844]]]\n",
      "Epoch: 196 Iteration: 18300. Train_MSE: 0.0013536539627239108. Test_MSE: [[[ 0.03492329  0.02587862  0.00492521  0.00235537]]]\n",
      "Epoch: 197 Iteration: 18400. Train_MSE: 0.001108743716031313. Test_MSE: [[[ 0.03488879  0.02586419  0.00492532  0.00235265]]]\n",
      "Epoch: 198 Iteration: 18500. Train_MSE: 0.0010077229235321283. Test_MSE: [[[ 0.03485657  0.025852    0.00492567  0.00234963]]]\n",
      "Epoch: 199 Iteration: 18600. Train_MSE: 0.0009174315491691232. Test_MSE: [[[ 0.03482633  0.02583777  0.00492608  0.00234567]]]\n",
      "Epoch: 201 Iteration: 18700. Train_MSE: 0.0010250646155327559. Test_MSE: [[[ 0.03479665  0.02582368  0.00492671  0.00234174]]]\n",
      "Epoch: 202 Iteration: 18800. Train_MSE: 0.0015194988809525967. Test_MSE: [[[ 0.034764    0.02581008  0.00492741  0.00233833]]]\n",
      "Epoch: 203 Iteration: 18900. Train_MSE: 0.0019781463779509068. Test_MSE: [[[ 0.03473011  0.02579533  0.00492823  0.00233541]]]\n",
      "Epoch: 204 Iteration: 19000. Train_MSE: 0.0015693266177549958. Test_MSE: [[[ 0.03469737  0.02578379  0.00492836  0.00233276]]]\n",
      "Epoch: 205 Iteration: 19100. Train_MSE: 0.001642454881221056. Test_MSE: [[[ 0.03466439  0.02577141  0.00492834  0.00233018]]]\n",
      "Epoch: 206 Iteration: 19200. Train_MSE: 0.0013133842730894685. Test_MSE: [[[ 0.03463278  0.02575801  0.0049286   0.00232728]]]\n",
      "Epoch: 207 Iteration: 19300. Train_MSE: 0.002403917955234647. Test_MSE: [[[ 0.03460401  0.02574445  0.00492911  0.0023233 ]]]\n",
      "Epoch: 208 Iteration: 19400. Train_MSE: 0.0012871265644207597. Test_MSE: [[[ 0.03457393  0.02573108  0.00492972  0.00231968]]]\n",
      "Epoch: 209 Iteration: 19500. Train_MSE: 0.007203711196780205. Test_MSE: [[[ 0.03454103  0.0257173   0.00493027  0.00231649]]]\n",
      "Epoch: 210 Iteration: 19600. Train_MSE: 0.0012588715180754662. Test_MSE: [[[ 0.03450923  0.02570418  0.00493084  0.00231383]]]\n",
      "Epoch: 211 Iteration: 19700. Train_MSE: 0.002038863953202963. Test_MSE: [[[ 0.03447745  0.02569162  0.00493093  0.00231141]]]\n",
      "Epoch: 212 Iteration: 19800. Train_MSE: 0.0010376954451203346. Test_MSE: [[[ 0.03444643  0.02567899  0.0049311   0.00230898]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 213 Iteration: 19900. Train_MSE: 0.0011071438202634454. Test_MSE: [[[ 0.03441746  0.02566616  0.0049315   0.00230565]]]\n",
      "Epoch: 215 Iteration: 20000. Train_MSE: 0.0008544047013856471. Test_MSE: [[[ 0.03438988  0.02565312  0.00493196  0.00230194]]]\n",
      "Epoch: 216 Iteration: 20100. Train_MSE: 0.0012686805566772819. Test_MSE: [[[ 0.03435981  0.02564039  0.00493253  0.00229883]]]\n",
      "Epoch: 217 Iteration: 20200. Train_MSE: 0.0016516962787136436. Test_MSE: [[[ 0.03432815  0.02562697  0.00493322  0.0022961 ]]]\n",
      "Epoch: 218 Iteration: 20300. Train_MSE: 0.001257972908206284. Test_MSE: [[[ 0.03429789  0.02561549  0.00493349  0.00229374]]]\n",
      "Epoch: 219 Iteration: 20400. Train_MSE: 0.001363487564958632. Test_MSE: [[[ 0.03426754  0.02560342  0.00493357  0.00229162]]]\n",
      "Epoch: 220 Iteration: 20500. Train_MSE: 0.001147267292253673. Test_MSE: [[[ 0.03423715  0.02559139  0.00493366  0.0022892 ]]]\n",
      "Epoch: 221 Iteration: 20600. Train_MSE: 0.0007135731866583228. Test_MSE: [[[ 0.03421     0.02557878  0.00493408  0.00228572]]]\n",
      "Epoch: 222 Iteration: 20700. Train_MSE: 0.000960643810685724. Test_MSE: [[[ 0.03418247  0.02556584  0.00493454  0.00228234]]]\n",
      "Epoch: 223 Iteration: 20800. Train_MSE: 0.0014015466440469027. Test_MSE: [[[ 0.03415249  0.02555306  0.00493525  0.00227946]]]\n",
      "Epoch: 224 Iteration: 20900. Train_MSE: 0.0014674983685836196. Test_MSE: [[[ 0.03412223  0.02554001  0.00493569  0.00227702]]]\n",
      "Epoch: 225 Iteration: 21000. Train_MSE: 0.0012910667574033141. Test_MSE: [[[ 0.03409256  0.02552956  0.00493574  0.00227483]]]\n",
      "Epoch: 226 Iteration: 21100. Train_MSE: 0.003213539021089673. Test_MSE: [[[ 0.03406264  0.02551595  0.00493583  0.00227282]]]\n",
      "Epoch: 227 Iteration: 21200. Train_MSE: 0.0008523911819793284. Test_MSE: [[[ 0.03403508  0.0255052   0.00493605  0.00227008]]]\n",
      "Epoch: 229 Iteration: 21300. Train_MSE: 0.0007506487309001386. Test_MSE: [[[ 0.0340094   0.02549278  0.00493638  0.00226671]]]\n",
      "Epoch: 230 Iteration: 21400. Train_MSE: 0.001273701200261712. Test_MSE: [[[ 0.03398257  0.02548055  0.00493687  0.00226387]]]\n",
      "Epoch: 231 Iteration: 21500. Train_MSE: 0.0025988260749727488. Test_MSE: [[[ 0.03395307  0.02546767  0.00493763  0.00226127]]]\n",
      "Epoch: 232 Iteration: 21600. Train_MSE: 0.001087807584553957. Test_MSE: [[[ 0.03392401  0.02545743  0.00493784  0.00225908]]]\n",
      "Epoch: 233 Iteration: 21700. Train_MSE: 0.002232970204204321. Test_MSE: [[[ 0.0338953   0.02544552  0.00493793  0.00225725]]]\n",
      "Epoch: 234 Iteration: 21800. Train_MSE: 0.0009348800522275269. Test_MSE: [[[ 0.03386679  0.02543468  0.0049378   0.00225523]]]\n",
      "Epoch: 235 Iteration: 21900. Train_MSE: 0.000564339745324105. Test_MSE: [[[ 0.03384072  0.02542318  0.00493814  0.00225241]]]\n",
      "Epoch: 236 Iteration: 22000. Train_MSE: 0.0008305943920277059. Test_MSE: [[[ 0.03381548  0.02541104  0.00493851  0.00224927]]]\n",
      "Epoch: 237 Iteration: 22100. Train_MSE: 0.0011733750579878688. Test_MSE: [[[ 0.03378785  0.02539951  0.0049391   0.00224652]]]\n",
      "Epoch: 238 Iteration: 22200. Train_MSE: 0.0015349382301792502. Test_MSE: [[[ 0.03375962  0.0253861   0.00493967  0.00224425]]]\n",
      "Epoch: 239 Iteration: 22300. Train_MSE: 0.0009243942331522703. Test_MSE: [[[ 0.03373139  0.02537628  0.00493974  0.00224221]]]\n",
      "Epoch: 240 Iteration: 22400. Train_MSE: 0.000900560466106981. Test_MSE: [[[ 0.0337032   0.02536411  0.00493961  0.00224049]]]\n",
      "Epoch: 241 Iteration: 22500. Train_MSE: 0.0013353136600926518. Test_MSE: [[[ 0.03367682  0.02535405  0.00493978  0.00223838]]]\n",
      "Epoch: 243 Iteration: 22600. Train_MSE: 0.0005942262941971421. Test_MSE: [[[ 0.03365255  0.02534223  0.00494005  0.00223537]]]\n",
      "Epoch: 244 Iteration: 22700. Train_MSE: 0.001208774046972394. Test_MSE: [[[ 0.03362819  0.02533073  0.00494054  0.00223258]]]\n",
      "Epoch: 245 Iteration: 22800. Train_MSE: 0.0017329109832644463. Test_MSE: [[[ 0.03360056  0.02531962  0.00494099  0.0022301 ]]]\n",
      "Epoch: 246 Iteration: 22900. Train_MSE: 0.0014105270383879542. Test_MSE: [[[ 0.03357316  0.02530841  0.00494149  0.00222818]]]\n",
      "Epoch: 247 Iteration: 23000. Train_MSE: 0.0013889239635318518. Test_MSE: [[[ 0.03354667  0.02529816  0.0049415   0.00222652]]]\n",
      "Epoch: 248 Iteration: 23100. Train_MSE: 0.012659608386456966. Test_MSE: [[[ 0.03351868  0.02528734  0.00494116  0.00222489]]]\n",
      "Epoch: 249 Iteration: 23200. Train_MSE: 0.0007557401550002396. Test_MSE: [[[ 0.03349373  0.02527686  0.00494142  0.00222267]]]\n",
      "Epoch: 250 Iteration: 23300. Train_MSE: 0.0008369551505893469. Test_MSE: [[[ 0.03347014  0.02526573  0.00494176  0.00221974]]]\n",
      "Epoch: 251 Iteration: 23400. Train_MSE: 0.0017341891070827842. Test_MSE: [[[ 0.03344471  0.02525455  0.00494224  0.00221712]]]\n",
      "Epoch: 252 Iteration: 23500. Train_MSE: 0.003428810043260455. Test_MSE: [[[ 0.03341782  0.02524251  0.00494259  0.00221495]]]\n",
      "Epoch: 253 Iteration: 23600. Train_MSE: 0.0011094675865024328. Test_MSE: [[[ 0.03339136  0.02523298  0.00494274  0.00221308]]]\n",
      "Epoch: 254 Iteration: 23700. Train_MSE: 0.010822344571352005. Test_MSE: [[[ 0.03336461  0.02522119  0.00494269  0.00221156]]]\n",
      "Epoch: 255 Iteration: 23800. Train_MSE: 0.0010163550032302737. Test_MSE: [[[ 0.03333975  0.02521167  0.00494279  0.00220985]]]\n",
      "Epoch: 256 Iteration: 23900. Train_MSE: 0.0005782957305200398. Test_MSE: [[[ 0.03331641  0.02520085  0.00494302  0.00220733]]]\n",
      "Epoch: 258 Iteration: 24000. Train_MSE: 0.0011258941376581788. Test_MSE: [[[ 0.03329382  0.02518992  0.00494337  0.00220463]]]\n",
      "Epoch: 259 Iteration: 24100. Train_MSE: 0.0010952927405014634. Test_MSE: [[[ 0.03326886  0.02517952  0.00494383  0.00220241]]]\n",
      "Epoch: 260 Iteration: 24200. Train_MSE: 0.0010054832091555. Test_MSE: [[[ 0.0332424   0.02516889  0.0049442   0.00220051]]]\n",
      "Epoch: 261 Iteration: 24300. Train_MSE: 0.0010260153794661164. Test_MSE: [[[ 0.0332174   0.02515973  0.0049442   0.00219896]]]\n",
      "Epoch: 262 Iteration: 24400. Train_MSE: 0.001363625400699675. Test_MSE: [[[ 0.03319189  0.02514953  0.0049441   0.00219756]]]\n",
      "Epoch: 263 Iteration: 24500. Train_MSE: 0.0048683504574000835. Test_MSE: [[[ 0.03316676  0.02513928  0.00494406  0.00219592]]]\n",
      "Epoch: 264 Iteration: 24600. Train_MSE: 0.0006273615872487426. Test_MSE: [[[ 0.03314485  0.02512879  0.00494439  0.00219318]]]\n",
      "Epoch: 265 Iteration: 24700. Train_MSE: 0.001596470014192164. Test_MSE: [[[ 0.03312176  0.02511807  0.00494473  0.00219075]]]\n",
      "Epoch: 266 Iteration: 24800. Train_MSE: 0.001186660723760724. Test_MSE: [[[ 0.0330963   0.02510783  0.00494522  0.00218857]]]\n",
      "Epoch: 267 Iteration: 24900. Train_MSE: 0.0011477802181616426. Test_MSE: [[[ 0.03307121  0.02509749  0.00494533  0.00218697]]]\n",
      "Epoch: 268 Iteration: 25000. Train_MSE: 0.0008979897829703987. Test_MSE: [[[ 0.03304686  0.02508827  0.00494529  0.00218553]]]\n",
      "Epoch: 269 Iteration: 25100. Train_MSE: 0.0009959005983546376. Test_MSE: [[[ 0.03302199  0.02507728  0.00494523  0.0021842 ]]]\n",
      "Epoch: 270 Iteration: 25200. Train_MSE: 0.0007395296706818044. Test_MSE: [[[ 0.03299931  0.02506795  0.00494537  0.0021821 ]]]\n",
      "Epoch: 272 Iteration: 25300. Train_MSE: 0.000745339784771204. Test_MSE: [[[ 0.03297821  0.02505754  0.00494562  0.00217957]]]\n",
      "Epoch: 273 Iteration: 25400. Train_MSE: 0.0014235532144084573. Test_MSE: [[[ 0.0329553   0.02504752  0.00494595  0.00217746]]]\n",
      "Epoch: 274 Iteration: 25500. Train_MSE: 0.0017953538335859776. Test_MSE: [[[ 0.03293035  0.0250372   0.00494641  0.00217564]]]\n",
      "Epoch: 275 Iteration: 25600. Train_MSE: 0.0012488235952332616. Test_MSE: [[[ 0.03290682  0.02502879  0.00494656  0.00217419]]]\n",
      "Epoch: 276 Iteration: 25700. Train_MSE: 0.0010145336855202913. Test_MSE: [[[ 0.03288286  0.02501894  0.00494644  0.00217302]]]\n",
      "Epoch: 277 Iteration: 25800. Train_MSE: 0.000867017894051969. Test_MSE: [[[ 0.03285899  0.02500978  0.00494627  0.00217164]]]\n",
      "Epoch: 278 Iteration: 25900. Train_MSE: 0.000699821684975177. Test_MSE: [[[ 0.03283759  0.02500002  0.00494649  0.00216941]]]\n",
      "Epoch: 279 Iteration: 26000. Train_MSE: 0.0009405161254107952. Test_MSE: [[[ 0.03281621  0.0249898   0.00494675  0.00216703]]]\n",
      "Epoch: 280 Iteration: 26100. Train_MSE: 0.0011721436167135835. Test_MSE: [[[ 0.03279288  0.02498016  0.00494721  0.00216503]]]\n",
      "Epoch: 281 Iteration: 26200. Train_MSE: 0.0010388382943347096. Test_MSE: [[[ 0.03276921  0.02496967  0.00494752  0.00216343]]]\n",
      "Epoch: 282 Iteration: 26300. Train_MSE: 0.0010336344130337238. Test_MSE: [[[ 0.03274577  0.02496166  0.00494742  0.00216208]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 283 Iteration: 26400. Train_MSE: 0.0008987331530079246. Test_MSE: [[[ 0.03272227  0.02495109  0.00494726  0.00216095]]]\n",
      "Epoch: 284 Iteration: 26500. Train_MSE: 0.0008640997693873942. Test_MSE: [[[ 0.03270046  0.02494244  0.00494736  0.00215934]]]\n",
      "Epoch: 286 Iteration: 26600. Train_MSE: 0.000690409098751843. Test_MSE: [[[ 0.03268041  0.02493263  0.00494751  0.00215701]]]\n",
      "Epoch: 287 Iteration: 26700. Train_MSE: 0.002800967078655958. Test_MSE: [[[ 0.03265947  0.02492287  0.00494781  0.00215503]]]\n",
      "Epoch: 288 Iteration: 26800. Train_MSE: 0.0020338520407676697. Test_MSE: [[[ 0.03263653  0.02491345  0.00494826  0.00215318]]]\n",
      "Epoch: 289 Iteration: 26900. Train_MSE: 0.0009017026168294251. Test_MSE: [[[ 0.03261363  0.0249052   0.00494844  0.00215184]]]\n",
      "Epoch: 290 Iteration: 27000. Train_MSE: 0.009605390951037407. Test_MSE: [[[ 0.03259095  0.02489601  0.00494828  0.00215082]]]\n",
      "Epoch: 291 Iteration: 27100. Train_MSE: 0.0009066867642104626. Test_MSE: [[[ 0.03256811  0.02488736  0.00494796  0.00214966]]]\n",
      "Epoch: 292 Iteration: 27200. Train_MSE: 0.0007712668739259243. Test_MSE: [[[ 0.03254743  0.02487833  0.00494817  0.0021479 ]]]\n",
      "Epoch: 293 Iteration: 27300. Train_MSE: 0.0009925712365657091. Test_MSE: [[[ 0.03252794  0.02486868  0.00494845  0.00214568]]]\n",
      "Epoch: 294 Iteration: 27400. Train_MSE: 0.0009577395976521075. Test_MSE: [[[ 0.03250612  0.02485956  0.00494878  0.00214372]]]\n",
      "Epoch: 295 Iteration: 27500. Train_MSE: 0.0011969193583354354. Test_MSE: [[[ 0.03248366  0.02484943  0.00494906  0.00214216]]]\n",
      "Epoch: 296 Iteration: 27600. Train_MSE: 0.000922595732845366. Test_MSE: [[[ 0.03246144  0.02484182  0.0049491   0.00214086]]]\n",
      "Epoch: 297 Iteration: 27700. Train_MSE: 0.000737558351829648. Test_MSE: [[[ 0.03243908  0.02483187  0.00494891  0.00213987]]]\n",
      "Epoch: 298 Iteration: 27800. Train_MSE: 0.0006988929235376418. Test_MSE: [[[ 0.03241837  0.024824    0.00494896  0.00213863]]]\n",
      "Epoch: 299 Iteration: 27900. Train_MSE: 0.0007084885728545487. Test_MSE: [[[ 0.0323991   0.02481461  0.0049491   0.00213662]]]\n",
      "Epoch: 301 Iteration: 28000. Train_MSE: 0.0007090784492902458. Test_MSE: [[[ 0.03238026  0.02480552  0.00494941  0.00213457]]]\n",
      "Epoch: 302 Iteration: 28100. Train_MSE: 0.001082751783542335. Test_MSE: [[[ 0.03235908  0.02479709  0.00494971  0.00213289]]]\n",
      "Epoch: 303 Iteration: 28200. Train_MSE: 0.0014086125884205103. Test_MSE: [[[ 0.03233694  0.0247879   0.00495006  0.0021316 ]]]\n",
      "Epoch: 304 Iteration: 28300. Train_MSE: 0.0011525738518685102. Test_MSE: [[[ 0.03231583  0.02478079  0.00494986  0.00213054]]]\n",
      "Epoch: 305 Iteration: 28400. Train_MSE: 0.0011790188727900386. Test_MSE: [[[ 0.03229421  0.02477246  0.00494958  0.00212959]]]\n",
      "Epoch: 306 Iteration: 28500. Train_MSE: 0.0009563390631228685. Test_MSE: [[[ 0.03227351  0.0247634   0.00494956  0.00212836]]]\n",
      "Epoch: 307 Iteration: 28600. Train_MSE: 0.0022292528301477432. Test_MSE: [[[ 0.03225497  0.02475446  0.0049498   0.00212625]]]\n",
      "Epoch: 308 Iteration: 28700. Train_MSE: 0.0009337814408354461. Test_MSE: [[[ 0.03223538  0.02474578  0.00495009  0.00212434]]]\n",
      "Epoch: 309 Iteration: 28800. Train_MSE: 0.0066243684850633144. Test_MSE: [[[ 0.03221351  0.02473698  0.00495026  0.00212273]]]\n",
      "Epoch: 310 Iteration: 28900. Train_MSE: 0.0008768094121478498. Test_MSE: [[[ 0.03219268  0.02472887  0.00495044  0.00212158]]]\n",
      "Epoch: 311 Iteration: 29000. Train_MSE: 0.0016939491033554077. Test_MSE: [[[ 0.03217197  0.0247204   0.00495025  0.00212064]]]\n",
      "Epoch: 312 Iteration: 29100. Train_MSE: 0.0007053504232317209. Test_MSE: [[[ 0.03215159  0.02471181  0.00495017  0.00211971]]]\n",
      "Epoch: 313 Iteration: 29200. Train_MSE: 0.0008507256861776114. Test_MSE: [[[ 0.03213278  0.02470337  0.0049503   0.00211802]]]\n",
      "Epoch: 315 Iteration: 29300. Train_MSE: 0.0006254759500734508. Test_MSE: [[[ 0.03211507  0.02469482  0.00495049  0.002116  ]]]\n",
      "Epoch: 316 Iteration: 29400. Train_MSE: 0.0009002922452054918. Test_MSE: [[[ 0.03209537  0.02468677  0.00495073  0.00211441]]]\n",
      "Epoch: 317 Iteration: 29500. Train_MSE: 0.0012570642866194248. Test_MSE: [[[ 0.03207442  0.02467851  0.004951    0.00211309]]]\n",
      "Epoch: 318 Iteration: 29600. Train_MSE: 0.0009133528219535947. Test_MSE: [[[ 0.03205469  0.02467149  0.00495095  0.00211211]]]\n",
      "Epoch: 319 Iteration: 29700. Train_MSE: 0.0009483441826887429. Test_MSE: [[[ 0.03203468  0.02466332  0.00495076  0.00211136]]]\n",
      "Epoch: 320 Iteration: 29800. Train_MSE: 0.0009005059255287051. Test_MSE: [[[ 0.03201444  0.02465517  0.00495063  0.00211036]]]\n",
      "Epoch: 321 Iteration: 29900. Train_MSE: 0.0005391848972067237. Test_MSE: [[[ 0.0319967   0.02464679  0.0049508   0.00210849]]]\n",
      "Epoch: 322 Iteration: 30000. Train_MSE: 0.000695421127602458. Test_MSE: [[[ 0.03197861  0.02463824  0.004951    0.00210664]]]\n",
      "Epoch: 323 Iteration: 30100. Train_MSE: 0.0010098214261233807. Test_MSE: [[[ 0.03195861  0.02463013  0.00495136  0.00210513]]]\n",
      "Epoch: 324 Iteration: 30200. Train_MSE: 0.0010416745208203793. Test_MSE: [[[ 0.03193842  0.02462183  0.00495146  0.00210401]]]\n",
      "Epoch: 325 Iteration: 30300. Train_MSE: 0.000944881874602288. Test_MSE: [[[ 0.03191891  0.02461522  0.00495125  0.0021031 ]]]\n",
      "Epoch: 326 Iteration: 30400. Train_MSE: 0.0028290709014981985. Test_MSE: [[[ 0.03189889  0.02460542  0.00495113  0.00210236]]]\n",
      "Epoch: 327 Iteration: 30500. Train_MSE: 0.0006215700996108353. Test_MSE: [[[ 0.03188075  0.02459847  0.00495114  0.00210102]]]\n",
      "Epoch: 329 Iteration: 30600. Train_MSE: 0.0005766486283391714. Test_MSE: [[[ 0.03186408  0.02459018  0.00495125  0.00209914]]]\n",
      "Epoch: 330 Iteration: 30700. Train_MSE: 0.0009606304811313748. Test_MSE: [[[ 0.03184651  0.02458228  0.00495146  0.00209764]]]\n",
      "Epoch: 331 Iteration: 30800. Train_MSE: 0.002161176409572363. Test_MSE: [[[ 0.03182676  0.02457417  0.00495185  0.00209629]]]\n",
      "Epoch: 332 Iteration: 30900. Train_MSE: 0.0007633868372067809. Test_MSE: [[[ 0.0318075   0.02456806  0.00495177  0.00209531]]]\n",
      "Epoch: 333 Iteration: 31000. Train_MSE: 0.00189316482283175. Test_MSE: [[[ 0.03178835  0.02455996  0.0049516   0.00209464]]]\n",
      "Epoch: 334 Iteration: 31100. Train_MSE: 0.0006770892650820315. Test_MSE: [[[ 0.03176918  0.02455252  0.00495132  0.00209384]]]\n",
      "Epoch: 335 Iteration: 31200. Train_MSE: 0.0004342577885836363. Test_MSE: [[[ 0.0317519   0.02454483  0.00495144  0.00209237]]]\n",
      "Epoch: 336 Iteration: 31300. Train_MSE: 0.0006227954290807247. Test_MSE: [[[ 0.03173527  0.02453668  0.0049516   0.00209061]]]\n",
      "Epoch: 337 Iteration: 31400. Train_MSE: 0.0008490753243677318. Test_MSE: [[[ 0.03171669  0.02452925  0.00495191  0.00208909]]]\n",
      "Epoch: 338 Iteration: 31500. Train_MSE: 0.0011800923384726048. Test_MSE: [[[ 0.0316976   0.02452049  0.00495216  0.00208797]]]\n",
      "Epoch: 339 Iteration: 31600. Train_MSE: 0.000652225106023252. Test_MSE: [[[ 0.03167875  0.02451437  0.00495199  0.00208705]]]\n",
      "Epoch: 340 Iteration: 31700. Train_MSE: 0.000642173457890749. Test_MSE: [[[ 0.03165976  0.02450553  0.0049517   0.00208643]]]\n",
      "Epoch: 341 Iteration: 31800. Train_MSE: 0.0010310233337804675. Test_MSE: [[[ 0.03164219  0.0244989   0.00495168  0.00208547]]]\n",
      "Epoch: 343 Iteration: 31900. Train_MSE: 0.0004644411674235016. Test_MSE: [[[ 0.03162624  0.02449089  0.00495176  0.00208376]]]\n",
      "Epoch: 344 Iteration: 32000. Train_MSE: 0.0009295426425524056. Test_MSE: [[[ 0.03161021  0.02448333  0.00495202  0.00208219]]]\n",
      "Epoch: 345 Iteration: 32100. Train_MSE: 0.0013495540479198098. Test_MSE: [[[ 0.03159153  0.02447632  0.0049522   0.00208084]]]\n",
      "Epoch: 346 Iteration: 32200. Train_MSE: 0.001051712897606194. Test_MSE: [[[ 0.03157313  0.02446934  0.00495237  0.00207995]]]\n",
      "Epoch: 347 Iteration: 32300. Train_MSE: 0.0011360286734998226. Test_MSE: [[[ 0.03155549  0.02446259  0.00495217  0.0020793 ]]]\n",
      "Epoch: 348 Iteration: 32400. Train_MSE: 0.01228040549904108. Test_MSE: [[[ 0.03153628  0.02445492  0.0049517   0.00207871]]]\n",
      "Epoch: 349 Iteration: 32500. Train_MSE: 0.0005639560986310244. Test_MSE: [[[ 0.03151956  0.02444782  0.00495177  0.00207762]]]\n",
      "Epoch: 350 Iteration: 32600. Train_MSE: 0.000634246040135622. Test_MSE: [[[ 0.03150384  0.02444027  0.00495193  0.00207593]]]\n",
      "Epoch: 351 Iteration: 32700. Train_MSE: 0.0013577486388385296. Test_MSE: [[[ 0.03148664  0.02443283  0.00495217  0.00207443]]]\n",
      "Epoch: 352 Iteration: 32800. Train_MSE: 0.0029874881729483604. Test_MSE: [[[ 0.03146822  0.02442487  0.00495227  0.00207328]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 353 Iteration: 32900. Train_MSE: 0.0007975116604939103. Test_MSE: [[[ 0.03145034  0.02441899  0.00495218  0.00207239]]]\n",
      "Epoch: 354 Iteration: 33000. Train_MSE: 0.010535540990531445. Test_MSE: [[[ 0.03143211  0.02441042  0.00495195  0.00207182]]]\n",
      "Epoch: 355 Iteration: 33100. Train_MSE: 0.0007590075838379562. Test_MSE: [[[ 0.03141536  0.02440394  0.00495187  0.0020711 ]]]\n",
      "Epoch: 356 Iteration: 33200. Train_MSE: 0.00045473803766071796. Test_MSE: [[[ 0.03139975  0.02439656  0.00495192  0.0020697 ]]]\n",
      "Epoch: 358 Iteration: 33300. Train_MSE: 0.0008586785988882184. Test_MSE: [[[ 0.03138474  0.02438921  0.00495206  0.00206812]]]\n",
      "Epoch: 359 Iteration: 33400. Train_MSE: 0.0007633189670741558. Test_MSE: [[[ 0.0313678   0.0243825   0.00495226  0.00206689]]]\n",
      "Epoch: 360 Iteration: 33500. Train_MSE: 0.00074963946826756. Test_MSE: [[[ 0.03134969  0.02437579  0.00495235  0.00206592]]]\n",
      "Epoch: 361 Iteration: 33600. Train_MSE: 0.0007548191351816058. Test_MSE: [[[ 0.03133286  0.02437002  0.00495213  0.00206525]]]\n",
      "Epoch: 362 Iteration: 33700. Train_MSE: 0.001071046106517315. Test_MSE: [[[ 0.03131543  0.0243628   0.00495185  0.00206475]]]\n",
      "Epoch: 363 Iteration: 33800. Train_MSE: 0.00470058573409915. Test_MSE: [[[ 0.03129809  0.02435554  0.00495166  0.00206405]]]\n",
      "Epoch: 364 Iteration: 33900. Train_MSE: 0.0004897632752545178. Test_MSE: [[[ 0.03128341  0.02434839  0.00495181  0.00206242]]]\n",
      "Epoch: 365 Iteration: 34000. Train_MSE: 0.0013533602468669415. Test_MSE: [[[ 0.03126771  0.02434107  0.00495196  0.002061  ]]]\n",
      "Epoch: 366 Iteration: 34100. Train_MSE: 0.0008999553392641246. Test_MSE: [[[ 0.03125016  0.02433446  0.0049522   0.00205974]]]\n",
      "Epoch: 367 Iteration: 34200. Train_MSE: 0.0008626655326224864. Test_MSE: [[[ 0.03123292  0.02432768  0.00495209  0.002059  ]]]\n",
      "Epoch: 368 Iteration: 34300. Train_MSE: 0.0006892189849168062. Test_MSE: [[[ 0.03121648  0.02432144  0.00495189  0.00205839]]]\n",
      "Epoch: 369 Iteration: 34400. Train_MSE: 0.0007074182503856719. Test_MSE: [[[ 0.03119932  0.02431334  0.00495168  0.0020579 ]]]\n",
      "Epoch: 370 Iteration: 34500. Train_MSE: 0.0005683305789716542. Test_MSE: [[[ 0.03118393  0.02430699  0.00495166  0.00205676]]]\n",
      "Epoch: 372 Iteration: 34600. Train_MSE: 0.0005602987948805094. Test_MSE: [[[ 0.03116994  0.02429982  0.00495176  0.00205524]]]\n",
      "Epoch: 373 Iteration: 34700. Train_MSE: 0.0011122345458716154. Test_MSE: [[[ 0.03115444  0.02429316  0.0049519   0.00205403]]]\n",
      "Epoch: 374 Iteration: 34800. Train_MSE: 0.00144548702519387. Test_MSE: [[[ 0.0311373   0.02428653  0.0049521   0.00205303]]]\n",
      "Epoch: 375 Iteration: 34900. Train_MSE: 0.0009212392033077776. Test_MSE: [[[ 0.03112147  0.02428137  0.00495203  0.00205235]]]\n",
      "Epoch: 376 Iteration: 35000. Train_MSE: 0.0007542063249275088. Test_MSE: [[[ 0.03110511  0.02427433  0.00495176  0.00205195]]]\n",
      "Epoch: 377 Iteration: 35100. Train_MSE: 0.0006705372943542898. Test_MSE: [[[ 0.0310887   0.0242678   0.0049515   0.00205138]]]\n",
      "Epoch: 378 Iteration: 35200. Train_MSE: 0.0005364603130146861. Test_MSE: [[[ 0.03107416  0.02426101  0.00495157  0.0020501 ]]]\n",
      "Epoch: 379 Iteration: 35300. Train_MSE: 0.000714422611054033. Test_MSE: [[[ 0.03105965  0.0242539   0.00495168  0.00204866]]]\n",
      "Epoch: 380 Iteration: 35400. Train_MSE: 0.0008998658740893006. Test_MSE: [[[ 0.03104354  0.0242475   0.00495192  0.00204748]]]\n",
      "Epoch: 381 Iteration: 35500. Train_MSE: 0.0008017450454644859. Test_MSE: [[[ 0.03102715  0.02424048  0.00495201  0.00204665]]]\n",
      "Epoch: 382 Iteration: 35600. Train_MSE: 0.0008202363387681544. Test_MSE: [[[ 0.03101115  0.02423527  0.00495174  0.00204604]]]\n",
      "Epoch: 383 Iteration: 35700. Train_MSE: 0.0006647186819463968. Test_MSE: [[[ 0.03099485  0.02422724  0.00495146  0.00204564]]]\n",
      "Epoch: 384 Iteration: 35800. Train_MSE: 0.0006810869090259075. Test_MSE: [[[ 0.03097991  0.0242213   0.00495141  0.00204483]]]\n",
      "Epoch: 386 Iteration: 35900. Train_MSE: 0.0005485977162607014. Test_MSE: [[[ 0.03096639  0.0242144   0.00495143  0.00204341]]]\n",
      "Epoch: 387 Iteration: 36000. Train_MSE: 0.002523558447137475. Test_MSE: [[[ 0.03095219  0.02420772  0.00495156  0.00204225]]]\n",
      "Epoch: 388 Iteration: 36100. Train_MSE: 0.0016994304023683071. Test_MSE: [[[ 0.0309363   0.0242016   0.00495179  0.00204114]]]\n",
      "Epoch: 389 Iteration: 36200. Train_MSE: 0.0006690884474664927. Test_MSE: [[[ 0.03092061  0.02419647  0.00495176  0.00204048]]]\n",
      "Epoch: 390 Iteration: 36300. Train_MSE: 0.009336302056908607. Test_MSE: [[[ 0.03090497  0.02418999  0.00495146  0.00204013]]]\n",
      "Epoch: 391 Iteration: 36400. Train_MSE: 0.0006494990666396916. Test_MSE: [[[ 0.03088912  0.02418371  0.00495109  0.00203968]]]\n",
      "Epoch: 392 Iteration: 36500. Train_MSE: 0.0006274241022765636. Test_MSE: [[[ 0.03087487  0.02417736  0.00495117  0.00203871]]]\n",
      "Epoch: 393 Iteration: 36600. Train_MSE: 0.0007845775689929724. Test_MSE: [[[ 0.03086164  0.02417055  0.0049513   0.00203734]]]\n",
      "Epoch: 394 Iteration: 36700. Train_MSE: 0.0007478818297386169. Test_MSE: [[[ 0.03084642  0.0241643   0.00495147  0.00203615]]]\n",
      "Epoch: 395 Iteration: 36800. Train_MSE: 0.0009737639338709414. Test_MSE: [[[ 0.03083069  0.0241574   0.00495156  0.00203527]]]\n",
      "Epoch: 396 Iteration: 36900. Train_MSE: 0.0007077018381096423. Test_MSE: [[[ 0.03081535  0.02415248  0.00495142  0.00203463]]]\n",
      "Epoch: 397 Iteration: 37000. Train_MSE: 0.0005440565291792154. Test_MSE: [[[ 0.03079974  0.02414497  0.00495113  0.00203428]]]\n",
      "Epoch: 398 Iteration: 37100. Train_MSE: 0.0005320544587448239. Test_MSE: [[[ 0.03078544  0.02413944  0.00495105  0.00203371]]]\n",
      "Epoch: 399 Iteration: 37200. Train_MSE: 0.000583326502237469. Test_MSE: [[[ 0.03077231  0.02413277  0.00495106  0.00203249]]]\n",
      "Epoch: 401 Iteration: 37300. Train_MSE: 0.0005340601201169193. Test_MSE: [[[ 0.03075956  0.02412649  0.00495122  0.00203121]]]\n",
      "Epoch: 402 Iteration: 37400. Train_MSE: 0.0008397627389058471. Test_MSE: [[[ 0.03074485  0.02412096  0.00495134  0.00203022]]]\n",
      "Epoch: 403 Iteration: 37500. Train_MSE: 0.001078296103514731. Test_MSE: [[[ 0.03072941  0.02411493  0.00495147  0.00202953]]]\n",
      "Epoch: 404 Iteration: 37600. Train_MSE: 0.0009348181774839759. Test_MSE: [[[ 0.03071491  0.02411029  0.00495114  0.00202907]]]\n",
      "Epoch: 405 Iteration: 37700. Train_MSE: 0.0009375233203172684. Test_MSE: [[[ 0.03069979  0.02410419  0.00495078  0.00202873]]]\n",
      "Epoch: 406 Iteration: 37800. Train_MSE: 0.0007420741021633148. Test_MSE: [[[ 0.03068536  0.02409756  0.00495068  0.00202816]]]\n",
      "Epoch: 407 Iteration: 37900. Train_MSE: 0.0021353652700781822. Test_MSE: [[[ 0.03067267  0.02409121  0.0049508   0.00202683]]]\n",
      "Epoch: 408 Iteration: 38000. Train_MSE: 0.0007430062396451831. Test_MSE: [[[ 0.03065912  0.02408515  0.00495096  0.00202563]]]\n",
      "Epoch: 409 Iteration: 38100. Train_MSE: 0.006299993954598904. Test_MSE: [[[ 0.03064365  0.02407914  0.00495099  0.00202465]]]\n",
      "Epoch: 410 Iteration: 38200. Train_MSE: 0.0006740301614627242. Test_MSE: [[[ 0.03062913  0.02407386  0.00495098  0.00202407]]]\n",
      "Epoch: 411 Iteration: 38300. Train_MSE: 0.0015234294114634395. Test_MSE: [[[ 0.03061469  0.02406761  0.0049507   0.00202369]]]\n",
      "Epoch: 412 Iteration: 38400. Train_MSE: 0.0005227900110185146. Test_MSE: [[[ 0.03060046  0.0240612   0.00495053  0.00202335]]]\n",
      "Epoch: 413 Iteration: 38500. Train_MSE: 0.0006902547902427614. Test_MSE: [[[ 0.03058744  0.02405515  0.00495055  0.00202234]]]\n",
      "Epoch: 415 Iteration: 38600. Train_MSE: 0.0004968034336343408. Test_MSE: [[[ 0.03057538  0.02404908  0.00495062  0.00202104]]]\n",
      "Epoch: 416 Iteration: 38700. Train_MSE: 0.0006978162564337254. Test_MSE: [[[ 0.03056163  0.02404361  0.00495071  0.00202007]]]\n",
      "Epoch: 417 Iteration: 38800. Train_MSE: 0.0010421662591397762. Test_MSE: [[[ 0.03054686  0.02403822  0.00495079  0.00201932]]]\n",
      "Epoch: 418 Iteration: 38900. Train_MSE: 0.0007303421152755618. Test_MSE: [[[ 0.03053321  0.02403367  0.00495059  0.00201886]]]\n",
      "Epoch: 419 Iteration: 39000. Train_MSE: 0.0007181085529737175. Test_MSE: [[[ 0.03051921  0.02402761  0.00495031  0.00201864]]]\n",
      "Epoch: 420 Iteration: 39100. Train_MSE: 0.0007594587514176965. Test_MSE: [[[ 0.03050485  0.02402153  0.0049501   0.00201822]]]\n",
      "Epoch: 421 Iteration: 39200. Train_MSE: 0.00043722326518036425. Test_MSE: [[[ 0.0304925   0.02401546  0.00495016  0.00201704]]]\n",
      "Epoch: 422 Iteration: 39300. Train_MSE: 0.0005413985345512629. Test_MSE: [[[ 0.03047989  0.02400933  0.00495024  0.00201585]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 423 Iteration: 39400. Train_MSE: 0.0007836707518436015. Test_MSE: [[[ 0.03046568  0.02400377  0.00495044  0.00201491]]]\n",
      "Epoch: 424 Iteration: 39500. Train_MSE: 0.0008063673158176243. Test_MSE: [[[ 0.03045132  0.02399808  0.00495038  0.00201432]]]\n",
      "Epoch: 425 Iteration: 39600. Train_MSE: 0.0007639199029654264. Test_MSE: [[[ 0.03043764  0.02399351  0.00495005  0.00201392]]]\n",
      "Epoch: 426 Iteration: 39700. Train_MSE: 0.0026077525690197945. Test_MSE: [[[ 0.03042339  0.02398574  0.00494985  0.00201369]]]\n",
      "Epoch: 427 Iteration: 39800. Train_MSE: 0.0004951210576109588. Test_MSE: [[[ 0.0304107   0.02398083  0.00494977  0.00201293]]]\n",
      "Epoch: 429 Iteration: 39900. Train_MSE: 0.00047938100760802627. Test_MSE: [[[ 0.03039923  0.02397477  0.00494979  0.00201172]]]\n",
      "Epoch: 430 Iteration: 40000. Train_MSE: 0.0007801228202879429. Test_MSE: [[[ 0.03038703  0.02396923  0.00494988  0.00201079]]]\n",
      "Epoch: 431 Iteration: 40100. Train_MSE: 0.0019208837766200304. Test_MSE: [[[ 0.03037297  0.02396374  0.00495008  0.00200996]]]\n",
      "Epoch: 432 Iteration: 40200. Train_MSE: 0.0005899343523196876. Test_MSE: [[[ 0.03035949  0.02395992  0.00494986  0.00200945]]]\n",
      "Epoch: 433 Iteration: 40300. Train_MSE: 0.0017147086327895522. Test_MSE: [[[ 0.03034599  0.0239539   0.0049496   0.00200924]]]\n",
      "Epoch: 434 Iteration: 40400. Train_MSE: 0.0005306366947479546. Test_MSE: [[[ 0.03033236  0.02394822  0.00494928  0.00200894]]]\n",
      "Epoch: 435 Iteration: 40500. Train_MSE: 0.00036144882324151695. Test_MSE: [[[ 0.03032021  0.02394257  0.00494931  0.00200805]]]\n",
      "Epoch: 436 Iteration: 40600. Train_MSE: 0.0005056076915934682. Test_MSE: [[[ 0.03030861  0.02393661  0.00494938  0.0020069 ]]]\n",
      "Epoch: 437 Iteration: 40700. Train_MSE: 0.0006649366696365178. Test_MSE: [[[ 0.03029537  0.02393142  0.00494956  0.00200592]]]\n",
      "Epoch: 438 Iteration: 40800. Train_MSE: 0.0009854449890553951. Test_MSE: [[[ 0.0302817   0.02392525  0.00494966  0.00200527]]]\n",
      "Epoch: 439 Iteration: 40900. Train_MSE: 0.0005083881551399827. Test_MSE: [[[ 0.03026843  0.02392115  0.00494939  0.00200481]]]\n",
      "Epoch: 440 Iteration: 41000. Train_MSE: 0.0005078417016193271. Test_MSE: [[[ 0.03025489  0.02391406  0.00494905  0.00200463]]]\n",
      "Epoch: 441 Iteration: 41100. Train_MSE: 0.0008518400136381388. Test_MSE: [[[ 0.03024247  0.02390924  0.00494895  0.00200415]]]\n",
      "Epoch: 443 Iteration: 41200. Train_MSE: 0.000390119559597224. Test_MSE: [[[ 0.03023141  0.02390329  0.00494895  0.00200304]]]\n",
      "Epoch: 444 Iteration: 41300. Train_MSE: 0.000768060446716845. Test_MSE: [[[ 0.03022029  0.02389789  0.0049491   0.00200202]]]\n",
      "Epoch: 445 Iteration: 41400. Train_MSE: 0.0011200009612366557. Test_MSE: [[[ 0.03020697  0.02389314  0.00494915  0.00200114]]]\n",
      "Epoch: 446 Iteration: 41500. Train_MSE: 0.0008461138349957764. Test_MSE: [[[ 0.03019396  0.02388856  0.00494916  0.00200068]]]\n",
      "Epoch: 447 Iteration: 41600. Train_MSE: 0.0010000208858400583. Test_MSE: [[[ 0.03018161  0.02388372  0.00494887  0.00200043]]]\n",
      "Epoch: 448 Iteration: 41700. Train_MSE: 0.012070557102560997. Test_MSE: [[[ 0.03016779  0.02387771  0.0049484   0.00200027]]]\n",
      "Epoch: 449 Iteration: 41800. Train_MSE: 0.00044937830534763634. Test_MSE: [[[ 0.03015597  0.02387244  0.00494839  0.00199966]]]\n",
      "Epoch: 450 Iteration: 41900. Train_MSE: 0.0005135053652338684. Test_MSE: [[[ 0.03014499  0.02386688  0.00494847  0.00199855]]]\n",
      "Epoch: 451 Iteration: 42000. Train_MSE: 0.0011366704711690545. Test_MSE: [[[ 0.03013276  0.02386151  0.00494861  0.00199755]]]\n",
      "Epoch: 452 Iteration: 42100. Train_MSE: 0.0027290680445730686. Test_MSE: [[[ 0.03011944  0.02385581  0.0049486   0.00199684]]]\n",
      "Epoch: 453 Iteration: 42200. Train_MSE: 0.0006227209814824164. Test_MSE: [[[ 0.03010676  0.02385193  0.00494842  0.00199635]]]\n",
      "Epoch: 454 Iteration: 42300. Train_MSE: 0.010396678000688553. Test_MSE: [[[ 0.03009375  0.02384515  0.00494813  0.00199617]]]\n",
      "Epoch: 455 Iteration: 42400. Train_MSE: 0.0006090827519074082. Test_MSE: [[[ 0.03008189  0.0238403   0.004948    0.00199586]]]\n",
      "Epoch: 456 Iteration: 42500. Train_MSE: 0.000383076403522864. Test_MSE: [[[ 0.03007098  0.0238348   0.00494798  0.00199497]]]\n",
      "Epoch: 458 Iteration: 42600. Train_MSE: 0.0006927794311195612. Test_MSE: [[[ 0.0300606   0.02382941  0.00494806  0.0019939 ]]]\n",
      "Epoch: 459 Iteration: 42700. Train_MSE: 0.0005697861779481173. Test_MSE: [[[ 0.03004861  0.02382474  0.00494816  0.00199311]]]\n",
      "Epoch: 460 Iteration: 42800. Train_MSE: 0.0006115876603871584. Test_MSE: [[[ 0.03003564  0.02382024  0.00494813  0.00199253]]]\n",
      "Epoch: 461 Iteration: 42900. Train_MSE: 0.0006026782793924212. Test_MSE: [[[ 0.03002387  0.02381635  0.00494785  0.00199222]]]\n",
      "Epoch: 462 Iteration: 43000. Train_MSE: 0.0009019635617733002. Test_MSE: [[[ 0.03001142  0.02381075  0.00494754  0.00199209]]]\n",
      "Epoch: 463 Iteration: 43100. Train_MSE: 0.004610786680132151. Test_MSE: [[[ 0.02999893  0.02380508  0.00494732  0.0019918 ]]]\n",
      "Epoch: 464 Iteration: 43200. Train_MSE: 0.00040823753806762397. Test_MSE: [[[ 0.0299887   0.02379978  0.00494742  0.00199069]]]\n",
      "Epoch: 465 Iteration: 43300. Train_MSE: 0.001209939131513238. Test_MSE: [[[ 0.02997757  0.02379435  0.0049475   0.00198975]]]\n",
      "Epoch: 466 Iteration: 43400. Train_MSE: 0.000726506463252008. Test_MSE: [[[ 0.02996491  0.02378977  0.00494764  0.00198889]]]\n",
      "Epoch: 467 Iteration: 43500. Train_MSE: 0.0006995847797952592. Test_MSE: [[[ 0.02995248  0.02378497  0.00494745  0.00198852]]]\n",
      "Epoch: 468 Iteration: 43600. Train_MSE: 0.0005770612042397261. Test_MSE: [[[ 0.02994083  0.02378036  0.00494717  0.00198827]]]\n",
      "Epoch: 469 Iteration: 43700. Train_MSE: 0.0005386335542425513. Test_MSE: [[[ 0.02992845  0.02377378  0.00494694  0.00198813]]]\n",
      "Epoch: 470 Iteration: 43800. Train_MSE: 0.00046801712596789. Test_MSE: [[[ 0.02991752  0.02376907  0.00494687  0.00198743]]]\n",
      "Epoch: 472 Iteration: 43900. Train_MSE: 0.0004514056781772524. Test_MSE: [[[ 0.02990776  0.02376369  0.00494689  0.0019864 ]]]\n",
      "Epoch: 473 Iteration: 44000. Train_MSE: 0.0009173050639219582. Test_MSE: [[[ 0.02989672  0.02375891  0.00494693  0.00198561]]]\n",
      "Epoch: 474 Iteration: 44100. Train_MSE: 0.0012382763670757413. Test_MSE: [[[ 0.02988431  0.02375437  0.00494699  0.00198497]]]\n",
      "Epoch: 475 Iteration: 44200. Train_MSE: 0.0007233452633954585. Test_MSE: [[[ 0.02987313  0.02375105  0.00494682  0.00198462]]]\n",
      "Epoch: 476 Iteration: 44300. Train_MSE: 0.0006044891779311001. Test_MSE: [[[ 0.02986135  0.02374557  0.00494649  0.00198454]]]\n",
      "Epoch: 477 Iteration: 44400. Train_MSE: 0.000555388571228832. Test_MSE: [[[ 0.02984942  0.02374042  0.0049462   0.00198433]]]\n",
      "Epoch: 478 Iteration: 44500. Train_MSE: 0.0004340727173257619. Test_MSE: [[[ 0.02983902  0.02373528  0.00494621  0.00198351]]]\n",
      "Epoch: 479 Iteration: 44600. Train_MSE: 0.0005767411203123629. Test_MSE: [[[ 0.02982868  0.02372993  0.00494624  0.00198252]]]\n",
      "Epoch: 480 Iteration: 44700. Train_MSE: 0.0007339391740970314. Test_MSE: [[[ 0.02981699  0.02372533  0.00494638  0.00198172]]]\n",
      "Epoch: 481 Iteration: 44800. Train_MSE: 0.0006694546318612993. Test_MSE: [[[ 0.02980503  0.0237203   0.00494636  0.00198123]]]\n",
      "Epoch: 482 Iteration: 44900. Train_MSE: 0.0007021608762443066. Test_MSE: [[[ 0.02979361  0.02371667  0.00494603  0.00198093]]]\n",
      "Epoch: 483 Iteration: 45000. Train_MSE: 0.0005330339190550148. Test_MSE: [[[ 0.0297818   0.02371003  0.00494574  0.00198085]]]\n",
      "Epoch: 484 Iteration: 45100. Train_MSE: 0.0005657087895087898. Test_MSE: [[[ 0.0297711   0.0237056   0.00494563  0.00198039]]]\n",
      "Epoch: 486 Iteration: 45200. Train_MSE: 0.0004600321117322892. Test_MSE: [[[ 0.0297616   0.02370035  0.0049456   0.00197943]]]\n",
      "Epoch: 487 Iteration: 45300. Train_MSE: 0.0023616119287908077. Test_MSE: [[[ 0.02975158  0.02369544  0.00494565  0.00197866]]]\n",
      "Epoch: 488 Iteration: 45400. Train_MSE: 0.0015000521671026945. Test_MSE: [[[ 0.02974011  0.02369123  0.00494576  0.0019779 ]]]\n",
      "Epoch: 489 Iteration: 45500. Train_MSE: 0.0005373060121200979. Test_MSE: [[[ 0.02972888  0.02368789  0.00494562  0.00197755]]]\n",
      "Epoch: 490 Iteration: 45600. Train_MSE: 0.009188111871480942. Test_MSE: [[[ 0.02971762  0.02368293  0.00494525  0.00197748]]]\n",
      "Epoch: 491 Iteration: 45700. Train_MSE: 0.0005005951388739049. Test_MSE: [[[ 0.02970609  0.02367792  0.00494487  0.00197735]]]\n",
      "Epoch: 492 Iteration: 45800. Train_MSE: 0.0005386074772104621. Test_MSE: [[[ 0.02969584  0.02367306  0.00494487  0.00197675]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 493 Iteration: 45900. Train_MSE: 0.0006493161781691015. Test_MSE: [[[ 0.02968646  0.02366788  0.00494493  0.00197581]]]\n",
      "Epoch: 494 Iteration: 46000. Train_MSE: 0.0006205200916156173. Test_MSE: [[[ 0.02967536  0.02366326  0.00494501  0.00197499]]]\n",
      "Epoch: 495 Iteration: 46100. Train_MSE: 0.0008477919618599117. Test_MSE: [[[ 0.02966376  0.02365824  0.00494498  0.00197444]]]\n",
      "Epoch: 496 Iteration: 46200. Train_MSE: 0.0005887907464057207. Test_MSE: [[[ 0.02965269  0.02365484  0.00494476  0.00197409]]]\n",
      "Epoch: 497 Iteration: 46300. Train_MSE: 0.0004331858071964234. Test_MSE: [[[ 0.02964137  0.02364872  0.00494443  0.00197401]]]\n",
      "Epoch: 498 Iteration: 46400. Train_MSE: 0.00043392053339630365. Test_MSE: [[[ 0.02963106  0.02364444  0.00494429  0.00197375]]]\n",
      "Epoch: 499 Iteration: 46500. Train_MSE: 0.0005021581309847534. Test_MSE: [[[ 0.02962174  0.02363931  0.00494424  0.00197293]]]\n",
      "Epoch: 501 Iteration: 46600. Train_MSE: 0.0004287062620278448. Test_MSE: [[[ 0.02961277  0.02363462  0.00494432  0.00197205]]]\n",
      "Epoch: 502 Iteration: 46700. Train_MSE: 0.0006911405944265425. Test_MSE: [[[ 0.02960211  0.02363072  0.00494435  0.00197137]]]\n",
      "Epoch: 503 Iteration: 46800. Train_MSE: 0.0008741161436773837. Test_MSE: [[[ 0.02959085  0.0236265   0.00494434  0.00197097]]]\n",
      "Epoch: 504 Iteration: 46900. Train_MSE: 0.0008106681052595377. Test_MSE: [[[ 0.02958048  0.02362323  0.00494394  0.00197077]]]\n",
      "Epoch: 505 Iteration: 47000. Train_MSE: 0.0008024050039239228. Test_MSE: [[[ 0.02956937  0.02361832  0.00494355  0.00197071]]]\n",
      "Epoch: 506 Iteration: 47100. Train_MSE: 0.0006037999992258847. Test_MSE: [[[ 0.02955876  0.02361301  0.00494339  0.00197046]]]\n",
      "Epoch: 507 Iteration: 47200. Train_MSE: 0.0020802542567253113. Test_MSE: [[[ 0.02954963  0.02360814  0.00494343  0.00196953]]]\n",
      "Epoch: 508 Iteration: 47300. Train_MSE: 0.0006289381417445838. Test_MSE: [[[ 0.02953978  0.02360356  0.0049435   0.00196869]]]\n",
      "Epoch: 509 Iteration: 47400. Train_MSE: 0.0061001162976026535. Test_MSE: [[[ 0.02952826  0.02359915  0.00494342  0.00196802]]]\n",
      "Epoch: 510 Iteration: 47500. Train_MSE: 0.0005576061666943133. Test_MSE: [[[ 0.02951769  0.02359548  0.00494331  0.00196772]]]\n",
      "Epoch: 511 Iteration: 47600. Train_MSE: 0.0014295808505266905. Test_MSE: [[[ 0.02950724  0.02359046  0.00494297  0.00196759]]]\n",
      "Epoch: 512 Iteration: 47700. Train_MSE: 0.00041473578312434256. Test_MSE: [[[ 0.02949679  0.02358524  0.00494274  0.00196751]]]\n",
      "Epoch: 513 Iteration: 47800. Train_MSE: 0.0005835366901010275. Test_MSE: [[[ 0.02948741  0.02358056  0.0049427   0.00196686]]]\n",
      "Epoch: 515 Iteration: 47900. Train_MSE: 0.0004191241750959307. Test_MSE: [[[ 0.02947889  0.02357592  0.0049427   0.00196594]]]\n",
      "Epoch: 516 Iteration: 48000. Train_MSE: 0.0005753072910010815. Test_MSE: [[[ 0.02946891  0.02357193  0.00494269  0.00196528]]]\n",
      "Epoch: 517 Iteration: 48100. Train_MSE: 0.0009137216839008033. Test_MSE: [[[ 0.02945808  0.02356821  0.00494265  0.00196479]]]\n",
      "Epoch: 518 Iteration: 48200. Train_MSE: 0.0006247496348805726. Test_MSE: [[[ 0.0294483   0.02356509  0.00494238  0.00196457]]]\n",
      "Epoch: 519 Iteration: 48300. Train_MSE: 0.0005794905591756105. Test_MSE: [[[ 0.02943806  0.02356021  0.00494203  0.00196459]]]\n",
      "Epoch: 520 Iteration: 48400. Train_MSE: 0.0006715480703860521. Test_MSE: [[[ 0.02942746  0.02355526  0.0049418   0.00196444]]]\n",
      "Epoch: 521 Iteration: 48500. Train_MSE: 0.0003716638311743736. Test_MSE: [[[ 0.02941856  0.02355053  0.0049418   0.00196362]]]\n",
      "Epoch: 522 Iteration: 48600. Train_MSE: 0.00044455548049882054. Test_MSE: [[[ 0.02940943  0.02354581  0.00494181  0.00196277]]]\n",
      "Epoch: 523 Iteration: 48700. Train_MSE: 0.0006413289811462164. Test_MSE: [[[ 0.02939893  0.02354176  0.00494191  0.00196212]]]\n",
      "Epoch: 524 Iteration: 48800. Train_MSE: 0.0006648054695688188. Test_MSE: [[[ 0.02938832  0.0235376   0.00494175  0.00196178]]]\n",
      "Epoch: 525 Iteration: 48900. Train_MSE: 0.0006619457853958011. Test_MSE: [[[ 0.02937847  0.02353422  0.00494139  0.00196161]]]\n",
      "Epoch: 526 Iteration: 49000. Train_MSE: 0.002470501000061631. Test_MSE: [[[ 0.02936785  0.02352764  0.00494114  0.0019616 ]]]\n",
      "Epoch: 527 Iteration: 49100. Train_MSE: 0.0004192821215838194. Test_MSE: [[[ 0.02935865  0.02352388  0.00494101  0.00196115]]]\n",
      "Epoch: 529 Iteration: 49200. Train_MSE: 0.00041988876182585955. Test_MSE: [[[ 0.02935048  0.02351917  0.00494096  0.00196028]]]\n",
      "Epoch: 530 Iteration: 49300. Train_MSE: 0.0006659965147264302. Test_MSE: [[[ 0.02934172  0.02351505  0.00494096  0.00195965]]]\n",
      "Epoch: 531 Iteration: 49400. Train_MSE: 0.0017782581271603703. Test_MSE: [[[ 0.02933135  0.02351116  0.00494104  0.00195907]]]\n",
      "Epoch: 532 Iteration: 49500. Train_MSE: 0.00048722478095442057. Test_MSE: [[[ 0.02932157  0.02350871  0.00494074  0.00195879]]]\n",
      "Epoch: 533 Iteration: 49600. Train_MSE: 0.0016126759583130479. Test_MSE: [[[ 0.02931163  0.02350393  0.0049404   0.00195879]]]\n",
      "Epoch: 534 Iteration: 49700. Train_MSE: 0.0004396120202727616. Test_MSE: [[[ 0.02930153  0.02349925  0.00494006  0.00195873]]]\n",
      "Epoch: 535 Iteration: 49800. Train_MSE: 0.0003178123151883483. Test_MSE: [[[ 0.02929264  0.02349484  0.00494002  0.00195816]]]\n",
      "Epoch: 536 Iteration: 49900. Train_MSE: 0.0004339088045526296. Test_MSE: [[[ 0.02928426  0.02349019  0.00494001  0.00195734]]]\n",
      "Epoch: 537 Iteration: 50000. Train_MSE: 0.0005511760246008635. Test_MSE: [[[ 0.02927446  0.02348635  0.0049401   0.00195664]]]\n",
      "Epoch: 538 Iteration: 50100. Train_MSE: 0.0008691962575539947. Test_MSE: [[[ 0.0292642   0.02348176  0.00494008  0.00195623]]]\n",
      "Epoch: 539 Iteration: 50200. Train_MSE: 0.00042559244320727885. Test_MSE: [[[ 0.02925451  0.02347886  0.00493974  0.00195598]]]\n",
      "Epoch: 540 Iteration: 50300. Train_MSE: 0.0004326764028519392. Test_MSE: [[[ 0.02924446  0.02347283  0.00493937  0.001956  ]]]\n",
      "Epoch: 541 Iteration: 50400. Train_MSE: 0.0007385206408798695. Test_MSE: [[[ 0.02923534  0.02346909  0.00493921  0.00195577]]]\n",
      "Epoch: 543 Iteration: 50500. Train_MSE: 0.00034442113246768713. Test_MSE: [[[ 0.0292274   0.02346441  0.00493915  0.00195498]]]\n",
      "Epoch: 544 Iteration: 50600. Train_MSE: 0.0006681974045932293. Test_MSE: [[[ 0.02921946  0.02346035  0.00493923  0.00195426]]]\n",
      "Epoch: 545 Iteration: 50700. Train_MSE: 0.000969766522757709. Test_MSE: [[[ 0.02920958  0.02345698  0.00493918  0.00195363]]]\n",
      "Epoch: 546 Iteration: 50800. Train_MSE: 0.0007191329495981336. Test_MSE: [[[ 0.02920004  0.02345385  0.00493907  0.00195337]]]\n",
      "Epoch: 547 Iteration: 50900. Train_MSE: 0.0009203728404827416. Test_MSE: [[[ 0.02919108  0.02345017  0.00493872  0.00195332]]]\n",
      "Epoch: 548 Iteration: 51000. Train_MSE: 0.01195228099822998. Test_MSE: [[[ 0.02918065  0.02344514  0.00493823  0.00195337]]]\n",
      "Epoch: 549 Iteration: 51100. Train_MSE: 0.0003749109455384314. Test_MSE: [[[ 0.02917194  0.02344094  0.00493817  0.00195302]]]\n",
      "Epoch: 550 Iteration: 51200. Train_MSE: 0.00043608303531073034. Test_MSE: [[[ 0.02916396  0.02343659  0.00493818  0.00195222]]]\n",
      "Epoch: 551 Iteration: 51300. Train_MSE: 0.0009963024640455842. Test_MSE: [[[ 0.02915492  0.02343248  0.00493823  0.00195149]]]\n",
      "Epoch: 552 Iteration: 51400. Train_MSE: 0.002567869611084461. Test_MSE: [[[ 0.02914488  0.02342819  0.00493813  0.00195101]]]\n",
      "Epoch: 553 Iteration: 51500. Train_MSE: 0.0005157295381650329. Test_MSE: [[[ 0.02913558  0.02342552  0.00493789  0.00195073]]]\n",
      "Epoch: 554 Iteration: 51600. Train_MSE: 0.010326235555112362. Test_MSE: [[[ 0.02912594  0.02341981  0.00493756  0.00195073]]]\n",
      "Epoch: 555 Iteration: 51700. Train_MSE: 0.0005151256336830556. Test_MSE: [[[ 0.02911725  0.02341591  0.00493738  0.00195063]]]\n",
      "Epoch: 556 Iteration: 51800. Train_MSE: 0.0003377698012627661. Test_MSE: [[[ 0.02910935  0.02341157  0.00493732  0.00195001]]]\n",
      "Epoch: 558 Iteration: 51900. Train_MSE: 0.0005837592179886997. Test_MSE: [[[ 0.02910197  0.0234074   0.00493733  0.00194923]]]\n",
      "Epoch: 559 Iteration: 52000. Train_MSE: 0.0004493801679927856. Test_MSE: [[[ 0.02909315  0.02340398  0.00493735  0.00194867]]]\n",
      "Epoch: 560 Iteration: 52100. Train_MSE: 0.0005299730692058802. Test_MSE: [[[ 0.02908352  0.02340083  0.00493722  0.0019483 ]]]\n",
      "Epoch: 561 Iteration: 52200. Train_MSE: 0.0005120733403600752. Test_MSE: [[[ 0.02907505  0.02339811  0.00493689  0.00194816]]]\n",
      "Epoch: 562 Iteration: 52300. Train_MSE: 0.000795873231254518. Test_MSE: [[[ 0.02906577  0.02339349  0.00493655  0.00194821]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 563 Iteration: 52400. Train_MSE: 0.004558699205517769. Test_MSE: [[[ 0.02905643  0.02338877  0.0049363   0.00194813]]]\n",
      "Epoch: 564 Iteration: 52500. Train_MSE: 0.00035614697844721377. Test_MSE: [[[ 0.02904905  0.02338461  0.00493634  0.00194731]]]\n",
      "Epoch: 565 Iteration: 52600. Train_MSE: 0.0011190936202183366. Test_MSE: [[[ 0.02904084  0.02338037  0.00493636  0.00194663]]]\n",
      "Epoch: 566 Iteration: 52700. Train_MSE: 0.0006121931364759803. Test_MSE: [[[ 0.02903136  0.02337704  0.00493641  0.001946  ]]]\n",
      "Epoch: 567 Iteration: 52800. Train_MSE: 0.0006000973517075181. Test_MSE: [[[ 0.02902206  0.02337348  0.00493615  0.00194581]]]\n",
      "Epoch: 568 Iteration: 52900. Train_MSE: 0.0005129828932695091. Test_MSE: [[[ 0.02901362  0.02336988  0.00493584  0.00194572]]]\n",
      "Epoch: 569 Iteration: 53000. Train_MSE: 0.00043335024383850396. Test_MSE: [[[ 0.02900431  0.02336429  0.00493557  0.00194576]]]\n",
      "Epoch: 570 Iteration: 53100. Train_MSE: 0.0004046921676490456. Test_MSE: [[[ 0.0289963   0.02336056  0.00493547  0.0019453 ]]]\n",
      "Epoch: 572 Iteration: 53200. Train_MSE: 0.0003838227712549269. Test_MSE: [[[ 0.02898933  0.02335632  0.00493544  0.00194454]]]\n",
      "Epoch: 573 Iteration: 53300. Train_MSE: 0.0007866917294450104. Test_MSE: [[[ 0.02898126  0.02335272  0.00493541  0.00194397]]]\n",
      "Epoch: 574 Iteration: 53400. Train_MSE: 0.0011059616226702929. Test_MSE: [[[ 0.028972    0.0233495   0.00493538  0.00194353]]]\n",
      "Epoch: 575 Iteration: 53500. Train_MSE: 0.0005950273480266333. Test_MSE: [[[ 0.02896391  0.02334734  0.00493513  0.00194334]]]\n",
      "Epoch: 576 Iteration: 53600. Train_MSE: 0.0005099503323435783. Test_MSE: [[[ 0.02895514  0.02334284  0.00493476  0.00194342]]]\n",
      "Epoch: 577 Iteration: 53700. Train_MSE: 0.00048347871052101254. Test_MSE: [[[ 0.02894621  0.02333855  0.00493446  0.00194338]]]\n",
      "Epoch: 578 Iteration: 53800. Train_MSE: 0.000365580985089764. Test_MSE: [[[ 0.02893855  0.02333445  0.00493443  0.00194281]]]\n",
      "Epoch: 579 Iteration: 53900. Train_MSE: 0.0004869104304816574. Test_MSE: [[[ 0.02893097  0.02333023  0.00493441  0.00194208]]]\n",
      "Epoch: 580 Iteration: 54000. Train_MSE: 0.0006223515374585986. Test_MSE: [[[ 0.02892222  0.02332679  0.00493448  0.00194149]]]\n",
      "Epoch: 581 Iteration: 54100. Train_MSE: 0.0005893781199119985. Test_MSE: [[[ 0.0289132   0.02332302  0.00493437  0.00194118]]]\n",
      "Epoch: 582 Iteration: 54200. Train_MSE: 0.0006320804823189974. Test_MSE: [[[ 0.02890486  0.02332039  0.004934    0.00194103]]]\n",
      "Epoch: 583 Iteration: 54300. Train_MSE: 0.00045403852709569037. Test_MSE: [[[ 0.02889599  0.02331463  0.00493369  0.0019411 ]]]\n",
      "Epoch: 584 Iteration: 54400. Train_MSE: 0.0004872932331636548. Test_MSE: [[[ 0.02888812  0.02331112  0.00493355  0.00194083]]]\n",
      "Epoch: 586 Iteration: 54500. Train_MSE: 0.00040113303111866117. Test_MSE: [[[ 0.02888126  0.02330692  0.00493347  0.00194013]]]\n",
      "Epoch: 587 Iteration: 54600. Train_MSE: 0.00225664209574461. Test_MSE: [[[ 0.02887397  0.02330311  0.00493346  0.00193958]]]\n",
      "Epoch: 588 Iteration: 54700. Train_MSE: 0.0013772229431197047. Test_MSE: [[[ 0.0288654   0.02330011  0.00493349  0.00193901]]]\n",
      "Epoch: 589 Iteration: 54800. Train_MSE: 0.0004559909866657108. Test_MSE: [[[ 0.02885713  0.02329792  0.00493326  0.0019388 ]]]\n",
      "Epoch: 590 Iteration: 54900. Train_MSE: 0.00909382663667202. Test_MSE: [[[ 0.02884877  0.02329392  0.00493285  0.00193887]]]\n",
      "Epoch: 591 Iteration: 55000. Train_MSE: 0.00040896874270401895. Test_MSE: [[[ 0.02884007  0.0232897   0.00493247  0.0019389 ]]]\n",
      "Epoch: 592 Iteration: 55100. Train_MSE: 0.00047992210602387786. Test_MSE: [[[ 0.02883245  0.02328579  0.00493241  0.00193852]]]\n",
      "Epoch: 593 Iteration: 55200. Train_MSE: 0.0005555105162784457. Test_MSE: [[[ 0.02882562  0.02328165  0.0049324   0.00193782]]]\n",
      "Epoch: 594 Iteration: 55300. Train_MSE: 0.0005363585660234094. Test_MSE: [[[ 0.02881725  0.02327805  0.00493243  0.00193721]]]\n",
      "Epoch: 595 Iteration: 55400. Train_MSE: 0.0007719290442764759. Test_MSE: [[[ 0.02880847  0.02327424  0.00493232  0.00193683]]]\n",
      "Epoch: 596 Iteration: 55500. Train_MSE: 0.0005190803785808384. Test_MSE: [[[ 0.02880031  0.02327182  0.00493204  0.00193663]]]\n",
      "Epoch: 597 Iteration: 55600. Train_MSE: 0.00036380227538757026. Test_MSE: [[[ 0.0287918   0.02326659  0.00493168  0.00193669]]]\n",
      "Epoch: 598 Iteration: 55700. Train_MSE: 0.00037217733915895224. Test_MSE: [[[ 0.02878417  0.02326311  0.00493151  0.00193659]]]\n",
      "Epoch: 599 Iteration: 55800. Train_MSE: 0.00044571392936632037. Test_MSE: [[[ 0.02877739  0.02325897  0.00493142  0.00193599]]]\n",
      "Epoch: 601 Iteration: 55900. Train_MSE: 0.0003605749225243926. Test_MSE: [[[ 0.02877095  0.02325534  0.00493144  0.00193533]]]\n",
      "Epoch: 602 Iteration: 56000. Train_MSE: 0.0005935445660725236. Test_MSE: [[[ 0.02876301  0.02325249  0.00493139  0.00193484]]]\n",
      "Epoch: 603 Iteration: 56100. Train_MSE: 0.0007401814218610525. Test_MSE: [[[ 0.02875456  0.02324947  0.00493129  0.00193459]]]\n",
      "Epoch: 604 Iteration: 56200. Train_MSE: 0.0007325948099605739. Test_MSE: [[[ 0.02874702  0.02324709  0.00493087  0.00193452]]]\n",
      "Epoch: 605 Iteration: 56300. Train_MSE: 0.0007229826878756285. Test_MSE: [[[ 0.02873863  0.02324297  0.00493046  0.00193459]]]\n",
      "Epoch: 606 Iteration: 56400. Train_MSE: 0.0005094421794638038. Test_MSE: [[[ 0.02873062  0.02323849  0.00493027  0.00193451]]]\n",
      "Epoch: 607 Iteration: 56500. Train_MSE: 0.0020443210378289223. Test_MSE: [[[ 0.02872391  0.02323458  0.00493026  0.00193381]]]\n",
      "Epoch: 608 Iteration: 56600. Train_MSE: 0.0005558853154070675. Test_MSE: [[[ 0.02871658  0.02323096  0.00493028  0.00193318]]]\n",
      "Epoch: 609 Iteration: 56700. Train_MSE: 0.005964890122413635. Test_MSE: [[[ 0.0287078   0.02322759  0.00493015  0.00193268]]]\n",
      "Epoch: 610 Iteration: 56800. Train_MSE: 0.0004853002610616386. Test_MSE: [[[ 0.02869994  0.02322497  0.00492998  0.00193252]]]\n",
      "Epoch: 611 Iteration: 56900. Train_MSE: 0.0013751945225521922. Test_MSE: [[[ 0.02869223  0.0232208   0.00492963  0.00193251]]]\n",
      "Epoch: 612 Iteration: 57000. Train_MSE: 0.0003477716527413577. Test_MSE: [[[ 0.02868436  0.02321634  0.00492938  0.00193256]]]\n",
      "Epoch: 613 Iteration: 57100. Train_MSE: 0.0005080107366666198. Test_MSE: [[[ 0.02867745  0.02321256  0.0049293   0.0019321 ]]]\n",
      "Epoch: 615 Iteration: 57200. Train_MSE: 0.00036843324778601527. Test_MSE: [[[ 0.02867134  0.02320887  0.00492927  0.0019314 ]]]\n",
      "Epoch: 616 Iteration: 57300. Train_MSE: 0.0004955414333380759. Test_MSE: [[[ 0.02866393  0.02320586  0.00492921  0.00193092]]]\n",
      "Epoch: 617 Iteration: 57400. Train_MSE: 0.0008305061492137611. Test_MSE: [[[ 0.02865583  0.02320325  0.0049291   0.00193058]]]\n",
      "Epoch: 618 Iteration: 57500. Train_MSE: 0.0005594547255896032. Test_MSE: [[[ 0.02864873  0.02320107  0.00492879  0.00193048]]]\n",
      "Epoch: 619 Iteration: 57600. Train_MSE: 0.0004911868018098176. Test_MSE: [[[ 0.02864108  0.023197    0.00492842  0.00193061]]]\n",
      "Epoch: 620 Iteration: 57700. Train_MSE: 0.0006131944246590137. Test_MSE: [[[ 0.02863302  0.02319278  0.00492818  0.0019306 ]]]\n",
      "Epoch: 621 Iteration: 57800. Train_MSE: 0.00032561790430918336. Test_MSE: [[[ 0.02862644  0.02318894  0.00492814  0.00192999]]]\n",
      "Epoch: 622 Iteration: 57900. Train_MSE: 0.00037958737812004983. Test_MSE: [[[ 0.0286197   0.02318514  0.00492811  0.00192935]]]\n",
      "Epoch: 623 Iteration: 58000. Train_MSE: 0.000546745490282774. Test_MSE: [[[ 0.02861177  0.02318208  0.00492815  0.00192886]]]\n",
      "Epoch: 624 Iteration: 58100. Train_MSE: 0.0005739371990785003. Test_MSE: [[[ 0.02860374  0.02317894  0.00492794  0.00192866]]]\n",
      "Epoch: 625 Iteration: 58200. Train_MSE: 0.0006034899270161986. Test_MSE: [[[ 0.02859653  0.02317634  0.00492756  0.0019286 ]]]\n",
      "Epoch: 626 Iteration: 58300. Train_MSE: 0.0023827238474041224. Test_MSE: [[[ 0.02858844  0.02317055  0.00492728  0.00192871]]]\n",
      "Epoch: 627 Iteration: 58400. Train_MSE: 0.00037072692066431046. Test_MSE: [[[ 0.02858165  0.02316755  0.00492714  0.00192841]]]\n",
      "Epoch: 629 Iteration: 58500. Train_MSE: 0.00038060423685237765. Test_MSE: [[[ 0.02857578  0.02316373  0.00492707  0.00192776]]]\n",
      "Epoch: 630 Iteration: 58600. Train_MSE: 0.0005886481958441436. Test_MSE: [[[ 0.02856942  0.02316055  0.00492703  0.0019273 ]]]\n",
      "Epoch: 631 Iteration: 58700. Train_MSE: 0.0016891369596123695. Test_MSE: [[[ 0.02856163  0.02315773  0.00492705  0.00192686]]]\n",
      "Epoch: 632 Iteration: 58800. Train_MSE: 0.0004219381371513009. Test_MSE: [[[ 0.02855451  0.02315616  0.00492673  0.00192669]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 633 Iteration: 58900. Train_MSE: 0.0015484747709706426. Test_MSE: [[[ 0.02854716  0.02315224  0.00492638  0.0019268 ]]]\n",
      "Epoch: 634 Iteration: 59000. Train_MSE: 0.0003801136335823685. Test_MSE: [[[ 0.02853958  0.02314823  0.00492607  0.00192685]]]\n",
      "Epoch: 635 Iteration: 59100. Train_MSE: 0.0002892497868742794. Test_MSE: [[[ 0.02853302  0.02314462  0.00492602  0.00192645]]]\n",
      "Epoch: 636 Iteration: 59200. Train_MSE: 0.00038616490201093256. Test_MSE: [[[ 0.02852694  0.02314086  0.00492599  0.00192583]]]\n",
      "Epoch: 637 Iteration: 59300. Train_MSE: 0.000475793523946777. Test_MSE: [[[ 0.02851959  0.0231379   0.00492605  0.00192529]]]\n",
      "Epoch: 638 Iteration: 59400. Train_MSE: 0.0007949713035486639. Test_MSE: [[[ 0.02851188  0.02313436  0.00492599  0.00192502]]]\n",
      "Epoch: 639 Iteration: 59500. Train_MSE: 0.00037448006332851946. Test_MSE: [[[ 0.02850477  0.02313226  0.00492565  0.00192487]]]\n",
      "Epoch: 640 Iteration: 59600. Train_MSE: 0.0003874019021168351. Test_MSE: [[[ 0.02849719  0.02312691  0.00492528  0.00192499]]]\n",
      "Epoch: 641 Iteration: 59700. Train_MSE: 0.0006622342625632882. Test_MSE: [[[ 0.02849045  0.02312386  0.00492512  0.00192489]]]\n",
      "Epoch: 643 Iteration: 59800. Train_MSE: 0.0003132864076178521. Test_MSE: [[[ 0.02848475  0.02312003  0.00492505  0.00192429]]]\n",
      "Epoch: 644 Iteration: 59900. Train_MSE: 0.0006022347370162606. Test_MSE: [[[ 0.02847907  0.02311685  0.0049251   0.00192374]]]\n",
      "Epoch: 645 Iteration: 60000. Train_MSE: 0.0008622181485407054. Test_MSE: [[[ 0.02847167  0.02311441  0.00492503  0.00192326]]]\n",
      "Epoch: 646 Iteration: 60100. Train_MSE: 0.00063612888334319. Test_MSE: [[[ 0.02846463  0.02311224  0.00492487  0.00192311]]]\n",
      "Epoch: 647 Iteration: 60200. Train_MSE: 0.0008707937668077648. Test_MSE: [[[ 0.02845815  0.02310935  0.00492452  0.00192315]]]\n",
      "Epoch: 648 Iteration: 60300. Train_MSE: 0.011878486722707748. Test_MSE: [[[ 0.02845015  0.02310496  0.00492406  0.0019233 ]]]\n",
      "Epoch: 649 Iteration: 60400. Train_MSE: 0.0003240662335883826. Test_MSE: [[[ 0.02844373  0.02310149  0.00492398  0.00192309]]]\n",
      "Epoch: 650 Iteration: 60500. Train_MSE: 0.0003832403162959963. Test_MSE: [[[ 0.02843792  0.02309794  0.00492398  0.00192248]]]\n",
      "Epoch: 651 Iteration: 60600. Train_MSE: 0.0009013665257953107. Test_MSE: [[[ 0.02843119  0.02309468  0.00492401  0.00192192]]]\n",
      "Epoch: 652 Iteration: 60700. Train_MSE: 0.0024615987204015255. Test_MSE: [[[ 0.02842362  0.02309134  0.0049239   0.00192156]]]\n",
      "Epoch: 653 Iteration: 60800. Train_MSE: 0.0004473378648981452. Test_MSE: [[[ 0.02841677  0.02308947  0.00492364  0.00192139]]]\n",
      "Epoch: 654 Iteration: 60900. Train_MSE: 0.01028076559305191. Test_MSE: [[[ 0.02840955  0.02308452  0.00492331  0.00192148]]]\n",
      "Epoch: 655 Iteration: 61000. Train_MSE: 0.00045213830890133977. Test_MSE: [[[ 0.02840314  0.02308126  0.00492314  0.00192148]]]\n",
      "Epoch: 656 Iteration: 61100. Train_MSE: 0.00030642913770861924. Test_MSE: [[[ 0.0283974   0.02307768  0.00492306  0.00192102]]]\n",
      "Epoch: 658 Iteration: 61200. Train_MSE: 0.0005081122508272529. Test_MSE: [[[ 0.02839215  0.02307434  0.00492306  0.00192042]]]\n",
      "Epoch: 659 Iteration: 61300. Train_MSE: 0.00037034583510831. Test_MSE: [[[ 0.02838564  0.02307176  0.00492305  0.00192   ]]]\n",
      "Epoch: 660 Iteration: 61400. Train_MSE: 0.0004796335706487298. Test_MSE: [[[ 0.02837841  0.02306952  0.00492288  0.00191973]]]\n",
      "Epoch: 661 Iteration: 61500. Train_MSE: 0.0004538862267509103. Test_MSE: [[[ 0.02837233  0.02306759  0.00492255  0.00191969]]]\n",
      "Epoch: 662 Iteration: 61600. Train_MSE: 0.0007254087831825018. Test_MSE: [[[ 0.02836542  0.02306364  0.00492222  0.00191982]]]\n",
      "Epoch: 663 Iteration: 61700. Train_MSE: 0.004525406751781702. Test_MSE: [[[ 0.02835832  0.02305955  0.00492198  0.00191985]]]\n",
      "Epoch: 664 Iteration: 61800. Train_MSE: 0.0003200058708898723. Test_MSE: [[[ 0.02835303  0.02305618  0.00492202  0.00191921]]]\n",
      "Epoch: 665 Iteration: 61900. Train_MSE: 0.0010576191125437617. Test_MSE: [[[ 0.028347    0.02305273  0.00492203  0.00191869]]]\n",
      "Epoch: 666 Iteration: 62000. Train_MSE: 0.0005324849626049399. Test_MSE: [[[ 0.02833991  0.02305025  0.00492206  0.00191818]]]\n",
      "Epoch: 667 Iteration: 62100. Train_MSE: 0.0005361479707062244. Test_MSE: [[[ 0.02833298  0.02304751  0.0049218   0.00191809]]]\n",
      "Epoch: 668 Iteration: 62200. Train_MSE: 0.00047229512711055577. Test_MSE: [[[ 0.02832689  0.02304462  0.00492149  0.00191808]]]\n",
      "Epoch: 669 Iteration: 62300. Train_MSE: 0.00036551631637848914. Test_MSE: [[[ 0.02831988  0.02303968  0.00492124  0.0019182 ]]]\n",
      "Epoch: 670 Iteration: 62400. Train_MSE: 0.0003623928932938725. Test_MSE: [[[ 0.02831404  0.02303663  0.00492115  0.00191787]]]\n",
      "Epoch: 672 Iteration: 62500. Train_MSE: 0.00033805068233050406. Test_MSE: [[[ 0.02830918  0.02303319  0.00492113  0.00191728]]]\n",
      "Epoch: 673 Iteration: 62600. Train_MSE: 0.0006937449215911329. Test_MSE: [[[ 0.02830334  0.02303038  0.00492109  0.00191685]]]\n",
      "Epoch: 674 Iteration: 62700. Train_MSE: 0.0010166059946641326. Test_MSE: [[[ 0.02829646  0.02302806  0.00492105  0.00191651]]]\n",
      "Epoch: 675 Iteration: 62800. Train_MSE: 0.0005075664375908673. Test_MSE: [[[ 0.02829072  0.0230267   0.0049208   0.00191641]]]\n",
      "Epoch: 676 Iteration: 62900. Train_MSE: 0.00044792229891754687. Test_MSE: [[[ 0.02828433  0.02302288  0.00492045  0.00191655]]]\n",
      "Epoch: 677 Iteration: 63000. Train_MSE: 0.0004363519256003201. Test_MSE: [[[ 0.02827761  0.02301914  0.00492019  0.00191661]]]\n",
      "Epoch: 678 Iteration: 63100. Train_MSE: 0.0003174477897118777. Test_MSE: [[[ 0.02827201  0.02301575  0.00492016  0.00191618]]]\n",
      "Epoch: 679 Iteration: 63200. Train_MSE: 0.00042520073475316167. Test_MSE: [[[ 0.02826651  0.02301228  0.00492015  0.00191561]]]\n",
      "Epoch: 680 Iteration: 63300. Train_MSE: 0.0005453412304632366. Test_MSE: [[[ 0.02825998  0.0230096   0.0049202   0.00191515]]]\n",
      "Epoch: 681 Iteration: 63400. Train_MSE: 0.0005382527597248554. Test_MSE: [[[ 0.02825326  0.02300669  0.00492009  0.00191494]]]\n",
      "Epoch: 682 Iteration: 63500. Train_MSE: 0.0005876731593161821. Test_MSE: [[[ 0.02824725  0.02300475  0.00491975  0.00191487]]]\n",
      "Epoch: 683 Iteration: 63600. Train_MSE: 0.0004037017351947725. Test_MSE: [[[ 0.0282406   0.0229996   0.00491946  0.001915  ]]]\n",
      "Epoch: 684 Iteration: 63700. Train_MSE: 0.0004304375615902245. Test_MSE: [[[ 0.02823485  0.02299672  0.00491934  0.00191485]]]\n",
      "Epoch: 686 Iteration: 63800. Train_MSE: 0.00035935116466134787. Test_MSE: [[[ 0.02823     0.02299323  0.00491928  0.00191429]]]\n",
      "Epoch: 687 Iteration: 63900. Train_MSE: 0.002187243662774563. Test_MSE: [[[ 0.02822482  0.02299019  0.00491927  0.00191388]]]\n",
      "Epoch: 688 Iteration: 64000. Train_MSE: 0.001295803813263774. Test_MSE: [[[ 0.02821845  0.02298802  0.00491928  0.00191342]]]\n",
      "Epoch: 689 Iteration: 64100. Train_MSE: 0.0004031195130664855. Test_MSE: [[[ 0.02821244  0.02298658  0.00491905  0.0019133 ]]]\n",
      "Epoch: 690 Iteration: 64200. Train_MSE: 0.009037167765200138. Test_MSE: [[[ 0.02820642  0.02298328  0.00491868  0.00191343]]]\n",
      "Epoch: 691 Iteration: 64300. Train_MSE: 0.0003496203862596303. Test_MSE: [[[ 0.02819988  0.02297959  0.00491835  0.00191353]]]\n",
      "Epoch: 692 Iteration: 64400. Train_MSE: 0.0004374872660264373. Test_MSE: [[[ 0.02819429  0.02297634  0.00491831  0.00191327]]]\n",
      "Epoch: 693 Iteration: 64500. Train_MSE: 0.0004880010965280235. Test_MSE: [[[ 0.02818944  0.02297294  0.00491831  0.00191272]]]\n",
      "Epoch: 694 Iteration: 64600. Train_MSE: 0.00047836973681114614. Test_MSE: [[[ 0.02818319  0.02297007  0.00491835  0.00191224]]]\n",
      "Epoch: 695 Iteration: 64700. Train_MSE: 0.0007255175150930882. Test_MSE: [[[ 0.02817665  0.02296709  0.00491826  0.00191195]]]\n",
      "Epoch: 696 Iteration: 64800. Train_MSE: 0.00047616695519536734. Test_MSE: [[[ 0.02817074  0.02296534  0.00491801  0.00191182]]]\n",
      "Epoch: 697 Iteration: 64900. Train_MSE: 0.00031794910319149494. Test_MSE: [[[ 0.02816442  0.02296074  0.00491768  0.00191194]]]\n",
      "Epoch: 698 Iteration: 65000. Train_MSE: 0.00033107693889178336. Test_MSE: [[[ 0.02815887  0.02295781  0.00491755  0.00191192]]]\n",
      "Epoch: 699 Iteration: 65100. Train_MSE: 0.0004045954265166074. Test_MSE: [[[ 0.02815406  0.02295435  0.00491748  0.00191146]]]\n",
      "Epoch: 701 Iteration: 65200. Train_MSE: 0.00031491045956499875. Test_MSE: [[[ 0.0281496   0.02295143  0.00491753  0.00191095]]]\n",
      "Epoch: 702 Iteration: 65300. Train_MSE: 0.0005258837481960654. Test_MSE: [[[ 0.02814379  0.02294931  0.00491749  0.00191056]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 703 Iteration: 65400. Train_MSE: 0.0006490882369689643. Test_MSE: [[[ 0.02813756  0.0229471   0.00491738  0.00191038]]]\n",
      "Epoch: 704 Iteration: 65500. Train_MSE: 0.0006832011276856065. Test_MSE: [[[ 0.02813225  0.02294536  0.00491701  0.00191037]]]\n",
      "Epoch: 705 Iteration: 65600. Train_MSE: 0.0006722280522808433. Test_MSE: [[[ 0.02812604  0.02294178  0.00491666  0.00191051]]]\n",
      "Epoch: 706 Iteration: 65700. Train_MSE: 0.0004420591867528856. Test_MSE: [[[ 0.02812003  0.02293789  0.00491649  0.00191051]]]\n",
      "Epoch: 707 Iteration: 65800. Train_MSE: 0.0020185380708426237. Test_MSE: [[[ 0.02811523  0.02293467  0.00491651  0.00190997]]]\n",
      "Epoch: 708 Iteration: 65900. Train_MSE: 0.0005052153719589114. Test_MSE: [[[ 0.02810989  0.02293175  0.00491654  0.00190946]]]\n",
      "Epoch: 709 Iteration: 66000. Train_MSE: 0.00587704312056303. Test_MSE: [[[ 0.02810329  0.02292912  0.00491645  0.00190906]]]\n",
      "Epoch: 710 Iteration: 66100. Train_MSE: 0.00043747841846197844. Test_MSE: [[[ 0.02809755  0.02292724  0.00491628  0.00190897]]]\n",
      "Epoch: 711 Iteration: 66200. Train_MSE: 0.0013407915830612183. Test_MSE: [[[ 0.02809194  0.02292368  0.00491596  0.00190902]]]\n",
      "Epoch: 712 Iteration: 66300. Train_MSE: 0.0003044708864763379. Test_MSE: [[[ 0.0280861   0.02291977  0.00491575  0.00190913]]]\n",
      "Epoch: 713 Iteration: 66400. Train_MSE: 0.0004520179354585707. Test_MSE: [[[ 0.02808113  0.02291662  0.0049157   0.00190879]]]\n",
      "Epoch: 715 Iteration: 66500. Train_MSE: 0.0003328259044792503. Test_MSE: [[[ 0.02807689  0.0229136   0.00491569  0.00190822]]]\n",
      "Epoch: 716 Iteration: 66600. Train_MSE: 0.00043952290434390306. Test_MSE: [[[ 0.0280715   0.02291127  0.00491564  0.00190784]]]\n",
      "Epoch: 717 Iteration: 66700. Train_MSE: 0.0007750255754217505. Test_MSE: [[[ 0.0280655   0.02290943  0.00491553  0.00190759]]]\n",
      "Epoch: 718 Iteration: 66800. Train_MSE: 0.0005158161511644721. Test_MSE: [[[ 0.02806049  0.02290794  0.00491525  0.00190755]]]\n",
      "Epoch: 719 Iteration: 66900. Train_MSE: 0.000431386346463114. Test_MSE: [[[ 0.02805497  0.02290446  0.00491493  0.00190772]]]\n",
      "Epoch: 720 Iteration: 67000. Train_MSE: 0.0005707500968128443. Test_MSE: [[[ 0.02804885  0.02290078  0.00491473  0.00190779]]]\n",
      "Epoch: 721 Iteration: 67100. Train_MSE: 0.00029121595434844494. Test_MSE: [[[ 0.02804411  0.02289758  0.00491471  0.00190731]]]\n",
      "Epoch: 722 Iteration: 67200. Train_MSE: 0.00033405196154490113. Test_MSE: [[[ 0.02803923  0.02289446  0.00491471  0.0019068 ]]]\n",
      "Epoch: 723 Iteration: 67300. Train_MSE: 0.00048152991803362966. Test_MSE: [[[ 0.0280333   0.0228921   0.00491475  0.00190641]]]\n",
      "Epoch: 724 Iteration: 67400. Train_MSE: 0.0005133607774041593. Test_MSE: [[[ 0.02802732  0.02288969  0.00491456  0.00190627]]]\n",
      "Epoch: 725 Iteration: 67500. Train_MSE: 0.000568108691368252. Test_MSE: [[[ 0.02802215  0.02288767  0.00491421  0.00190627]]]\n",
      "Epoch: 726 Iteration: 67600. Train_MSE: 0.0023254386615008116. Test_MSE: [[[ 0.02801604  0.0228825   0.00491398  0.00190643]]]\n",
      "Epoch: 727 Iteration: 67700. Train_MSE: 0.0003378190740477294. Test_MSE: [[[ 0.0280111   0.02288001  0.00491387  0.00190623]]]\n",
      "Epoch: 729 Iteration: 67800. Train_MSE: 0.000353041454218328. Test_MSE: [[[ 0.02800701  0.02287683  0.00491382  0.00190571]]]\n",
      "Epoch: 730 Iteration: 67900. Train_MSE: 0.0005335268215276301. Test_MSE: [[[ 0.02800249  0.0228743   0.00491379  0.00190535]]]\n",
      "Epoch: 731 Iteration: 68000. Train_MSE: 0.0016319277929142118. Test_MSE: [[[ 0.02799667  0.02287223  0.0049138   0.001905  ]]]\n",
      "Epoch: 732 Iteration: 68100. Train_MSE: 0.00038027510163374245. Test_MSE: [[[ 0.02799153  0.02287129  0.00491349  0.0019049 ]]]\n",
      "Epoch: 733 Iteration: 68200. Train_MSE: 0.0015058499993756413. Test_MSE: [[[ 0.02798617  0.02286798  0.00491316  0.00190505]]]\n",
      "Epoch: 734 Iteration: 68300. Train_MSE: 0.00033979761064983904. Test_MSE: [[[ 0.0279804   0.02286443  0.00491289  0.00190517]]]\n",
      "Epoch: 735 Iteration: 68400. Train_MSE: 0.00026834962773136795. Test_MSE: [[[ 0.02797555  0.02286138  0.00491284  0.00190487]]]\n",
      "Epoch: 736 Iteration: 68500. Train_MSE: 0.0003528849338181317. Test_MSE: [[[ 0.02797115  0.02285826  0.00491282  0.00190439]]]\n",
      "Epoch: 737 Iteration: 68600. Train_MSE: 0.0004233730142004788. Test_MSE: [[[ 0.02796563  0.02285593  0.00491287  0.00190395]]]\n",
      "Epoch: 738 Iteration: 68700. Train_MSE: 0.0007454907172359526. Test_MSE: [[[ 0.02795978  0.02285315  0.0049128   0.00190375]]]\n",
      "Epoch: 739 Iteration: 68800. Train_MSE: 0.00034007360227406025. Test_MSE: [[[ 0.02795462  0.02285163  0.00491248  0.00190366]]]\n",
      "Epoch: 740 Iteration: 68900. Train_MSE: 0.0003598721232265234. Test_MSE: [[[ 0.02794892  0.02284684  0.00491215  0.00190383]]]\n",
      "Epoch: 741 Iteration: 69000. Train_MSE: 0.0006088856025598943. Test_MSE: [[[ 0.02794395  0.0228443   0.004912    0.0019038 ]]]\n",
      "Epoch: 743 Iteration: 69100. Train_MSE: 0.00029084362904541194. Test_MSE: [[[ 0.02793992  0.02284109  0.00491194  0.00190332]]]\n",
      "Epoch: 744 Iteration: 69200. Train_MSE: 0.0005562809528782964. Test_MSE: [[[ 0.02793592  0.02283856  0.00491199  0.00190289]]]\n",
      "Epoch: 745 Iteration: 69300. Train_MSE: 0.0007828043890185654. Test_MSE: [[[ 0.02793039  0.02283679  0.00491191  0.00190249]]]\n",
      "Epoch: 746 Iteration: 69400. Train_MSE: 0.0005779687198810279. Test_MSE: [[[ 0.02792522  0.02283532  0.00491173  0.0019024 ]]]\n",
      "Epoch: 747 Iteration: 69500. Train_MSE: 0.0008388429414480925. Test_MSE: [[[ 0.02792061  0.02283304  0.00491141  0.00190249]]]\n",
      "Epoch: 748 Iteration: 69600. Train_MSE: 0.011827284470200539. Test_MSE: [[[ 0.02791451  0.02282916  0.004911    0.00190269]]]\n",
      "Epoch: 749 Iteration: 69700. Train_MSE: 0.00028811575612053275. Test_MSE: [[[ 0.02790973  0.02282624  0.00491093  0.00190256]]]\n",
      "Epoch: 750 Iteration: 69800. Train_MSE: 0.00034485009382478893. Test_MSE: [[[ 0.02790553  0.0228233   0.00491093  0.00190208]]]\n",
      "Epoch: 751 Iteration: 69900. Train_MSE: 0.0008338562911376357. Test_MSE: [[[ 0.0279005   0.02282067  0.00491096  0.00190162]]]\n",
      "Epoch: 752 Iteration: 70000. Train_MSE: 0.0023904151748865843. Test_MSE: [[[ 0.0278947   0.02281802  0.00491084  0.00190134]]]\n",
      "Epoch: 753 Iteration: 70100. Train_MSE: 0.00040196094778366387. Test_MSE: [[[ 0.02788967  0.02281678  0.00491059  0.00190123]]]\n",
      "Epoch: 754 Iteration: 70200. Train_MSE: 0.01025260891765356. Test_MSE: [[[ 0.02788424  0.02281242  0.00491028  0.00190137]]]\n",
      "Epoch: 755 Iteration: 70300. Train_MSE: 0.0004087622801307589. Test_MSE: [[[ 0.0278795   0.02280965  0.00491012  0.00190142]]]\n",
      "Epoch: 756 Iteration: 70400. Train_MSE: 0.0002836007624864578. Test_MSE: [[[ 0.02787537  0.02280667  0.00491005  0.00190107]]]\n",
      "Epoch: 758 Iteration: 70500. Train_MSE: 0.00045305874664336443. Test_MSE: [[[ 0.02787171  0.02280396  0.00491004  0.00190058]]]\n",
      "Epoch: 759 Iteration: 70600. Train_MSE: 0.0003161275526508689. Test_MSE: [[[ 0.02786688  0.022802    0.00491002  0.00190025]]]\n",
      "Epoch: 760 Iteration: 70700. Train_MSE: 0.0004471226711757481. Test_MSE: [[[ 0.02786145  0.02280046  0.00490984  0.00190005]]]\n",
      "Epoch: 761 Iteration: 70800. Train_MSE: 0.0004152830224484205. Test_MSE: [[[ 0.02785714  0.02279912  0.00490952  0.00190005]]]\n",
      "Epoch: 762 Iteration: 70900. Train_MSE: 0.0006768482853658497. Test_MSE: [[[ 0.02785194  0.02279571  0.0049092   0.00190022]]]\n",
      "Epoch: 763 Iteration: 71000. Train_MSE: 0.0045021213591098785. Test_MSE: [[[ 0.02784641  0.0227921   0.00490898  0.00190032]]]\n",
      "Epoch: 764 Iteration: 71100. Train_MSE: 0.00029365881346166134. Test_MSE: [[[ 0.02784257  0.02278932  0.004909    0.0018998 ]]]\n",
      "Epoch: 765 Iteration: 71200. Train_MSE: 0.0010142269311472774. Test_MSE: [[[ 0.02783804  0.02278646  0.00490899  0.00189939]]]\n",
      "Epoch: 766 Iteration: 71300. Train_MSE: 0.00047533330507576466. Test_MSE: [[[ 0.02783258  0.0227846   0.004909    0.00189896]]]\n",
      "Epoch: 767 Iteration: 71400. Train_MSE: 0.000493917556013912. Test_MSE: [[[ 0.0278273   0.02278248  0.00490873  0.00189894]]]\n",
      "Epoch: 768 Iteration: 71500. Train_MSE: 0.0004454863374121487. Test_MSE: [[[ 0.02782283  0.02278014  0.00490842  0.00189897]]]\n",
      "Epoch: 769 Iteration: 71600. Train_MSE: 0.00031938854954205453. Test_MSE: [[[ 0.0278174   0.02277572  0.00490819  0.00189913]]]\n",
      "Epoch: 770 Iteration: 71700. Train_MSE: 0.00033245503436774015. Test_MSE: [[[ 0.02781304  0.02277318  0.00490811  0.00189889]]]\n",
      "Epoch: 772 Iteration: 71800. Train_MSE: 0.0003053974942304194. Test_MSE: [[[ 0.02780961  0.02277032  0.00490808  0.0018984 ]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 773 Iteration: 71900. Train_MSE: 0.0006252856692299247. Test_MSE: [[[ 0.02780527  0.02276809  0.00490804  0.00189806]]]\n",
      "Epoch: 774 Iteration: 72000. Train_MSE: 0.0009536989964544773. Test_MSE: [[[ 0.02780002  0.02276644  0.00490798  0.00189778]]]\n",
      "Epoch: 775 Iteration: 72100. Train_MSE: 0.0004460549680516124. Test_MSE: [[[ 0.02779586  0.02276565  0.00490773  0.00189772]]]\n",
      "Epoch: 776 Iteration: 72200. Train_MSE: 0.00040548574179410934. Test_MSE: [[[ 0.02779105  0.02276236  0.00490739  0.0018979 ]]]\n",
      "Epoch: 777 Iteration: 72300. Train_MSE: 0.0004039659397676587. Test_MSE: [[[ 0.02778585  0.02275907  0.00490716  0.00189801]]]\n",
      "Epoch: 778 Iteration: 72400. Train_MSE: 0.0002821170201059431. Test_MSE: [[[ 0.02778164  0.02275621  0.00490713  0.00189767]]]\n",
      "Epoch: 779 Iteration: 72500. Train_MSE: 0.0003812609938904643. Test_MSE: [[[ 0.02777755  0.02275332  0.00490712  0.00189721]]]\n",
      "Epoch: 780 Iteration: 72600. Train_MSE: 0.0004899710766039789. Test_MSE: [[[ 0.02777252  0.02275122  0.00490716  0.00189683]]]\n",
      "Epoch: 781 Iteration: 72700. Train_MSE: 0.0005046672886237502. Test_MSE: [[[ 0.02776732  0.02274896  0.00490703  0.00189667]]]\n",
      "Epoch: 782 Iteration: 72800. Train_MSE: 0.000558585103135556. Test_MSE: [[[ 0.02776289  0.02274754  0.0049067   0.00189664]]]\n",
      "Epoch: 783 Iteration: 72900. Train_MSE: 0.00037042898475192487. Test_MSE: [[[ 0.02775775  0.02274289  0.00490643  0.0018968 ]]]\n",
      "Epoch: 784 Iteration: 73000. Train_MSE: 0.0003878161951433867. Test_MSE: [[[ 0.02775342  0.02274047  0.00490631  0.00189671]]]\n",
      "Epoch: 786 Iteration: 73100. Train_MSE: 0.00032834208104759455. Test_MSE: [[[ 0.02774992  0.02273755  0.00490625  0.00189626]]]\n",
      "Epoch: 787 Iteration: 73200. Train_MSE: 0.0021403927821666002. Test_MSE: [[[ 0.02774613  0.02273507  0.00490624  0.00189594]]]\n",
      "Epoch: 788 Iteration: 73300. Train_MSE: 0.0012405815068632364. Test_MSE: [[[ 0.02774127  0.02273351  0.00490623  0.00189555]]]\n",
      "Epoch: 789 Iteration: 73400. Train_MSE: 0.00036883351276628673. Test_MSE: [[[ 0.02773682  0.02273266  0.00490599  0.00189547]]]\n",
      "Epoch: 790 Iteration: 73500. Train_MSE: 0.009009803645312786. Test_MSE: [[[ 0.02773229  0.02272991  0.00490563  0.00189563]]]\n",
      "Epoch: 791 Iteration: 73600. Train_MSE: 0.0003093260165769607. Test_MSE: [[[ 0.02772723  0.02272664  0.00490533  0.00189578]]]\n",
      "Epoch: 792 Iteration: 73700. Train_MSE: 0.0004053212469443679. Test_MSE: [[[ 0.02772299  0.02272389  0.00490529  0.00189559]]]\n",
      "Epoch: 793 Iteration: 73800. Train_MSE: 0.00043801774154417217. Test_MSE: [[[ 0.02771943  0.02272104  0.00490528  0.00189514]]]\n",
      "Epoch: 794 Iteration: 73900. Train_MSE: 0.0004368443333078176. Test_MSE: [[[ 0.0277146   0.02271871  0.00490531  0.00189474]]]\n",
      "Epoch: 795 Iteration: 74000. Train_MSE: 0.0006956369616091251. Test_MSE: [[[ 0.0277095   0.02271635  0.0049052   0.00189452]]]\n",
      "Epoch: 796 Iteration: 74100. Train_MSE: 0.0004484532692003995. Test_MSE: [[[ 0.02770509  0.02271514  0.00490495  0.00189443]]]\n",
      "Epoch: 797 Iteration: 74200. Train_MSE: 0.00028623457183130085. Test_MSE: [[[ 0.02770025  0.02271109  0.00490464  0.00189458]]]\n",
      "Epoch: 798 Iteration: 74300. Train_MSE: 0.0003024601028300822. Test_MSE: [[[ 0.02769606  0.02270858  0.00490451  0.0018946 ]]]\n",
      "Epoch: 799 Iteration: 74400. Train_MSE: 0.0003731739998329431. Test_MSE: [[[ 0.02769256  0.02270568  0.00490445  0.00189424]]]\n",
      "Epoch: 801 Iteration: 74500. Train_MSE: 0.0002828568685799837. Test_MSE: [[[ 0.02768938  0.02270331  0.00490447  0.00189381]]]\n",
      "Epoch: 802 Iteration: 74600. Train_MSE: 0.0004767841019202024. Test_MSE: [[[ 0.02768497  0.02270175  0.00490442  0.00189349]]]\n",
      "Epoch: 803 Iteration: 74700. Train_MSE: 0.0005842974642291665. Test_MSE: [[[ 0.02768021  0.02270019  0.00490429  0.00189337]]]\n",
      "Epoch: 804 Iteration: 74800. Train_MSE: 0.0006507645011879504. Test_MSE: [[[ 0.02767635  0.02269894  0.00490393  0.00189339]]]\n",
      "Epoch: 805 Iteration: 74900. Train_MSE: 0.0006381715647876263. Test_MSE: [[[ 0.02767156  0.02269582  0.00490359  0.00189356]]]\n",
      "Epoch: 806 Iteration: 75000. Train_MSE: 0.0003922844771295786. Test_MSE: [[[ 0.02766686  0.0226924   0.00490343  0.00189361]]]\n",
      "Epoch: 807 Iteration: 75100. Train_MSE: 0.0019988210406154394. Test_MSE: [[[ 0.02766329  0.02268972  0.00490344  0.00189317]]]\n",
      "Epoch: 808 Iteration: 75200. Train_MSE: 0.00046872044913470745. Test_MSE: [[[ 0.02765923  0.02268731  0.00490346  0.00189275]]]\n",
      "Epoch: 809 Iteration: 75300. Train_MSE: 0.005818198435008526. Test_MSE: [[[ 0.02765404  0.02268524  0.00490335  0.00189241]]]\n",
      "Epoch: 810 Iteration: 75400. Train_MSE: 0.0004044420784339309. Test_MSE: [[[ 0.02764966  0.02268392  0.00490317  0.00189236]]]\n",
      "Epoch: 811 Iteration: 75500. Train_MSE: 0.0013158656656742096. Test_MSE: [[[ 0.02764545  0.02268085  0.00490286  0.00189244]]]\n",
      "Epoch: 812 Iteration: 75600. Train_MSE: 0.00027448241598904133. Test_MSE: [[[ 0.02764094  0.02267739  0.00490265  0.00189258]]]\n",
      "Epoch: 813 Iteration: 75700. Train_MSE: 0.00040933353011496365. Test_MSE: [[[ 0.02763722  0.02267472  0.0049026   0.00189232]]]\n",
      "Epoch: 815 Iteration: 75800. Train_MSE: 0.00030630186665803194. Test_MSE: [[[ 0.02763419  0.02267222  0.00490257  0.00189185]]]\n",
      "Epoch: 816 Iteration: 75900. Train_MSE: 0.0003995805745944381. Test_MSE: [[[ 0.0276301   0.0226704   0.00490252  0.00189154]]]\n",
      "Epoch: 817 Iteration: 76000. Train_MSE: 0.0007365630590356886. Test_MSE: [[[ 0.02762548  0.02266912  0.00490238  0.00189133]]]\n",
      "Epoch: 818 Iteration: 76100. Train_MSE: 0.0004860214830841869. Test_MSE: [[[ 0.02762185  0.02266816  0.0049021   0.00189132]]]\n",
      "Epoch: 819 Iteration: 76200. Train_MSE: 0.00038942412356846035. Test_MSE: [[[ 0.02761764  0.02266513  0.00490178  0.00189152]]]\n",
      "Epoch: 820 Iteration: 76300. Train_MSE: 0.0005384453106671572. Test_MSE: [[[ 0.02761284  0.02266185  0.00490159  0.00189163]]]\n",
      "Epoch: 821 Iteration: 76400. Train_MSE: 0.00026456057094037533. Test_MSE: [[[ 0.02760925  0.02265913  0.00490156  0.00189124]]]\n",
      "Epoch: 822 Iteration: 76500. Train_MSE: 0.00030042254365980625. Test_MSE: [[[ 0.02760557  0.02265651  0.00490155  0.00189081]]]\n",
      "Epoch: 823 Iteration: 76600. Train_MSE: 0.00043487880611792207. Test_MSE: [[[ 0.02760093  0.02265466  0.00490157  0.00189049]]]\n",
      "Epoch: 824 Iteration: 76700. Train_MSE: 0.00047063938109204173. Test_MSE: [[[ 0.02759625  0.02265279  0.00490136  0.0018904 ]]]\n",
      "Epoch: 825 Iteration: 76800. Train_MSE: 0.0005453329067677259. Test_MSE: [[[ 0.02759242  0.02265121  0.00490103  0.00189042]]]\n",
      "Epoch: 826 Iteration: 76900. Train_MSE: 0.002287250244989991. Test_MSE: [[[ 0.02758761  0.0226465   0.0049008   0.00189061]]]\n",
      "Epoch: 827 Iteration: 77000. Train_MSE: 0.000314244331093505. Test_MSE: [[[ 0.02758386  0.02264442  0.00490069  0.00189047]]]\n",
      "Epoch: 829 Iteration: 77100. Train_MSE: 0.0003323255805298686. Test_MSE: [[[ 0.0275809   0.02264174  0.00490063  0.00189002]]]\n",
      "Epoch: 830 Iteration: 77200. Train_MSE: 0.0004929080605506897. Test_MSE: [[[ 0.02757756  0.02263969  0.00490059  0.00188974]]]\n",
      "Epoch: 831 Iteration: 77300. Train_MSE: 0.001595228211954236. Test_MSE: [[[ 0.02757303  0.02263816  0.00490057  0.00188945]]]\n",
      "Epoch: 832 Iteration: 77400. Train_MSE: 0.0003521597827784717. Test_MSE: [[[ 0.0275692   0.0226377   0.00490025  0.00188937]]]\n",
      "Epoch: 833 Iteration: 77500. Train_MSE: 0.0014766481472179294. Test_MSE: [[[ 0.0275651   0.02263486  0.00489993  0.00188955]]]\n",
      "Epoch: 834 Iteration: 77600. Train_MSE: 0.0003112227423116565. Test_MSE: [[[ 0.02756057  0.02263168  0.00489967  0.00188969]]]\n",
      "Epoch: 835 Iteration: 77700. Train_MSE: 0.00025216859648935497. Test_MSE: [[[ 0.02755682  0.02262907  0.00489961  0.00188947]]]\n",
      "Epoch: 836 Iteration: 77800. Train_MSE: 0.00032826184178702533. Test_MSE: [[[ 0.02755353  0.02262642  0.00489957  0.00188907]]]\n",
      "Epoch: 837 Iteration: 77900. Train_MSE: 0.0003854831447824836. Test_MSE: [[[ 0.0275492   0.02262455  0.00489961  0.0018887 ]]]\n",
      "Epoch: 838 Iteration: 78000. Train_MSE: 0.000711217347998172. Test_MSE: [[[ 0.02754457  0.02262232  0.00489951  0.00188855]]]\n",
      "Epoch: 839 Iteration: 78100. Train_MSE: 0.00031694481731392443. Test_MSE: [[[ 0.02754069  0.02262126  0.00489919  0.00188849]]]\n",
      "Epoch: 840 Iteration: 78200. Train_MSE: 0.00034133318695239723. Test_MSE: [[[ 0.02753623  0.02261689  0.00489888  0.00188868]]]\n",
      "Epoch: 841 Iteration: 78300. Train_MSE: 0.000570189265999943. Test_MSE: [[[ 0.02753242  0.02261472  0.00489873  0.00188868]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 843 Iteration: 78400. Train_MSE: 0.0002734962326940149. Test_MSE: [[[ 0.02752947  0.02261198  0.00489867  0.00188828]]]\n",
      "Epoch: 844 Iteration: 78500. Train_MSE: 0.0005229117232374847. Test_MSE: [[[ 0.02752657  0.02260991  0.0048987   0.00188793]]]\n",
      "Epoch: 845 Iteration: 78600. Train_MSE: 0.0007206941372714937. Test_MSE: [[[ 0.02752226  0.0226086   0.00489862  0.00188758]]]\n",
      "Epoch: 846 Iteration: 78700. Train_MSE: 0.0005349633283913136. Test_MSE: [[[ 0.02751832  0.02260764  0.00489842  0.00188753]]]\n",
      "Epoch: 847 Iteration: 78800. Train_MSE: 0.0008162753074429929. Test_MSE: [[[ 0.02751493  0.02260579  0.0048981   0.00188763]]]\n",
      "Epoch: 848 Iteration: 78900. Train_MSE: 0.011790120974183083. Test_MSE: [[[ 0.02751004  0.02260227  0.00489771  0.00188786]]]\n",
      "Epoch: 849 Iteration: 79000. Train_MSE: 0.0002615003613755107. Test_MSE: [[[ 0.02750633  0.02259972  0.00489764  0.00188777]]]\n",
      "Epoch: 850 Iteration: 79100. Train_MSE: 0.0003157858154736459. Test_MSE: [[[ 0.02750317  0.02259723  0.00489763  0.00188737]]]\n",
      "Epoch: 851 Iteration: 79200. Train_MSE: 0.0007839251193217933. Test_MSE: [[[ 0.02749926  0.02259503  0.00489764  0.00188698]]]\n",
      "Epoch: 852 Iteration: 79300. Train_MSE: 0.002341283019632101. Test_MSE: [[[ 0.02749465  0.02259286  0.00489751  0.00188675]]]\n",
      "Epoch: 853 Iteration: 79400. Train_MSE: 0.0003704184200614691. Test_MSE: [[[ 0.02749086  0.02259206  0.00489727  0.00188667]]]\n",
      "Epoch: 854 Iteration: 79500. Train_MSE: 0.010235521011054516. Test_MSE: [[[ 0.02748663  0.02258814  0.00489697  0.00188682]]]\n",
      "Epoch: 855 Iteration: 79600. Train_MSE: 0.0003766768495552242. Test_MSE: [[[ 0.02748303  0.02258572  0.00489682  0.0018869 ]]]\n",
      "Epoch: 856 Iteration: 79700. Train_MSE: 0.00026551977498456836. Test_MSE: [[[ 0.02747997  0.02258315  0.00489675  0.00188662]]]\n",
      "Epoch: 858 Iteration: 79800. Train_MSE: 0.0004107112472411245. Test_MSE: [[[ 0.02747734  0.02258088  0.00489674  0.00188621]]]\n",
      "Epoch: 859 Iteration: 79900. Train_MSE: 0.0002774735039565712. Test_MSE: [[[ 0.02747365  0.02257934  0.00489671  0.00188592]]]\n",
      "Epoch: 860 Iteration: 80000. Train_MSE: 0.000425641774199903. Test_MSE: [[[ 0.02746943  0.02257825  0.00489652  0.00188577]]]\n",
      "Epoch: 861 Iteration: 80100. Train_MSE: 0.0003883567114826292. Test_MSE: [[[ 0.02746632  0.02257735  0.00489621  0.00188579]]]\n",
      "Epoch: 862 Iteration: 80200. Train_MSE: 0.0006425096071325243. Test_MSE: [[[ 0.02746228  0.0225743   0.0048959   0.00188598]]]\n",
      "Epoch: 863 Iteration: 80300. Train_MSE: 0.004484604112803936. Test_MSE: [[[ 0.02745788  0.02257103  0.00489569  0.00188611]]]\n",
      "Epoch: 864 Iteration: 80400. Train_MSE: 0.00027358514489606023. Test_MSE: [[[ 0.02745505  0.02256866  0.00489571  0.00188567]]]\n",
      "Epoch: 865 Iteration: 80500. Train_MSE: 0.0009811867494136095. Test_MSE: [[[ 0.02745158  0.02256622  0.0048957   0.00188533]]]\n",
      "Epoch: 866 Iteration: 80600. Train_MSE: 0.00043174863094463944. Test_MSE: [[[ 0.02744732  0.0225648   0.0048957   0.00188496]]]\n",
      "Epoch: 867 Iteration: 80700. Train_MSE: 0.00046391438809223473. Test_MSE: [[[ 0.02744321  0.02256312  0.00489543  0.00188496]]]\n",
      "Epoch: 868 Iteration: 80800. Train_MSE: 0.00042646614019759. Test_MSE: [[[ 0.02743992  0.02256118  0.00489514  0.00188502]]]\n",
      "Epoch: 869 Iteration: 80900. Train_MSE: 0.00028637979994527996. Test_MSE: [[[ 0.02743563  0.02255713  0.00489491  0.0018852 ]]]\n",
      "Epoch: 870 Iteration: 81000. Train_MSE: 0.00030963050085119903. Test_MSE: [[[ 0.02743231  0.02255494  0.00489482  0.00188502]]]\n",
      "Epoch: 872 Iteration: 81100. Train_MSE: 0.0002810735022649169. Test_MSE: [[[ 0.02742987  0.02255249  0.00489478  0.00188462]]]\n",
      "Epoch: 873 Iteration: 81200. Train_MSE: 0.000572462915442884. Test_MSE: [[[ 0.02742659  0.02255067  0.00489472  0.00188434]]]\n",
      "Epoch: 874 Iteration: 81300. Train_MSE: 0.0009067300125025213. Test_MSE: [[[ 0.02742248  0.02254947  0.00489462  0.00188412]]]\n",
      "Epoch: 875 Iteration: 81400. Train_MSE: 0.00040001387242227793. Test_MSE: [[[ 0.02741946  0.02254908  0.00489435  0.00188408]]]\n",
      "Epoch: 876 Iteration: 81500. Train_MSE: 0.00037464938941411674. Test_MSE: [[[ 0.02741574  0.02254617  0.00489401  0.00188429]]]\n",
      "Epoch: 877 Iteration: 81600. Train_MSE: 0.00038016517646610737. Test_MSE: [[[ 0.02741162  0.02254318  0.00489378  0.00188443]]]\n",
      "Epoch: 878 Iteration: 81700. Train_MSE: 0.00025507487589493394. Test_MSE: [[[ 0.02740838  0.0225407   0.00489373  0.00188416]]]\n",
      "Epoch: 879 Iteration: 81800. Train_MSE: 0.0003483376931399107. Test_MSE: [[[ 0.02740527  0.02253821  0.0048937   0.00188379]]]\n",
      "Epoch: 880 Iteration: 81900. Train_MSE: 0.00044750620145350695. Test_MSE: [[[ 0.0274013   0.02253651  0.00489371  0.00188347]]]\n",
      "Epoch: 881 Iteration: 82000. Train_MSE: 0.00048113896627910435. Test_MSE: [[[ 0.02739719  0.02253469  0.00489356  0.00188336]]]\n",
      "Epoch: 882 Iteration: 82100. Train_MSE: 0.000538053922355175. Test_MSE: [[[ 0.02739387  0.02253364  0.00489322  0.00188335]]]\n",
      "Epoch: 883 Iteration: 82200. Train_MSE: 0.00034739539842121303. Test_MSE: [[[ 0.02738979  0.02252935  0.00489294  0.00188354]]]\n",
      "Epoch: 884 Iteration: 82300. Train_MSE: 0.00035460374783724546. Test_MSE: [[[ 0.02738645  0.02252727  0.00489281  0.00188349]]]\n",
      "Epoch: 886 Iteration: 82400. Train_MSE: 0.000304181594401598. Test_MSE: [[[ 0.02738387  0.02252473  0.00489274  0.00188312]]]\n",
      "Epoch: 887 Iteration: 82500. Train_MSE: 0.0021044223103672266. Test_MSE: [[[ 0.02738102  0.02252265  0.0048927   0.00188287]]]\n",
      "Epoch: 888 Iteration: 82600. Train_MSE: 0.0012014118256047368. Test_MSE: [[[ 0.02737719  0.02252151  0.00489265  0.00188254]]]\n",
      "Epoch: 889 Iteration: 82700. Train_MSE: 0.0003451834199950099. Test_MSE: [[[ 0.02737381  0.02252105  0.00489239  0.00188249]]]\n",
      "Epoch: 890 Iteration: 82800. Train_MSE: 0.008991275914013386. Test_MSE: [[[ 0.02737033  0.02251867  0.00489201  0.00188268]]]\n",
      "Epoch: 891 Iteration: 82900. Train_MSE: 0.00028109850245527923. Test_MSE: [[[ 0.02736627  0.0225157   0.00489171  0.00188285]]]\n",
      "Epoch: 892 Iteration: 83000. Train_MSE: 0.00037988825351931155. Test_MSE: [[[ 0.02736294  0.0225133   0.00489165  0.00188272]]]\n",
      "Epoch: 893 Iteration: 83100. Train_MSE: 0.00039951232611201704. Test_MSE: [[[ 0.02736026  0.02251083  0.00489162  0.00188235]]]\n",
      "Epoch: 894 Iteration: 83200. Train_MSE: 0.000405577797209844. Test_MSE: [[[ 0.0273564   0.02250887  0.00489162  0.00188202]]]\n",
      "Epoch: 895 Iteration: 83300. Train_MSE: 0.0006751830223947763. Test_MSE: [[[ 0.02735229  0.02250694  0.00489148  0.00188185]]]\n",
      "Epoch: 896 Iteration: 83400. Train_MSE: 0.0004291580116841942. Test_MSE: [[[ 0.0273489   0.02250609  0.00489121  0.00188179]]]\n",
      "Epoch: 897 Iteration: 83500. Train_MSE: 0.00026323218480683863. Test_MSE: [[[ 0.02734507  0.02250241  0.00489089  0.00188196]]]\n",
      "Epoch: 898 Iteration: 83600. Train_MSE: 0.0002819370711222291. Test_MSE: [[[ 0.02734178  0.02250019  0.00489075  0.00188202]]]\n",
      "Epoch: 899 Iteration: 83700. Train_MSE: 0.00034791685175150633. Test_MSE: [[[ 0.02733915  0.02249766  0.00489067  0.00188172]]]\n",
      "Epoch: 901 Iteration: 83800. Train_MSE: 0.00025892400299198925. Test_MSE: [[[ 0.02733684  0.02249569  0.00489067  0.00188137]]]\n",
      "Epoch: 902 Iteration: 83900. Train_MSE: 0.0004388187371660024. Test_MSE: [[[ 0.02733337  0.02249449  0.00489059  0.0018811 ]]]\n",
      "Epoch: 903 Iteration: 84000. Train_MSE: 0.0005359826027415693. Test_MSE: [[[ 0.02732961  0.02249335  0.00489042  0.00188102]]]\n",
      "Epoch: 904 Iteration: 84100. Train_MSE: 0.0006274004117585719. Test_MSE: [[[ 0.02732677  0.02249244  0.00489005  0.00188106]]]\n",
      "Epoch: 905 Iteration: 84200. Train_MSE: 0.0006141894846223295. Test_MSE: [[[ 0.02732294  0.02248962  0.00488972  0.00188125]]]\n",
      "Epoch: 906 Iteration: 84300. Train_MSE: 0.0003541083715390414. Test_MSE: [[[ 0.02731915  0.02248652  0.00488954  0.00188135]]]\n",
      "Epoch: 907 Iteration: 84400. Train_MSE: 0.0019824132323265076. Test_MSE: [[[ 0.02731642  0.02248419  0.00488953  0.00188098]]]\n",
      "Epoch: 908 Iteration: 84500. Train_MSE: 0.0004409480025060475. Test_MSE: [[[ 0.02731326  0.02248215  0.00488952  0.00188063]]]\n",
      "Epoch: 909 Iteration: 84600. Train_MSE: 0.005773394834250212. Test_MSE: [[[ 0.02730905  0.02248044  0.0048894   0.00188035]]]\n",
      "Epoch: 910 Iteration: 84700. Train_MSE: 0.00038043659878894687. Test_MSE: [[[ 0.02730567  0.02247952  0.0048892   0.00188033]]]\n",
      "Epoch: 911 Iteration: 84800. Train_MSE: 0.0012977691367268562. Test_MSE: [[[ 0.02730245  0.02247681  0.00488888  0.00188043]]]\n",
      "Epoch: 912 Iteration: 84900. Train_MSE: 0.00025227051810361445. Test_MSE: [[[ 0.02729884  0.02247365  0.00488866  0.0018806 ]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 913 Iteration: 85000. Train_MSE: 0.00037530812551267445. Test_MSE: [[[ 0.02729599  0.02247133  0.0048886   0.00188039]]]\n",
      "Epoch: 915 Iteration: 85100. Train_MSE: 0.00028578852652572095. Test_MSE: [[[ 0.02729381  0.0224692   0.00488856  0.00188   ]]]\n",
      "Epoch: 916 Iteration: 85200. Train_MSE: 0.0003689959994517267. Test_MSE: [[[ 0.02729063  0.02246774  0.00488848  0.00187975]]]\n",
      "Epoch: 917 Iteration: 85300. Train_MSE: 0.0007084750104695559. Test_MSE: [[[ 0.027287    0.02246687  0.00488832  0.00187958]]]\n",
      "Epoch: 918 Iteration: 85400. Train_MSE: 0.0004642304847948253. Test_MSE: [[[ 0.02728435  0.02246629  0.00488803  0.00187959]]]\n",
      "Epoch: 919 Iteration: 85500. Train_MSE: 0.0003591539280023426. Test_MSE: [[[ 0.02728111  0.0224636   0.00488771  0.00187982]]]\n",
      "Epoch: 920 Iteration: 85600. Train_MSE: 0.0005124440649524331. Test_MSE: [[[ 0.02727721  0.0224606   0.00488752  0.00187995]]]\n",
      "Epoch: 921 Iteration: 85700. Train_MSE: 0.00024287510314024985. Test_MSE: [[[ 0.02727446  0.02245824  0.00488748  0.00187963]]]\n",
      "Epoch: 922 Iteration: 85800. Train_MSE: 0.00027446754393167794. Test_MSE: [[[ 0.02727165  0.02245598  0.00488745  0.00187928]]]\n",
      "Epoch: 923 Iteration: 85900. Train_MSE: 0.0003995988517999649. Test_MSE: [[[ 0.02726796  0.02245451  0.00488745  0.00187901]]]\n",
      "Epoch: 924 Iteration: 86000. Train_MSE: 0.0004385797947179526. Test_MSE: [[[ 0.02726426  0.02245302  0.00488723  0.00187896]]]\n",
      "Epoch: 925 Iteration: 86100. Train_MSE: 0.0005297978059388697. Test_MSE: [[[ 0.02726139  0.02245178  0.00488689  0.001879  ]]]\n",
      "Epoch: 926 Iteration: 86200. Train_MSE: 0.002260240726172924. Test_MSE: [[[ 0.02725752  0.02244743  0.00488666  0.00187921]]]\n",
      "Epoch: 927 Iteration: 86300. Train_MSE: 0.0002960741985589266. Test_MSE: [[[ 0.02725464  0.02244564  0.00488655  0.00187911]]]\n",
      "Epoch: 929 Iteration: 86400. Train_MSE: 0.0003157432365696877. Test_MSE: [[[ 0.02725251  0.02244331  0.00488648  0.00187874]]]\n",
      "Epoch: 930 Iteration: 86500. Train_MSE: 0.0004614827339537442. Test_MSE: [[[ 0.02725002  0.02244162  0.00488642  0.00187852]]]\n",
      "Epoch: 931 Iteration: 86600. Train_MSE: 0.0015695937909185886. Test_MSE: [[[ 0.02724645  0.0224405   0.00488638  0.00187826]]]\n",
      "Epoch: 932 Iteration: 86700. Train_MSE: 0.0003319941752124578. Test_MSE: [[[ 0.02724363  0.0224404   0.00488607  0.00187821]]]\n",
      "Epoch: 933 Iteration: 86800. Train_MSE: 0.0014555881498381495. Test_MSE: [[[ 0.02724049  0.02243793  0.00488575  0.0018784 ]]]\n",
      "Epoch: 934 Iteration: 86900. Train_MSE: 0.0002901222906075418. Test_MSE: [[[ 0.02723687  0.02243502  0.0048855   0.00187857]]]\n",
      "Epoch: 935 Iteration: 87000. Train_MSE: 0.000238999433349818. Test_MSE: [[[ 0.02723398  0.02243274  0.00488544  0.00187839]]]\n",
      "Epoch: 936 Iteration: 87100. Train_MSE: 0.0003088967932853848. Test_MSE: [[[ 0.02723153  0.02243044  0.0048854   0.00187806]]]\n",
      "Epoch: 937 Iteration: 87200. Train_MSE: 0.0003565124061424285. Test_MSE: [[[ 0.02722813  0.02242893  0.00488543  0.00187774]]]\n",
      "Epoch: 938 Iteration: 87300. Train_MSE: 0.0006865581381134689. Test_MSE: [[[ 0.02722444  0.02242711  0.00488532  0.00187763]]]\n",
      "Epoch: 939 Iteration: 87400. Train_MSE: 0.0002999603748321533. Test_MSE: [[[ 0.02722156  0.02242639  0.00488501  0.00187759]]]\n",
      "Epoch: 940 Iteration: 87500. Train_MSE: 0.0003279205702710897. Test_MSE: [[[ 0.02721805  0.02242238  0.00488471  0.00187779]]]\n",
      "Epoch: 941 Iteration: 87600. Train_MSE: 0.0005404666299000382. Test_MSE: [[[ 0.02721509  0.02242048  0.00488457  0.00187783]]]\n",
      "Epoch: 943 Iteration: 87700. Train_MSE: 0.00025908779934979975. Test_MSE: [[[ 0.02721297  0.02241809  0.00488451  0.00187748]]]\n",
      "Epoch: 944 Iteration: 87800. Train_MSE: 0.0004977537901140749. Test_MSE: [[[ 0.02721091  0.02241639  0.00488453  0.00187719]]]\n",
      "Epoch: 945 Iteration: 87900. Train_MSE: 0.0006699711084365845. Test_MSE: [[[ 0.02720753  0.02241544  0.00488444  0.00187689]]]\n",
      "Epoch: 946 Iteration: 88000. Train_MSE: 0.0005023542908020318. Test_MSE: [[[ 0.02720453  0.02241486  0.00488422  0.00187687]]]\n",
      "Epoch: 947 Iteration: 88100. Train_MSE: 0.0008001381647773087. Test_MSE: [[[ 0.02720209  0.02241338  0.00488391  0.00187698]]]\n",
      "Epoch: 948 Iteration: 88200. Train_MSE: 0.011761711910367012. Test_MSE: [[[ 0.02719813  0.02241014  0.00488355  0.00187723]]]\n",
      "Epoch: 949 Iteration: 88300. Train_MSE: 0.00024091906379908323. Test_MSE: [[[ 0.02719527  0.0224079   0.00488347  0.00187718]]]\n",
      "Epoch: 950 Iteration: 88400. Train_MSE: 0.000292951735900715. Test_MSE: [[[ 0.02719291  0.02240575  0.00488346  0.00187685]]]\n",
      "Epoch: 951 Iteration: 88500. Train_MSE: 0.0007457130122929811. Test_MSE: [[[ 0.02718987  0.02240391  0.00488347  0.00187652]]]\n",
      "Epoch: 952 Iteration: 88600. Train_MSE: 0.0023066841531544924. Test_MSE: [[[ 0.02718617  0.02240212  0.00488334  0.00187633]]]\n",
      "Epoch: 953 Iteration: 88700. Train_MSE: 0.0003467842470854521. Test_MSE: [[[ 0.02718331  0.02240166  0.0048831   0.00187627]]]\n",
      "Epoch: 954 Iteration: 88800. Train_MSE: 0.010222566314041615. Test_MSE: [[[ 0.02718     0.02239809  0.0048828   0.00187644]]]\n",
      "Epoch: 955 Iteration: 88900. Train_MSE: 0.00035207142354920506. Test_MSE: [[[ 0.02717723  0.02239595  0.00488265  0.00187654]]]\n",
      "Epoch: 956 Iteration: 89000. Train_MSE: 0.0002507486497052014. Test_MSE: [[[ 0.02717497  0.02239371  0.00488259  0.0018763 ]]]\n",
      "Epoch: 958 Iteration: 89100. Train_MSE: 0.0003771189658436924. Test_MSE: [[[ 0.02717314  0.02239179  0.00488257  0.00187596]]]\n",
      "Epoch: 959 Iteration: 89200. Train_MSE: 0.00024873114307411015. Test_MSE: [[[ 0.02717029  0.0223906   0.00488253  0.00187572]]]\n",
      "Epoch: 960 Iteration: 89300. Train_MSE: 0.00041008181869983673. Test_MSE: [[[ 0.02716699  0.0223899   0.00488234  0.00187559]]]\n",
      "Epoch: 961 Iteration: 89400. Train_MSE: 0.00036819675005972385. Test_MSE: [[[ 0.0271648   0.02238935  0.00488204  0.00187563]]]\n",
      "Epoch: 962 Iteration: 89500. Train_MSE: 0.0006165553350001574. Test_MSE: [[[ 0.02716166  0.02238663  0.00488175  0.00187584]]]\n",
      "Epoch: 963 Iteration: 89600. Train_MSE: 0.004470381885766983. Test_MSE: [[[ 0.02715807  0.02238365  0.00488155  0.00187599]]]\n",
      "Epoch: 964 Iteration: 89700. Train_MSE: 0.0002574716054368764. Test_MSE: [[[ 0.02715601  0.02238162  0.00488156  0.00187561]]]\n",
      "Epoch: 965 Iteration: 89800. Train_MSE: 0.0009543782216496766. Test_MSE: [[[ 0.02715334  0.02237953  0.00488156  0.00187533]]]\n",
      "Epoch: 966 Iteration: 89900. Train_MSE: 0.00039731402648612857. Test_MSE: [[[ 0.02714997  0.02237846  0.00488156  0.001875  ]]]\n",
      "Epoch: 967 Iteration: 90000. Train_MSE: 0.00044186730519868433. Test_MSE: [[[ 0.02714672  0.02237711  0.00488129  0.00187503]]]\n",
      "Epoch: 968 Iteration: 90100. Train_MSE: 0.00041171739576384425. Test_MSE: [[[ 0.02714432  0.02237551  0.00488101  0.0018751 ]]]\n",
      "Epoch: 969 Iteration: 90200. Train_MSE: 0.00026202143635600805. Test_MSE: [[[ 0.02714086  0.02237177  0.00488079  0.0018753 ]]]\n",
      "Epoch: 970 Iteration: 90300. Train_MSE: 0.0002916278608608991. Test_MSE: [[[ 0.02713831  0.02236987  0.00488071  0.00187515]]]\n",
      "Epoch: 972 Iteration: 90400. Train_MSE: 0.0002621837775222957. Test_MSE: [[[ 0.02713664  0.02236777  0.00488068  0.00187481]]]\n",
      "Epoch: 973 Iteration: 90500. Train_MSE: 0.0005301244091242552. Test_MSE: [[[ 0.02713419  0.02236631  0.00488062  0.00187458]]]\n",
      "Epoch: 974 Iteration: 90600. Train_MSE: 0.0008708235109224916. Test_MSE: [[[ 0.027131    0.02236547  0.00488053  0.00187439]]]\n",
      "Epoch: 975 Iteration: 90700. Train_MSE: 0.0003649175923783332. Test_MSE: [[[ 0.02712889  0.02236545  0.00488027  0.00187437]]]\n",
      "Epoch: 976 Iteration: 90800. Train_MSE: 0.00035203355946578085. Test_MSE: [[[ 0.0271261   0.02236289  0.00487995  0.00187458]]]\n",
      "Epoch: 977 Iteration: 90900. Train_MSE: 0.00036166873178444803. Test_MSE: [[[ 0.02712285  0.02236017  0.00487976  0.00187474]]]\n",
      "Epoch: 978 Iteration: 91000. Train_MSE: 0.00023366538516711444. Test_MSE: [[[ 0.02712041  0.022358    0.00487972  0.00187452]]]\n",
      "Epoch: 979 Iteration: 91100. Train_MSE: 0.0003224406682420522. Test_MSE: [[[ 0.0271181   0.02235587  0.00487971  0.0018742 ]]]\n",
      "Epoch: 980 Iteration: 91200. Train_MSE: 0.00041420827619731426. Test_MSE: [[[ 0.02711501  0.0223545   0.00487973  0.00187392]]]\n",
      "Epoch: 981 Iteration: 91300. Train_MSE: 0.00046453613322228193. Test_MSE: [[[ 0.02711177  0.02235303  0.00487957  0.00187384]]]\n",
      "Epoch: 982 Iteration: 91400. Train_MSE: 0.0005226420471444726. Test_MSE: [[[ 0.02710938  0.02235232  0.00487926  0.00187385]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 983 Iteration: 91500. Train_MSE: 0.000330286449752748. Test_MSE: [[[ 0.02710618  0.02234835  0.00487901  0.00187404]]]\n",
      "Epoch: 984 Iteration: 91600. Train_MSE: 0.0003279226366430521. Test_MSE: [[[ 0.02710366  0.02234654  0.0048789   0.00187403]]]\n",
      "Epoch: 986 Iteration: 91700. Train_MSE: 0.00028435405693016946. Test_MSE: [[[ 0.02710187  0.02234434  0.00487884  0.0018737 ]]]\n",
      "Epoch: 987 Iteration: 91800. Train_MSE: 0.002074234886094928. Test_MSE: [[[ 0.02709984  0.0223426   0.00487881  0.0018735 ]]]\n",
      "Epoch: 988 Iteration: 91900. Train_MSE: 0.0011727442033588886. Test_MSE: [[[ 0.02709693  0.02234181  0.00487878  0.0018732 ]]]\n",
      "Epoch: 989 Iteration: 92000. Train_MSE: 0.0003280674573034048. Test_MSE: [[[ 0.02709447  0.02234171  0.00487853  0.00187317]]]\n",
      "Epoch: 990 Iteration: 92100. Train_MSE: 0.008978566154837608. Test_MSE: [[[ 0.02709192  0.02233967  0.00487818  0.00187337]]]\n",
      "Epoch: 991 Iteration: 92200. Train_MSE: 0.00025990515132434666. Test_MSE: [[[ 0.02708877  0.02233698  0.00487793  0.00187355]]]\n",
      "Epoch: 992 Iteration: 92300. Train_MSE: 0.0003588796535041183. Test_MSE: [[[ 0.02708624  0.02233488  0.00487788  0.00187345]]]\n",
      "Epoch: 993 Iteration: 92400. Train_MSE: 0.00036913526128046215. Test_MSE: [[[ 0.02708436  0.02233274  0.00487786  0.00187314]]]\n",
      "Epoch: 994 Iteration: 92500. Train_MSE: 0.0003811231581494212. Test_MSE: [[[ 0.02708136  0.0223311   0.00487788  0.00187286]]]\n",
      "Epoch: 995 Iteration: 92600. Train_MSE: 0.0006602706853300333. Test_MSE: [[[ 0.02707816  0.02232954  0.00487776  0.00187271]]]\n",
      "Epoch: 996 Iteration: 92700. Train_MSE: 0.00041486843838356435. Test_MSE: [[[ 0.0270757   0.02232902  0.00487753  0.00187266]]]\n",
      "Epoch: 997 Iteration: 92800. Train_MSE: 0.00024588132509961724. Test_MSE: [[[ 0.0270728   0.02232568  0.00487724  0.00187284]]]\n",
      "Epoch: 998 Iteration: 92900. Train_MSE: 0.00026624518795870245. Test_MSE: [[[ 0.02707033  0.02232371  0.00487712  0.00187291]]]\n",
      "Epoch: 999 Iteration: 93000. Train_MSE: 0.0003266619169153273. Test_MSE: [[[ 0.02706849  0.02232151  0.00487706  0.00187266]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type RNNModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "if run_train:\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    X_train = X_train.type(torch.FloatTensor)\n",
    "    y_train = y_train.type(torch.FloatTensor)\n",
    "    # Training the model\n",
    "    seq_dim = 1\n",
    "\n",
    "    n_iter =0\n",
    "    num_samples = len(X_train)\n",
    "    test_samples = len(X_test)\n",
    "    batch_size = 100\n",
    "    num_epochs = 1000\n",
    "    feat_dim = X_train.shape[1]\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, int(num_samples/batch_size -1)):\n",
    "\n",
    "\n",
    "            features = Variable(X_train[i*batch_size:(i+1)*batch_size, :]).view(-1, seq_dim, feat_dim)\n",
    "            Kt_value = Variable(y_train[i*batch_size:(i+1)*batch_size])\n",
    "\n",
    "            #print(\"Kt_value={}\".format(Kt_value))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(features)\n",
    "            #print(\"outputs ={}\".format(outputs))\n",
    "\n",
    "            loss = criterion(outputs, Kt_value)\n",
    "\n",
    "            train_loss.append(loss.data[0])\n",
    "            train_iter.append(n_iter)\n",
    "\n",
    "            #print(\"loss = {}\".format(loss))\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            n_iter += 1  \n",
    "            test_batch_mse =list()    \n",
    "            if n_iter%100 == 0:\n",
    "                for i in range(0,int(test_samples/batch_size -1)):\n",
    "                    features = Variable(X_test[i*batch_size:(i+1)*batch_size, :]).view(-1, seq_dim, feat_dim)\n",
    "                    Kt_test = Variable(y_test[i*batch_size:(i+1)*batch_size])\n",
    "\n",
    "                    outputs = model(features)\n",
    "\n",
    "                    test_batch_mse.append(np.mean([(Kt_test.data.numpy() - outputs.data.numpy().squeeze())**2],axis=1))\n",
    "\n",
    "                test_iter.append(n_iter)\n",
    "                test_loss.append(np.mean([test_batch_mse],axis=1))\n",
    "\n",
    "                print('Epoch: {} Iteration: {}. Train_MSE: {}. Test_MSE: {}'.format(epoch, n_iter, loss.data[0], test_loss[-1]))       \n",
    "    torch.save(model,'RNN Paper Results/Exp2_1/' + test_location + '/'+  test_year + 'torch_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST TEST CELL\n",
    "\n",
    "batch_size = 100\n",
    "seq_dim = 1\n",
    "test_samples = len(X_test)\n",
    "batch_size = 100\n",
    "feat_dim = X_test.shape[1]\n",
    "\n",
    "# initializing lists to store losses over epochs:\n",
    "test_loss = []\n",
    "test_iter = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,int(test_samples/batch_size -1)):\n",
    "    features = Variable(X_test[i*batch_size:(i+1)*batch_size, :]).view(-1, seq_dim, feat_dim)\n",
    "    Kt_test = Variable(y_test[i*batch_size:(i+1)*batch_size])\n",
    "                \n",
    "    outputs = model(features)\n",
    "                \n",
    "    test_batch_mse.append(np.mean([(Kt_test.data.numpy() - outputs.data.numpy().squeeze())**2],axis=1))\n",
    "                \n",
    "    test_iter.append(n_iter)\n",
    "    test_loss.append(np.mean([test_batch_mse],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSTVj8EtSzRj8klQzBr8k1YzBL0k18/8BILiabzYgrCAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f079932deb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if run_train:\n",
    "    print(len(train_loss))\n",
    "    plt.plot(train_loss,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmQHPWd5/131n109d3q49etk5ZaByBASEKctpFRM4Cw\n18uAZ8eAPcZ+nsExM+FndxzeiLVjJ3aDnViPh33CgRd7WMOzPBzjA4SQuMQhc1ogkNAJQmf/utX3\nWV135f6RWdXVravU6u7qVn9fQZF31i+7SvnJ/GVW/gzTNBFCCCEchS6AEEKI6UECQQghBCCBIIQQ\nwiaBIIQQApBAEEIIYZNAEEIIAUggCCGEsEkgCCGEACQQhBBC2FyFLsD5WLFihdnQ0FDoYgghxIyy\ne/fuLq111bnmm1GB0NDQwNatWwtdDCGEmFGUUsfymU+qjIQQQgASCEIIIWx5VRkppTYADwNO4Nda\n64fGTDfs6bcCw8B9WuudSikfsB3w2u/1W631T+xlyoFngPnAUeAurXXvBGyTEEKIcTjnGYJSygn8\nAmgGlgH3KKWWjZmtGWi0Xw8Aj9jjY8CXtdaXAyuBDUqptfa0HwHbtNaNwDZ7WAghRIHkU2W0Gjik\ntT6stY4DTwMbx8yzEXhCa21qrd8HSpVStfbwkD2P236ZOcs8bvc/Dtx5IRsihBDiwuQTCAo4kTPc\nYo/Lax6llFMp9QnQAbyqtf7Anqdaa91m958Eqs+z7EIIISbQpF9U1lqntNYrgXpgtVJqxWnmMRk5\ncxhFKfWAUupDpdSH3d3dk1xaIYSYvfK5qKyB3F+D1dvjzmserXWfUuoNYAOwB2i3q5XalFK1WGcQ\np7651o8CjwI0NzdLe59CTJJULEbPBzuIdXTgLi3FXVqCp6wMd2kpntISDKez0EUUkyyfQNgBNCql\nFmDt5O8Gvjlmnk3Ag0qpp4E1QL+9o68CEnYY+IH1wH/LWeZe4CG7+/wFb40Q4ryY6TT9e/bS+cZb\ndL/3PqlI5PQzGgbu4pAdFKV4ykrxlJfjq63FX1eLr7YWT3kZhmFM7QaICXXOQNBaJ5VSDwIvY912\n+pjWeq9S6vv29F8CW7BuOT2Eddvp/fbitcDj9p1KDuBZrfVme9pDwLNKqe8Ax4C7Jm6zhBBnM3z8\nOB1vvEXnW38k3t2N0++nYt01VN10A6HGS0gMDBDv7SPR20e8r5dEX7813NdLvLePgbY24j29mMlk\ndp0OrxdfbQ3+2lp8dSNB4ZtTBYYDzDSmadqVwyZm2q4pNq1+w2HgLi3FFQgU6s8y6xmmOXNqYZqb\nm015dIUQ4xPv66Nr+9t0vPkW4S8Og8NB2RUrqbrpRsrXXI3T6z2v9ZmpFLGuLiKtbURb24i0Zbon\nibW3Y6ZS4yqn0+/HU1GBp6Icr931VFTgrRwZ5youlrOR86CU+khrvepc882oZxkJIfKXisUY+uxz\n+vfuY2DPXvr37oN0muCiRSz4q/upvP46PKWl416/4XTiq67GV10NV6wcNc1MpYh2dBJtayPWZd0M\nYhjZ/2E4rC4GYDgwDAMznSLe20e8p4d4Vzex7m76du0m3tsL6fSo9XvKywk1LSHUtJjipiaCCxfg\ncLvHvS3CIoEgxEUiGQ4zeOCgFQB79zF06AurSscwCC6YT/3X76TqphsJNNRPelkMpxN/bQ3+2poL\nXpeZShHv6yfe3U28u4doRwdDh75g8MBBut99z3o/l4uiRYsILV1CaIkVEp7ysgt+79lGAkGIGSox\nMMjA3n1WAOzbR/jIUUinMZxOii65hLo7bqN4+TKKm5pwFQULXdxxM5xOvBXleCvKT5kW7+ll8OBB\nBg4cZPDgZ7S9uJXW5zYB4J1TRaipieKlTRQvayLQ0CB3Sp2DBIIQM0Q2APbsoX/PXoaPWk80dng8\nhJYspuGub1C8fBmhxY04fb4Cl3ZqeMrLqLhmLRXXWE/ESScShA8fsQLiwEH6P91D1/Y/AuAMBggt\nWWIFxNImihY3nvd1k4udBIIQ01RiMBMAexnYs5fw0WNgmlYALG1i7l/cQ8mK5RQ1XiL15zaH201o\nyWJCSxbDxtsxTZNYRwcD+w8wsO8Ag/v3c/zJpwDrzCO4aKF9BrGU4uXLcIdCBd6CwpJAEGIaiff1\n0/mWdTto+PCRkQBoWsLcb94tAXCeDMPIXviec9ONgBW0gwc/Y3D/AQb27adty0u0Pv8CAIF5cylZ\nsYLiFcsoWb4Md0lJIYs/5SQQhCiwdDJJ70c76dj2Or0f7sRMpShqbJQAmCTuUIjyVVdRvuoqwKpm\nGvr8kHUmtncf7a9to+3FLQD4G+opWbGCkhXLKF6x/ILuypoJJBCEKJDwseN0bHudzje3k+jvx11a\nSt0dtzHny18iMFfaDp8qDrfbqjJathSwAnro0BfZW3U73niTk1tfAsBfryi59FJKLltByYoVuIsv\nriomCQQhplByaIjO7W/Tse11hg59geFyUX71Vcz5ypcpvWIlDpf8kyw0h8tFcdMSipuWUP+Nr2Om\nUgx9cTh7LSc3IIIL5lNy6QpKLruU4uXLZvyvrOXbJ8QkSycS9O78mM43t9Oz40PMRILggvks+Kv7\nqbrh+llXTz3TGE4nocWNhBY3wtfvzJ5B9O/+lP5P99C29WVaN20Gh4OiSxZRcukKSi+7lNDSphl3\nF5MEghCTwDRNBg8cpPOt7XS9/Q7JwSHcJcXUfHU9c27+EkULFxa6iGKccs8gGu76Bul4nMGDn9Fn\nB0Trc5vQv/sDhstFaHEjxSuWU3LpCoqbluDweApd/LOSQBBiAkV0K51vbafzre1ET7bj8HgoX7ua\nqhtvoHTl5VIldBFyeDxWtdGlVlMvqUiEgf0H6P90D/2f7qHlt7+n5dnfYti3xGbmDS1unHY3C8i3\nU4gLlByO0PnGG3S8sZ2hzz8Hw6Dksktp+PO7KF+7BlfAX+giiink9Pspu/IKyq68ArAeKTKwb382\nIE48/Swnnnom+3uSkhXLp83dZBIIQoyTmU7T+eZbHH3if5Po7SO4YD7z77+XyuuvxVtRUejiiWnC\nFQxSfvUqyq+2HjaaGBwcFRCZH8plfnFebAdEaHHjlFcxSSAIMQ6DBz/j8K8eY+jzzylqbKTpR/+B\n4qYlhS6WmAHcoRAVa1ZTsWY1YD+SZN8++vfsY2DvXusMwjRHqpiWW7+BCC1ZPOkXqSUQhDgPse5u\njj3xJJ1vvoW7rIzGv/0BVTfegOGY9ObJxUXKXRyiYu0aKtauAaxbkwf27ad/z1769+zjxL/+Dp75\nV5p+/PfZEJksEghC5CEdj6Off4GW3/4eM5mk/htfp/4bX8fpl+sDYmK5ioooX3015auvBuxrEPsP\nULy0afLfe9LfQYgZzDRNet7/gCOPPU6so4OKa9Yw/75v4au58Of8C5EPVzCYfczGpL/XlLyLEDPQ\n4OeHOPb4/0f/p3sIzJvL8v/8E0ovv6zQxRJi0syKQBg6fITk0BAll66QdljFWZnpNL0f7UT/4XkG\n9u7DFSpi4fe+S80t66VxFXHRmxWB0Pr8Jjrf3E5w0ULUnXdQse4a+YGQGCUdj9P51nb0cy8QaWnB\nU1nJ/G/fS/X6m2f882mEyNes2Cte8tf/F8XLl9H63CY++9k/433if1N7+232P3a5KDibJYeGaNv6\nMm2bt5Dos35L0Ph3f0PldevkoEHMOrPiG+/weKj56nqqb/4KvR9+hH5uE0cf+w0nnnmWmlu+Su1t\nt8oPiWaZaHsHrZteoP2110lHo5ResRJ15x2UXH6ZVCuKWWtWBEKG4XBkb+ca/Oxz9HOb0M9tonXT\nZqpuuI66jXcQnD+v0MUU5ykxOGi1frX/AIm+PtLJJGYyhZlMYqaSpBNJuz9lTUskGG7RGIZB5fXX\nob52B8H58wu9GUIU3KwKhFyhxY00/YcfEm1vp3XTZtpf3UbH629SuvJy6jbeTunKy+XHRtNUrLOT\ngX0HGNi3j4H9Bxg+dhwAw+XCU1aK4XZjOJ04XG4MlxPD5cJwOnF6PLjcLgyni7KrV1F7azPeSjkz\nFCLDME2z0GXIW3Nzs7l169ZJWXdicJCTL71C24tbSPT24Vd11N7+Z8z50k04fb5JeU+Rn+jJk/R+\nvMtuA3cfsc4uwHqIWKhpid1A+lKKLrlkxj1/XoipoJT6SGu96lzzSSCMkU4k6HrnPdpe2MzQoS9w\nBoPUfPVmav+sGW9V1aS+txjNTKVo+d0fOPH0s5ipFO6yUrupw2UUL2siOG+e3AoqRB7yDYS8qoyU\nUhuAhwEn8Gut9UNjphv29FuBYeA+rfVOpVQD8ARQDZjAo1rrh+1lfgp8F+i0V/NjrfWWfMozmRxu\nN3NuuoGqG69n8MBBWl/YjH7+BfTzL1Cxdg11t/8ZoaVNcuFxkkU7Ovj85/+DgX37qbzhOuZ+8258\nNTXydxdiEp0zEJRSTuAXwHqgBdihlNqktd6XM1sz0Gi/1gCP2N0k8EM7HELAR0qpV3OW/bnW+r9P\n3OZMHMMwKF7aRPHSJmKdnbRteYn2V16j+933CC5aRN3tt1J53bUFf375xajjze0c/p+/AqDx7/6G\nOTfdUOASCTE75HOGsBo4pLU+DKCUehrYCOQGwkbgCa21CbyvlCpVStVqrduANgCt9aBSaj+gxiw7\n7Xmrqph/71/S8Of/lo433qJt84t8/s//L0cee5zqm79MzS3r5dk2EyA5FOaL//krurb/kdDSJhb/\n3d/gq55T6GIJMWvkEwgKOJEz3IJ19H+ueRR2GAAopeYDVwAf5Mz3A6XUt4APsc4kek95c6UeAB6w\n+/Mo7uRx+nzUNt9CzS3r6d/9KW1bX7ZuXf3D85ResZKaDbdQvupKqdceh/69+/j85w8T6+5h7l/c\nQ/2/+Zr8HYWYYlNy26lSqgj4HfC3WusBe/QjwD9gXVv4B+BnwLfHLqu1fhR4FKyLylNR3nMxHA5K\nV15O6crLiXV30/7Ka7S/8hoH/utDeCorqbllPdXrv4KnrKzQRZ320skkJ556hpbfP4eveg6XPfRf\nCC1ZXOhiCTEr5RMIGmjIGa63x+U1j1LKjRUGT2qtf59dQOv2TL9S6lfA5vMq+TThrahg7j1/Tv2/\n/Tf07viQtq0vc/zJpzjx9LOUr11NzYZbKFmxXH7TcBoR3cpn//TPDB36gjk3f4WFf3W/tC8gRAHl\nEwg7gEal1AKsnfzdwDfHzLMJeNC+vrAG6Ndat9l3H/0LsF9r/U+5C+RcYwD4GrDnAraj4BwuFxXX\nrKXimrVEdCsnX36Fjm1v0P3Oe3irKqm87loqr7uW4KKFs/5OmcTAAPoPz9O2eQsOr4emH/17Kq5Z\nW+hiCTHrnTMQtNZJpdSDwMtYt50+prXeq5T6vj39l8AWrFtOD2Hddnq/vfi1wF8CnyqlPrHHZW4v\n/Uel1EqsKqOjwPcmbKsKzK/qWPDt+5j7F/fQ/d4HdL39Nq0vvIj+w/P4amuovP46KxzmzS10UadU\nciiMft56VEg6FqPqxuuZ961/J8+REmKakB+mTZHE4CA9739A5x/fof/TPZBOE5jbYIfDOvx1dYUu\n4qRJDkdo2/wi+rlNpMJhKq69hrl3/zmBuQ3nXlgIccEm9Idp4sK5QyGq199M9fqbiff10f3u+3T9\n8W2OP/kUx598iuDCBfjr6jDcbhxuFw632+p3uexxbgyXNR7DANME08Q0TTDTmGl7OJ3OTgOyz/Ex\nXE4MpwuH3bWGref8ODwe3MXFuEuKcYVCE/bY51QsRtuLW9G/f47k4CDlq69m7jfvJrhg/oSsXwgx\nsSQQCsBTWkrtrRuovXUDsa5uut55l573P2Do8BHMZIJ0IoGZSJJOWP2k01NaPmcwgDtkB0RxCHfI\n7hYX4yoK4goGcRUV4bS7rmAQVzCQvU00HY9z8uVXafnt70n09VF6xUrmfvNuQosbp3Q7xPlLRSLE\ne3txl5bi9Ptn/fWu2UYCocC8lRWojbejNt5+xnlGHtucJJ1MWEf/hmH9YzUcGA7DOmvI6TcMA9M0\nMVMp61HQKeuR0Gn7kdDWOOsR0alYjOTgIImBAZIDgyT6B0gMWv3x7h7Ch4+SGBjATCTOui3OQABX\nMEAqFic5MEDxiuU0/f3/Q/GypRP9ZxMTLNLWRtvmLXRse4NUJAJY7Yi4y0rxlJbiLi3FU2Z1c/sz\n3Yl8qKCZTmMmk9lHlY/q2o82d5eV4Skvk8CaYBIIM4DhdOJ0OqGAT/I0TZN0LEYyHCY5FCY5NERy\nKEwqHCYZHhoZFx7GTCWpXn8zpZddWrDyinMzTZP+Xbtp3fwivR/uxHA6qbxuHSWXXWodDPT1kejt\nI97bS/TkSQb2HyA5MHDadTkDgVOCwlNWhru0BFcwSCoSyfmO2N+h8BCp8HD2u5QcHsZMJDBTqbzK\n7/B48NVU46upGenWWv3eqip5rMw4SCCIvBiGgdPnw+nzyV1BM1wqGqXzze20bn6RyIkW3CUlNNz1\nDWo23IKn/Ow/pkwnk9YZZJ8VFFa3b1Q3fOQofR/3kRoePu06nMEArqBd1VgUxFdXZ1VFBgI4PJ6c\na2eukWtoLheGy7q+hsNBvLuH6MmT9qudvl27ScdiI2/icOCtrLTCYc4cfNVzsl1fdTXuslI5uzgN\nCQQhZoloRwcnt7xE+6vbSA4NEVy4gMa/eZDK66/L+2ja4XLhrSjHW1F+znlTsRiJvj6S4WFcAb91\n3cnvn5RHkpimSaK3LxsSkTYrKGLtHfR+9BGJ3r7R2+Hx4J1TNSYsqq3AqKnGVVQ04WWcCSQQhLhI\npKJR4j09xHt7iXf3Eu/tId7Ta43r6mbgwEGAKXuMu9PrxVldPWnrz2UYBp5y67rC6a5ZpWIxYh2d\nRNutkIh2dGS7Q599TnJoaHTZgwF8c6rxVmfOKubgra7Gr+rwVVdftE8ekEAQYgZJDg8TOdHC8PHj\nhI+dIHLiBLGuLuI9vaetonF4PHjKy/GUl6HuvIPaWzfMyoaenF4vgYZ6Ag31p52eHAoT7bDDor0j\nGxyRlhb6dn5MOh4fWZffT3DhAoILF1C0cCHBRQsJ1KuL4mGMEghCTEOpaJRhe8c/fNza8YePnSDe\n1ZWdx+Hx4G+oJ9DQQOnll9tHyOU53XKcwYDUlefBVRSkqGghRQsXnjLNTKdJ9PUTbW9n+EQL4cNH\nCB8+TPvLr9JmB4XD4yEwb54VEosWEFy4kMDchhnXpKsEghDTgJlKMfj5Ifo+2UXfJ7sYPPhZ9vcn\nhttNoF5RvGwpwXlz8Tc0EJjbgG9O1UVxVDrdGQ7HSHXU0qbseDOVIqJbGTp8mPDhIwx9cZiut9+m\n/eVXrBkcDvx1tQTnzye4YD6B+fMILpiPp7x82oa0BIIQBRJpO5kNgP5PPyUVHgbDoOiSRdR//U6K\nLllEYO5cfDXVsuOfhgynk8BcK5y56UbAurgda29n6PARwkeOMnz0GIOffUbX2+9kl3OFQgQXzCdo\nB0Rg3jwCDfU4PJ7CbEgOCQQhpkA6mSTW3kH42DH6d+2m75NdRE9aT4D3VlVSuW4dpVdcTsmll+Iu\nDhW4tGK8DMOwfxdRQ+W6a7Ljk0NhwseOEj5yzA6Ko5x86ZWRaxMOB/7aGisc5s0lOG8egfnz8FXP\nmdIL2BIIQkygxMAAEd1KROuRbosmerI9+4Mrh89HyaUrqLvjNkpXrsRXVzttqxDExHAVBSlZvpyS\n5cuz48xUikhbG8PHjhM+eszqHj5C93vvZ59F5vD5CDQ0EJg3l7rb/4zg/HmTW85JXbsQF7FULMbA\nvv3079rNwIGDRFo0ycHB7HTD5cJXW4O/oYHytWsI1Cv8ShFctHDCHiAoZi7D6SRQX0+gvp7Ka9dl\nx6eiUYaPn2D42DHCx44zfOw4vTt2UH3zlye9TPKtFCJPZirF0KEv6Nu1m75duxk8cBAzmcRwuShq\nvISKdWvxqzr8ytrxy0VfMR5On4/Q4sZTHgY5FU0VzIpASMVi1k/i5bRcnAfTNInoVqvOf9du+vfs\nsS78AsEFC6i97VZKL7+M4mVLcfp8BS6tuNhNxf5rVgRCy7O/pXP7H6lYdw0V16wltLjxov2locif\nmUoR7+kl1tlJtKOTWEcHsc5O6xetHZ3Eu7qyF/281XOovHYdpZdfRsmlK3CXlBS49EJMvFkRCEWL\nGwkfPUbb5i20PrcJT0W51f7xumsobloip/UzjJlOE+vsZPhEi/Wr3ZYWIic0wy0tpCIRq37e4bAe\niJZtHCjzshoHSkUixLu6T3myprukBO+cKoIL5lG+ehV+pSi9bAW+mpoCba0QU2dWBELFmtVUrFlN\nMhymZ8eHdL/7PidffpW2zVtwl5VSsXYtFevWUrJ8mYTDNGOaJv27P2Xw4GdWALS0EGnRox4l4C4t\nxV+vqLrhOlxFRdl2HsxUym5Lwm77IacdCIfXg+/6OXirquyHnFXhraqacb8sFWIizYpAyHAFg8y5\n6Ubm3HQjyeEIvR/tpPvd9+jY9jont76Eq7iYijWrKV+7mpJLV8jOocDCR49y5Nf/y2qDGut+fX99\nPSUrlmcf2eCvV7hDct++EBNhVgVCLlfAT9X111J1/bWkolF6d35M97vv0fX2O7S/+hoOr5fSlZdT\nvvpqylZdhadU6oynSqK/n2NPPkX7q9twBQMsfOA7VH3pS7gC/kIXTYiL2qwNhFxOn4/KdddQue4a\n0okE/Xv20vOnHfT86UN6PvgTGAahJYspX3015auvxl+v5I6lSZBOJGh7cSsnnvlXUtEotbduoOHu\nu+QMQIgpYkzFva0Tpbm52dy6deuUvZ9pmoSPHM2GQ/iLLwDw1dZQfvUqyq66kuLly6Spvgtkmia9\nOz7kyP96nGhrG2VXXcH8++8746OKhRDnRyn1kdZ61bnmkzOEszAMg6KFCyhauIC5d99FrKubnh0f\n0rtjB21bXqJ10+bsYwjKrrqCsiuvxFc9p9DFnlHCx45z9LHf0PfJLvz1imX/6T9SdtWVhS6WELOS\nBMJ58FZWUNt8C7XNt5CKROj/dA+9Oz+hd+dOend8CIC/XlF25RXW2cOypdPiCYbT0XCLpu2FzZx8\n5TWcfj8L/urb1DTfIo90EKKA5F/fODn9/uw1hcwvWvt2fkzvRztp2/qydfbg9VKyYjnBBfOtpvfq\n6vDX1Y3raZamaZIKh4n39JAMD5NOJEjH4/bL6jcTI/2Z2zINtxuH243D48bh9uDwuK3Gyj1uHB4P\nDrcbp9+Pp7ICd3HxpP5gLxWL0f3ue7S/uo2BvfswnE5qNnyVuffcLU/4FGIayCsQlFIbgIcBJ/Br\nrfVDY6Yb9vRbgWHgPq31TqVUA/AEUA2YwKNa64ftZcqBZ4D5wFHgLq117wRs05QzDINAvSJQr6i7\n4zZS0Sj9e/bSt/Nj+nbtpvfjT7KNnQC4iorw1dXir6uznn1TV4uvtpZ0PG61f9vdQ6y7O9uf6ebe\ne3/OMtm/pxj7w6uzLuNy4a2swFNRgbeyEk9lBd6KCjyVlXirKvBWVo1rxx0+epT2V16j483tpMJh\nfLU1zPvWv2POl2/CU1Z23usTQkyOcwaCUsoJ/AJYD7QAO5RSm7TW+3JmawYa7dca4BG7mwR+aIdD\nCPhIKfWqveyPgG1a64eUUj+yh/9+AretYJw+H+WrrqJ81VXAyLPwI21tRHQr0dZWIq1t9H+6h843\n3zrtOgy3G2+F1Qxi0aJFeFZfjaeiHE95Ba6ioH2E7x05+vd47bMA68g/NxDSySRmImGdPWTOIhIJ\ne1ycZDhMvLubWJf1ind1MXDgAPHuHsxkclS5XKHQyAPc6lW231dTPaq6JxWJ0PX2O5x85TWGPvsc\nw+WiYt1aqtffTMmK5fLoECGmoXzOEFYDh7TWhwGUUk8DG4HcQNgIPKG1NoH3lVKlSqlarXUb0Aag\ntR5USu0HlL3sRuAme/nHgTe5SAJhLIfLZe8468AOiYxULEa0rY1o20mrQfTMTj9UNCG3thpOJ06n\nE8bxIzsznSbR32+HRDfRjo7sM/57d+6kY9vro97HV1ONXymcfj/dH/yJdDSKv6GeBd+5n6qbbpRq\nISGmuXwCQQEncoZbsI7+zzWPwg4DAKXUfOAK4AN7VLUdGAAnsaqVZh2n12u1uTp/fqGLcgrD4cBT\nVmZV6zRecsr0ZDg8qhGYTH+8t4/KdWup/up6Qk1L5DcbQswQU3JRWSlVBPwO+Fut9cDY6VprUyl1\n2h9EKKUeAB6w+ye1nOL8uILB0z63XQgxM+VTkauBhpzhentcXvMopdxYYfCk1vr3OfO0K6Vq7Xlq\ngY7TvrnWj2qtV2mtV1VUVORRXCGEEOORTyDsABqVUguUUh7gbmDTmHk2Ad9SShlKqbVAv9a6zb77\n6F+A/VrrfzrNMvfa/fcCz497K4QQQlywc1YZaa2TSqkHgZexbjt9TGu9Vyn1fXv6L4EtWLecHsK6\n7fR+e/Frgb8EPlVKfWKP+7HWegvwEPCsUuo7wDHgronbLCGEEOdLnmUkhBAXuXyfZSQ3gwshhAAk\nEIQQQtgkEIQQQgASCEIIIWwSCEIIIQAJBCGEEDYJBCGEEIAEghBCCJsEghBCCEACQQghhE0CQQgh\nBCCBIIQQwiaBIIQQApBAEEIIYZNAEEIIAUggCCGEsEkgCCGEACQQhBBC2CQQhBBCABIIQgghbBII\nQgghAAkEIYQQNgkEIYQQgASCEEIImwSCEEIIQAJBCCGEzZXPTEqpDcDDgBP4tdb6oTHTDXv6rcAw\ncJ/Weqc97THgNqBDa70iZ5mfAt8FOu1RP9Zab7mgrRFCCDFu5zxDUEo5gV8AzcAy4B6l1LIxszUD\njfbrAeCRnGm/ATacYfU/11qvtF8SBkIIUUD5VBmtBg5prQ9rrePA08DGMfNsBJ7QWpta6/eBUqVU\nLYDWejvQM5GFFkIIMfHyCQQFnMgZbrHHne88p/MDpdRupdRjSqmyPOYXQggxSQp5UfkRYCGwEmgD\nfna6mZRSDyilPlRKfdjd3T2V5RNCiFkln4vKGmjIGa63x53vPKMX0Lo906+U+hWw+QzzPQo8CtDc\n3GzmUV7P+q28AAATEElEQVQhhBDjkM8Zwg6gUSm1QCnlAe4GNo2ZZxPwLaWUoZRaC/RrrdvOttLM\nNQbb14A951FuIYQQE+ycZwha66RS6kHgZazbTh/TWu9VSn3fnv5LYAvWLaeHsG47vT+zvFLqKeAm\noFIp1QL8RGv9L8A/KqVWAiZwFPjeBG6XEEKI82SY5syphWlubja3bt1a6GIIIcSMopT6SGu96lzz\nyS+VhRBCABIIQgghbBIIQgghAAkEIYQQNgkEIYQQgASCEEIImwSCEEIIQAJBCCGETQJBCCEEIIEg\nhBDCJoEghBACkEAQQghhk0AQQggBSCAIIYSwSSAIIYQAJBCEEELYJBCEEEIAEghCCCFsEghCCCEA\nCQQhhBA2CQQhhBCABIIQQgibBIIQQghAAkEIIYRNAkEIIQQggSCEEMImgSCEEAIAVz4zKaU2AA8D\nTuDXWuuHxkw37Om3AsPAfVrrnfa0x4DbgA6t9YqcZcqBZ4D5wFHgLq117wVujxBCiHE65xmCUsoJ\n/AJoBpYB9yillo2ZrRlotF8PAI/kTPsNsOE0q/4RsE1r3Qhss4eFEEIUSD5VRquBQ1rrw1rrOPA0\nsHHMPBuBJ7TWptb6faBUKVULoLXeDvScZr0bgcft/seBO8ezAUIIISZGPlVGCjiRM9wCrMljHgW0\nnWW91VrrzPSTQPVp31ypB7DOOlBK5VFcIYQQ4zEtLiprrU3APMO0R7XWq7TWqyoqKqa4ZEIIMXvk\nEwgaaMgZrrfHne88Y7VnqpXsbkceZRFCCDFJ8gmEHUCjUmqBUsoD3A1sGjPPJuBbSilDKbUW6M+p\nDjqTTcC9dv+9wPPnUW4hhBAT7JyBoLVOAg8CLwP7gWe11nuVUt9XSn3fnm0LcBg4BPwK+L8zyyul\nngLeA5YopVqUUt+xJz0ErFdKfQ7cbA8LIYQoEMM0T1t1Py01NzebW7duLXQxhBBiRlFKfaS1XnWu\n+abFRWUhhBCFJ4EghBACkEAQQghhk0AQQggBSCAIIYSwSSAIIYQAJBCEEELYJBCEEEIAEghCCCFs\nEghCCCEACQQhhBA2CQQhhBCABIIQQgibBIIQQghAAkEIIYRNAkEIIQQggSCEEMImgSCEEAKQQBBC\nCGGTQBBCCAFIIAghhLBJIAghhAAkEIQQQtgkEIQQQgASCEIIIWwSCEIIIQBw5TOTUmoD8DDgBH6t\ntX5ozHTDnn4rMAzcp7XeebZllVI/Bb4LdNqr+bHWesuFbpAQYvyS4TDx7m6cwSCuYBCH14thGIUu\nlpgi5wwEpZQT+AWwHmgBdiilNmmt9+XM1gw02q81wCPAmjyW/bnW+r9P2NYIIc6bmUrRt2s3Hdve\noPuDP2EmEtlphtNph0MAVzCYDQqrP4ArEMAZ8OP0B3AFAzj9fpxjxo03VFLRKPHeXhK9fcR7++z+\nXhL9AxguZ/a9XPZ7WcP2+/v9uAIBHF4PDo8Hw+WSYMtDPmcIq4FDWuvDAEqpp4GNQG4gbASe0Fqb\nwPtKqVKlVC0wP49lhTijVCTC0KEvSEWjYBgYDquW03A4wDBGxtldh9uNMxiwdkYBPw6Pp8BbMH0N\nt7TQ8fqbdL7xFvGeHlyhImq+ejOhpiZS0QjJoTCpcJik/UqFwySHhhnu7skOp+Pxc7+RYeDweHB4\n3DjcnpF+jyf7MtxuDKeT5MAA8d5e4r19pKPRU9flcOAuLsZMpUhFIpjJZH4b63Dg8Hhwej057+vN\nBobDfv/TvlxODIfVdbjdI6Hn92XDJxNAmVCaqWdW+QSCAk7kDLdgnQWcax6Vx7I/UEp9C/gQ+KHW\nujfPcouLkGmaxDo7GTxwkIH9Bxg8cJDw0WOQTo97nYbLNfooMnMU6/dldwxOr3dkJ+HN2Ulkptkv\np9eT7Xd4rGHD6ZzAv8DkSw6F6Xr7HTpef4PBg5+Bw0HZVVew4LvfpvzqVTjc7vNan5lKkRweJjUc\nIRWxutnh4WGrPxIhHY9jJhKkYlY3HY9br0SCVCRKemAAM5nEVVxM0aJFuMtK8ZSV4SkrxZ3plpbh\nLg5lDwoAa/nhYZLDEVKRkTKkIhGrG4uSjsVH3i8WIx2Pk4qNGR4exkylMFMp0skUpEf3p5P2cDye\n3/fR4cDp81mhYQfGqS/f6H6fD0fuMj4fTp/fGufzjtruyZLXNYRJ8gjwD4Bpd38GfHvsTEqpB4AH\n7P5xvVG0vZ1keNjaKdgpfr5ffDHx0skk4SNHGTxwIBsA8e4eABw+H6HFjdR/4+sUL23CFQqBaYJp\nYma66fQp3XQ8Ye0UwtaO6HQ7p3h3d3YnZe0U4vkd6Z6G4XaPCRTPqCNfR860zNGp4XbjcLmsrtuF\n4XJZR6jZrj0+c3TqtPodrjHj7K6ZSmEm4qTjCdLJhNWNxzGTSXsbreG+Xbvoef9PpONxAnMbmH//\nvVTdeD2esrJxf4aG04k7FMIdCo17HRfC4XbjKCnBXVIyJe9nmqYVIJGc0IlY369UJJr9jp3ysudL\n9PeTikSz4/M+wwGW/af/SNlVV07i1uUXCBpoyBmut8flM4/7TMtqrdszI5VSvwI2n/bNtX4UeBSg\nubnZzKO8p67jD5s4ufWlUeMMt3vkqDG33jEYwBUK4Soqwh0K4QqFcBdbXVfIGufw+Wbk6eB0kI7H\n6f34E7refpeeP+3IVgt4qyopXraU4qVNhJY2EZw3b0qPvjP/0Ee9YjHSsTgp+yjSGo6Ritpde9ia\nJzoqXNLxOMmhIdI9PaOPUO2jYsxxfZUviCtURPX6rzDny18iuGihfIfHwTAMnF4vTq8XSksveH2Z\nM6RUNEI6GrX77Vckao2LWgHiq6ubgC04u3wCYQfQqJRagLUzvxv45ph5NgEP2tcI1gD9Wus2pVTn\nmZZVStVqrdvs5b8G7LngrTmDmuZbKL38MlIR+9TSTvFkeHjkFHN4mHhXF8PHwiQHh0hFImdcn+Fy\njQoKdyiEqzh0mgCxgsXhdgGG9Z+RU/dtGOAwAAPDwDq6jeV8EWIxuz9if0lipKNRTNMcOaLMHGm6\nXBhuFw5X5kjTZR2VnnJq6p/yao50IkHfJ7voevsdej7YQSoSwRUKUXX9dZSuvIxQUxPeyoopLdNY\no/6hTzLTNCGdJp1IWEfxiUROfzI7zkwlMe2qCjOZzFZhjIy3upm6bcOdqae3X5mzEftMxFNRIWfG\n00zms3IXF+YMa6xzBoLWOqmUehB4GevW0ce01nuVUt+3p/8S2IJ1y+khrNtO7z/bsvaq/1EptRKr\nyugo8L2J3LBcwXlzCc6be17LpBMJkkNDJAcHSQwOkhzM9NvdgUGSg9Zr+ERLdr4Lqe/Oh+F0gmGc\n16nmKevIXBjLCQpXIJBz10gg5y6S4GnGB3H6z36WlE4k6N/9KV1vv0P3B38iFR7GVVRExbXXUHnt\nOkouuxSHq5A1loVjGAY4nThn2PUHcfEzzAKcuo5Xc3OzuXXr1kIX44xM0yQ1PDwqLBKDQ9YFqrQJ\nmNmuVedt99tdw+2xLyR57YtL/tHDPl/2CM80zVOPKHO6ZjJpn2FERs4yMnWX0eiYOs6odbYUDtt1\n7sPnDhyHYyREgsFsWLiCQcx0it4Pd5IcGsIZDFCxZjUV166j9PLL5AhViAJQSn2ktV51rvlm5yHa\nJDEMI7tTpLZm0t8rUx0w0bIXzoaHraCwQ8K6/XCkP2UPZ/qj7e3WrYiJJGWrrqTy2nWUXrFSQkCI\nGUICQZwitz79Qu5AEULMLPIsIyGEEIAEghBCCJsEghBCCEACQQghhE0CQQghBCCBIIQQwiaBIIQQ\nApBAEEIIYZNAEEIIAUggCCGEsEkgCCGEACQQhBBC2CQQhBBCAPK004JKJxJEWtsYPn6CiNZWK23p\nNKb9Ip222j1IpUeNN5xOq0U0t3ukRSyPJ9smb6bVLKttXrfVkprbnTO/KzstM3+21bWpbLYylcpp\nhjI2uuHzTBOV9jCA4XBY5XM4s/1W1wGZYafdepjTmdOinN11Wu0XW+Od9rocs7YpSTOVItrRSbSt\njYhuJdLaSrS1jeTQUM7fKefv57K/N9n+3HaeR3cd2Xaf7bafHU778xn5nIyczyzzWWRbkIvHMROZ\n1uRy+632PjCMs7Yz7XDZ3xNnzvfEkfM9GTtsfwVGNQ+THcgdadjvkXmNfJdG/R0cM/NYe1YEQt+u\n3YSPHsNwGGDYXwTDwHAYdr/DnmaM7EjcOTtT18iOd2RaTtOVLtdZvwDpZJJoayvDJ1oYPn4i+4q2\ntWGmUtZMhmHt1DNf0kzZMl9cu9yGw2E1Jp/5RxKPk04mJ6yltuyOwOMZExiebLOcowIlGyYj/YbT\nabcPG7GaLI1YDZCnMg3e2w3zjLdh+wk3asfkOHXn5XCeshPIHc7ufEbtZBxWc6kOR854w+53jszj\nOHUHOTIttxyu0TvT3B1phr0DyzZ6ldM1TUj09xHR1k4/0tpK9GT7qIaQnIEAflWHu6TYaqozmbQ+\np8HkqMaYzGSSdDKJmUjYzXpO3PfvopHZl4wNoex3bOzBzWm+F6O+D07mfvNuQo2XTGqxZ0UgdL/3\nPie3vjy5b+JwjG7f2G7XGAxinZ2jdvy+mmoCcxuoWLuawNy5BOY24Fd1ODyecb+9mUrZDbgn7bBI\n2P0Jqz+ZGH2UNao/MbrfbgjeOlJLYCbs9drjU8PD9vTkyLSc9WCaOe05+3EGrK6nohxnvR+nP4DL\nHufwea15vV4cmVd22JMdBsNueS5ttTGcSmf7yYzLdLM7rCRmyu7P3aFl2ijOris1evnM+nOnZdox\nTqdG2jlOpUhHY6RSSbs8qVFndtmzulTabiEv58wv9/3scVPBcLvx19Xir6+nfPXV+FUd/ro6fHVW\nEIz3bGnU385u7zkTKmYqmf07ZObhDH9762DEPeogzOFxjz4Acbmsv+dZ2pnODSrr75465Ux7ZDg1\n9q90Sm/m72KmTes9Rm3ryPvlbtPpPufM34BsmXK+Mznf6VF/z3hi5Ls+yWZFICz49n3M+8u/yPlH\naYKZ+cdpYpq51TOpkZ3HqB1lpnnKRPboKLPTGTV8mp1PxbXXEJjbYO/41aQ05G44nfYOeMJXfV4y\nO8KprHq6GIwOkNMF1OlCKjVqJzFqZ25YZ7y501yhEN7Kikn5bLJnQVPZOp60xDfhZkUgODyeCzr6\nFvnLNCAvzk/m72Y4nbKjEwUzM698CCGEmHASCEIIIQAJBCGEEDYJBCGEEIAEghBCCJsEghBCCEAC\nQQghhE0CQQghBACGOeppTtObUqoTODbOxSuBrgksTiHJtkw/F8t2gGzLdHUh2zJPa111rplmVCBc\nCKXUh1rrVYUux0SQbZl+LpbtANmW6WoqtkWqjIQQQgASCEIIIWyzKRAeLXQBJpBsy/RzsWwHyLZM\nV5O+LbPmGoIQQoizm01nCEIIIc5iVrSHoJTaADwMOIFfa60fKnCRxk0pdRQYBFJAcqbcQaGUegy4\nDejQWq+wx5UDzwDzgaPAXVrr3kKVMV9n2JafAt8FOu3Zfqy13lKYEuZHKdUAPAFUYzUc/KjW+uGZ\n+LmcZVt+ysz7XHzAdsCLtY/+rdb6J1PxuVz0ZwhKKSfwC6AZWAbco5RaVthSXbAvaa1XzpQwsP0G\n2DBm3I+AbVrrRmCbPTwT/IZTtwXg5/bnsnK673RsSeCHWutlwFrgr+1/GzPxcznTtsDM+1xiwJe1\n1pcDK4ENSqm1TMHnctEHArAaOKS1Pqy1jgNPAxsLXKZZR2u9HegZM3oj8Ljd/zhw55QWapzOsC0z\njta6TWu90+4fBPYDihn4uZxlW2YcrbWptR6yB932y2QKPpfZEAgKOJEz3MIM/aLYTOA1pdRHSqkH\nCl2YC1SttW6z+09ine7PZD9QSu1WSj2mlCordGHOh1JqPnAF8AEz/HMZsy0wAz8XpZRTKfUJ0AG8\nqrWeks9lNgTCxeY6rfVKrCqwv1ZK3VDoAk0ErbWJFXYz1SPAQqxT/DbgZ4UtTv6UUkXA74C/1VoP\n5E6baZ/LabZlRn4uWuuU/e+8HlitlFoxZvqkfC6zIRA00JAzXG+Pm5G01trudgB/wKoSm6nalVK1\nAHa3o8DlGTetdbv9jzgN/IoZ8rkopdxYO9Antda/t0fPyM/ldNsyUz+XDK11H/AG1jWrSf9cZkMg\n7AAalVILlFIe4G5gU4HLNC5KqaBSKpTpB74K7ClsqS7IJuBeu/9e4PkCluWCZP6h2r7GDPhclFIG\n8C/Afq31P+VMmnGfy5m2ZYZ+LlVKqVK73w+sBw4wBZ/LrPhhmlLqVuCfsW47fUxr/V8KXKRxUUot\nxDorAOt2tP9/pmyLUuop4CasJza2Az8BngOeBeZiPcX2Lq31tL9Ye4ZtuQmrWsLEuiXwezn1vdOS\nUuo64I/Ap0DaHv1jrLr3GfW5nGVb7mHmfS6XYV00dmIdtD+rtf7PSqkKJvlzmRWBIIQQ4txmQ5WR\nEEKIPEggCCGEACQQhBBC2CQQhBBCABIIQgghbBIIQgghAAkEIYQQNgkEIYQQAPwfaOzzYKsYOQgA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f079d3f9908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(test_loss))\n",
    "figLoss = plt.figure()\n",
    "plt.plot(np.array(test_loss).squeeze(),'r')\n",
    "\n",
    "figLoss.savefig('RNN Paper Results/Exp2_1/' + test_location + '/'+  test_year + 'test_loss.jpg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Demornamization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.164525\n",
      "0.149404\n",
      "0.069836\n",
      "0.0432742\n"
     ]
    }
   ],
   "source": [
    "mse_1 = np.array(test_loss).squeeze()[-1][0]\n",
    "mse_2 = np.array(test_loss).squeeze()[-1][1]\n",
    "mse_3 = np.array(test_loss).squeeze()[-1][2]\n",
    "mse_4 = np.array(test_loss).squeeze()[-1][3]\n",
    "\n",
    "rmse_1 = np.sqrt(mse_1)\n",
    "rmse_2 = np.sqrt(mse_2)\n",
    "rmse_3 = np.sqrt(mse_3)\n",
    "rmse_4 = np.sqrt(mse_4)\n",
    "\n",
    "print(rmse_1)\n",
    "print(rmse_2)\n",
    "print(rmse_3)\n",
    "print(rmse_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.572121648329\n",
      "1.04362327401\n",
      "4.46312278844\n",
      "54.6116210989\n"
     ]
    }
   ],
   "source": [
    "rmse_denorm1 = (rmse_1 * (df_new_test['Kt'].max() - df_new_test['Kt'].min()))+ df_new_test['Kt'].mean()\n",
    "rmse_denorm2 = (rmse_2 * (df_new_test['Kt_2'].max() - df_new_test['Kt_2'].min()))+ df_new_test['Kt_2'].mean()\n",
    "rmse_denorm3 = (rmse_3 * (df_new_test['Kt_3'].max() - df_new_test['Kt_3'].min()))+ df_new_test['Kt_3'].mean()\n",
    "rmse_denorm4 = (rmse_4 * (df_new_test['Kt_4'].max() - df_new_test['Kt_4'].min()))+ df_new_test['Kt_4'].mean()\n",
    "\n",
    "print(rmse_denorm1)\n",
    "print(rmse_denorm2)\n",
    "print(rmse_denorm3)\n",
    "print(rmse_denorm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.1726222024\n"
     ]
    }
   ],
   "source": [
    "rmse_mean = np.mean([rmse_denorm1, rmse_denorm2, rmse_denorm3, rmse_denorm4])\n",
    "print(rmse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3163.000000\n",
      "mean        0.169756\n",
      "std         0.393624\n",
      "min        -0.267460\n",
      "25%        -0.009081\n",
      "50%        -0.004916\n",
      "75%         0.125252\n",
      "max         2.178158\n",
      "Name: Kt, dtype: float64\n",
      "\n",
      "\n",
      "count    3163.000000\n",
      "mean        0.342026\n",
      "std         0.703577\n",
      "min        -0.031211\n",
      "25%        -0.006896\n",
      "50%        -0.002210\n",
      "75%         0.367659\n",
      "max         4.664769\n",
      "Name: Kt_2, dtype: float64\n",
      "\n",
      "\n",
      "count    3163.000000\n",
      "mean        1.086772\n",
      "std         3.345456\n",
      "min        -0.017466\n",
      "25%        -0.005377\n",
      "50%         0.066067\n",
      "75%         0.771512\n",
      "max        48.329415\n",
      "Name: Kt_3, dtype: float64\n",
      "\n",
      "\n",
      "count    3163.000000\n",
      "mean       10.176067\n",
      "std        45.253311\n",
      "min        -0.014020\n",
      "25%        -0.003442\n",
      "50%         0.266864\n",
      "75%         1.723366\n",
      "max      1026.823214\n",
      "Name: Kt_4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_new_test['Kt'].describe())\n",
    "print('\\n')\n",
    "print(df_new_test['Kt_2'].describe())\n",
    "print('\\n')\n",
    "print(df_new_test['Kt_3'].describe())\n",
    "print('\\n')\n",
    "print(df_new_test['Kt_4'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to file\n",
    "#f=open('RNN Paper Results/Exp2_1/' + test_location + '/'+  test_year + 'results.txt', \"a+\")\n",
    "#f.write(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Saving train and test losses to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_train:\n",
    "    df_trainLoss = pd.DataFrame(data={'Train Loss':train_loss}, columns=['Train Loss'])\n",
    "    df_trainLoss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloss_unsqueezed = np.array(test_loss).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse1</th>\n",
       "      <th>mse2</th>\n",
       "      <th>mse3</th>\n",
       "      <th>mse4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026378</td>\n",
       "      <td>0.021807</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025729</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.001822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025105</td>\n",
       "      <td>0.020901</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024517</td>\n",
       "      <td>0.020494</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024026</td>\n",
       "      <td>0.020282</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.001989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mse1      mse2      mse3      mse4\n",
       "0  0.026378  0.021807  0.004765  0.001834\n",
       "1  0.025729  0.021338  0.004686  0.001822\n",
       "2  0.025105  0.020901  0.004580  0.001783\n",
       "3  0.024517  0.020494  0.004473  0.001749\n",
       "4  0.024026  0.020282  0.004464  0.001989"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testLoss = pd.DataFrame(data=testloss_unsqueezed,columns=['mse1','mse2', 'mse3', 'mse4'])\n",
    "df_testLoss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_testLoss.to_csv('RNN Paper Results/Exp2_1/' + test_location + '/' +  test_year + '_TestLoss.csv')\n",
    "if run_train:\n",
    "    df_trainLoss.to_csv('RNN Paper Results/Exp2_1/' + test_location + '/'+  test_year + '_TrainLoss.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
